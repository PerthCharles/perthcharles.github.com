<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[天赋  无与伦比的坚持]]></title>
  
  <link href="/atom.xml" rel="self"/>
  <link href="http://perthcharles.github.com/"/>
  <updated>2015-11-02T14:49:35.107Z</updated>
  <id>http://perthcharles.github.com/</id>
  
  <author>
    <name><![CDATA[Perth Charles]]></name>
    <email><![CDATA[zhongbincharles@gmail.com]]></email>
  </author>
  
  <generator uri="http://zespia.tw/hexo/">Hexo</generator>
  
  <entry>
    <title><![CDATA[TCP Tail Loss Probe(TLP)]]></title>
    <link href="http://perthcharles.github.com/2015/10/31/wiki-network-tcp-tlp/"/>
    <id>http://perthcharles.github.com/2015/10/31/wiki-network-tcp-tlp/</id>
    <published>2015-10-31T11:01:45.000Z</published>
    <updated>2015-11-02T14:47:53.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>Early Retransmit机制解决了dupack较少，无法触发快速重传的问题。<br>但是如果发生了尾丢包，由于尾包后面没有更多的数据包，也就没有办法触发任何的dupack。<br>为解决这种尾丢包的问题，Google的几位大神提出了TLP算法。通过TLP算法，发送一个loss probe包，来产生足够的SACK/FACK的信息来触发RF。根据Google的测试，TLP能够有效的避免较长的RTO超时，进而提高TCP性能。  </p>
<a id="more"></a>  

<hr>
<h3 id="RFC解读">RFC解读</h3>
<hr>
<h4 id="TLP基本策略">TLP基本策略</h4>
<p>TLP算法会在TCP还是Open状态的时候，设置一个Probe TimeOut (PTO)。<br>当链路中有未被确认的数据包，同时在PTO时间内未收到任何ACK，则会触发PTO<br>超时处理机制。<br>TLP会选择传输序号最大的一个数据包作为tail loss probe包，这个序号最大的包可能是<br>一个可以发送的新的数据包，也可能是一个重传包。<br>TLP通过这样一个tail loss probe包，如果能够收到相应的ACK，则会触发FR机制，而不是RTO机制。  </p>
<hr>
<h4 id="触发超时机制的常见场景">触发超时机制的常见场景</h4>
<p>这些case还是用大神们的原文描述比较准确:)</p>
<pre><code>a. <span class="operator"><span class="keyword">Drop</span> tail <span class="keyword">at</span> the <span class="keyword">end</span> <span class="keyword">of</span> transactions.
b. <span class="keyword">Mid</span>-<span class="keyword">transaction</span> loss <span class="keyword">of</span> an entire window <span class="keyword">of</span> <span class="keyword">data</span> <span class="keyword">or</span> ACKs.
c. Insufficient <span class="built_in">number</span> <span class="keyword">of</span> duplicate ACKs <span class="keyword">to</span> <span class="keyword">trigger</span> <span class="keyword">fast</span> recovery <span class="keyword">at</span> sender.
    <span class="comment">-- 基本被Eearly Retransmit机制解决了</span>
d. An unexpectedly long <span class="keyword">round</span>-trip <span class="keyword">time</span>(RTT), such that the ACKs arrive <span class="keyword">after</span>
   the RTO timer expires.
    <span class="comment">-- F-RTO机制通过检测spurious retransmission，能够尽量的undo RTO造成的影响</span></span>
</code></pre><p>Early Retransmit技术可参考<a href="http://perthcharles.github.io/2015/10/31/wiki-network-tcp-early-retrans/" target="_blank" rel="external">这篇wiki</a><br>F-RTO技术可参考<a href="http://perthcharles.github.io/2015/06/16/wiki-network-tcp-frto/" target="_blank" rel="external">这篇wiki</a>  </p>
<p>Google Web servers上面，将近70%的重传是RTO超时重传，只有30%是Fast Recovery重传。<br>同时还有数据表明，96%的RTO超时重传是在没有收到任何dupack的情况下发生的。<br>没有到任何dupack就意味着FR和ER机制都是无法生效的。  </p>
<hr>
<h4 id="RTO与RTT的比值分布">RTO与RTT的比值分布</h4>
<p>Googler们还收集RTO/RTT的分布，来了解RTO值到底比RTT值大多少。下面是统计结果  </p>
<pre><code><span class="variable">Percentile</span>      <span class="variable">RTO</span>/<span class="variable">RTT</span>
<span class="number">50</span><span class="comment">%             4.3</span>
<span class="number">75</span><span class="comment">%             11.3</span>
<span class="number">90</span><span class="comment">%             28.9</span>
<span class="number">95</span><span class="comment">%             53.9</span>
<span class="number">99</span><span class="comment">%             214</span>
</code></pre><p>根据这个数据，显然这是一个CDF的统计。也就是说，50%的流，RTO/RTT小于4.3，75%的流，RTO/RTT小于11.3<br>不过反过来看，有50%的流RTO/RTT超过4.3，25%的流RTO/RTT超过11.3。<br>不过这个数据Googler并没有进一步的解释，有很多疑问在里面。<br>RTO的min值默认是200ms，这数据里面的是多少？这个数据里面是否同时包含了internet-face流和local-face流。<br>比如说，local-face流的rtt一般很小，常见值就是1.875ms，而min RTO值200ms的话，显然RTO/RTT很容易超过100<br>不过话说回来，数据来看，local-face的流应该没有包括，但是min RTO就不清楚了。  </p>
<p>Googler认为”Such large RTOs make a huge contribution to the long tail on the<br>latency statistics of short flows.”<br>这点如果结合TLP考虑的情景，推断确实合理。  </p>
<p>那将RTO的计算值设置的较小一点如何？可能会造成两个问题：<br>a. spurious retransmission<br>b. 更多的RTO =&gt; cwnd=1</p>
<p>TLP试图解决的方式是将”尾丢包+RTO”这种case转换为”尾丢包+尾探测+FR”。</p>
<hr>
<h4 id="TLP算法">TLP算法</h4>
<p>名词解释  </p>
<pre><code>FlightSize: <span class="keyword">the</span> amount <span class="keyword">of</span> data <span class="keyword">that</span> has been sent <span class="keyword">but</span> <span class="keyword">not</span> yet *cumulatively* acknowledged.
    <span class="comment">-- 这个与内核中的packet_in_flight计数器要区分开，这里要强调累计确认</span>

PTO: Probe <span class="keyword">timeout</span> <span class="keyword">is</span> a timer event indicating <span class="keyword">that</span> an ACK <span class="keyword">is</span> overdue.

Open state: <span class="keyword">the</span> sender has so far received <span class="keyword">in</span>-sequence ACKs <span class="keyword">with</span> no SACK
            blocks, <span class="keyword">and</span> no other indications (such <span class="keyword">as</span> retransmission <span class="keyword">timeout</span>) <span class="keyword">that</span>
            a loss may have occurred.
    <span class="comment">-- 换成中文：TCP的正常状态，哈哈</span>

Consecutive PTOs: <span class="keyword">back</span>-<span class="keyword">to</span>-<span class="keyword">back</span> PTOs all scheduled <span class="keyword">for</span> <span class="keyword">the</span> same tail packets <span class="keyword">in</span> a flight.
</code></pre><p>算法逻辑  </p>
<pre><code><span class="number">1.</span> 在Open state发送新数据后，设置一个PTO计时器  
    <span class="keyword">if</span> (FlightSize &gt; <span class="number">1</span>)     PTO = <span class="built_in">max</span>(<span class="number">2</span>*SRTT, <span class="number">10</span>ms)
    <span class="keyword">if</span> (FlightSize == <span class="number">0</span>)    PTO = <span class="built_in">max</span>(<span class="number">2</span>*SRTT, <span class="number">1.5</span>*SRTT + WCDelAckT)
    <span class="keyword">if</span> (RTO is earlier)     PTO = <span class="built_in">min</span>(RTO, PTO)
        其中WCDelAckT表示worst <span class="keyword">case</span> delayed ACK timer，默认值是<span class="number">200</span>ms

<span class="number">2.</span> 启用PTO timer的条件：
    <span class="operator">a</span>. connection is <span class="operator">in</span> <span class="built_in">open</span> state
        <span class="comment">-- 如果不在open state，说明有其他信息帮助判断丢包。而无需启用TLP</span>
    b. connection is either cwnd limited <span class="operator">or</span> application limited
        <span class="comment">-- TLP必须满足tail这个条件</span>
    c. <span class="built_in">number</span> <span class="operator">of</span> consecutive PTOs &lt;= <span class="number">2</span>
        <span class="comment">-- TLP 不要尝试太多次</span>
    d. connection is SACK enable
        <span class="comment">-- TLP依赖于SACK选项来提供是否触发FR的决策</span>

<span class="number">3.</span> 当PTO超时后：
    <span class="keyword">if</span> (能发新数据)         发送一个新数据包，FlightSize += SMSS, cwnd不改变
    <span class="keyword">if</span> (没有新数据可发)     发送一个序号最大的数据包
    增加loss probe的计数器
    如果步骤<span class="number">2</span>中的条件满足，则再次设置PTO；否则设置RTO超时计时器<span class="string">'now+RTO'</span>

<span class="number">4.</span> 在处理收到的ACK包时
    取消PTO timer
    如果步骤<span class="number">2</span>条件满足，则设置PTO timer
</code></pre><hr>
<h4 id="基于FACK机制的FR触发算法">基于FACK机制的FR触发算法</h4>
<p>理解FACK机制最终的一点就是意识到SACK信息能够反应较准确的接收端接收情况。<br>FACK机制的算法如下，非常好理解：  </p>
<pre><code><span class="keyword">if</span> (SND.FACK - SND.UNA) &gt; dupack threshold:
    -&gt; Invoke Fast Retransmit <span class="operator">and</span> Fast Recovery.
SND.FACK relects <span class="operator">the</span> forward-most data held <span class="keyword">by</span> <span class="operator">the</span> received plus <span class="constant">one</span>.
</code></pre><hr>
<h4 id="如果丢失的包就是TLP重传的数据包会怎样">如果丢失的包就是TLP重传的数据包会怎样</h4>
<p>如果丢失的包刚好是最后一个数据包，那么TLP的重传可能会恰巧修复了这个丢包。<br>这样对于congestion control机制来说，就无法发现这个丢包。这与TCP的拥塞控制<br>机制相违背。<br>因此TLP需要设计一个检测丢包是否被TLP探测包修复的逻辑。  </p>
<p>检测的核心思想就是：  </p>
<pre><code>如果发送了<span class="keyword">N</span>次TLP探测包，判断是否收到了<span class="keyword">N</span>个<span class="string">"TLP dupacks"</span>。
如果没有，则意味着第一个TLP探测报可能就刚好修复了一个丢失包。  
</code></pre><hr>
<h4 id="TLP丢包检测算法">TLP丢包检测算法</h4>
<p>名词解释  </p>
<pre><code>TLPRtxOout: <span class="operator">the</span> <span class="built_in">number</span> <span class="operator">of</span> unacknowledged TLP retransmissions <span class="operator">in</span> current TCP episode.

TLPHighRxt: <span class="operator">the</span> <span class="built_in">value</span> <span class="operator">of</span> SND.NXT <span class="keyword">at</span> <span class="operator">the</span> <span class="built_in">time</span> <span class="operator">of</span> TLP retransmission.
</code></pre><p>算法步骤：</p>
<pre><code><span class="number">1</span>. 初始化  
    当TCP流进入ESTABLISHED状态，或者RTO超时后，或者进入Fast Recovery后，对上面两个变量进行初始化
    <span class="variable">TLPRtxOut =</span> <span class="number">0</span>;
    <span class="variable">TLPHighRxt =</span> <span class="number">0</span>;
<span class="number">2</span>. 当发送一个TLP探测包后  
    <span class="keyword">if</span> (<span class="variable">TLPRtxOut =</span>= <span class="number">0</span>)
        <span class="variable">TLPHighRxt =</span> SND.NXT
    TLPRtxOut++;
<span class="number">3</span>. 在收到一个ACK包后  
    当满足所有以下条件时，认为这个ACK是由TLP包触发的，而且这个TLP是完全多余的
    a. TLPRtxOut &gt; <span class="number">0</span>                        <span class="comment">/* 首先当然得发送过TLP包 */</span>
    b. SEG.<span class="variable">ACK =</span>= TLPHighRxt                <span class="comment">/* ACK包确认了SND.NXT序号 */</span>
    c. ACK不包含序号超过TLPHighRxt的SACK段  <span class="comment">/* 意味着这个ACK就是TLP包序号触发的，而不是TLPHighRxt序号之后某个包触发的 */</span>
    d. ACK没有移动SND.UNA                   <span class="comment">/* 说明这是一个纯粹的dupack，并且ACK号是SND.NXT证明这个ACK包对应的TLP是完全多余的 */</span>
    e. ACK包不含数据                        <span class="comment">/* 就是要证明这个ACK是一个完全多余的TLP包触发的 */</span>
    f. ACK包不是一个窗口更新包              <span class="comment">/* 理由同e */</span>
    以上条件都满足时，TLPRtxOut--

    如果ACK.SEQ &gt; TLPHighRxt，则说明TLP阶段应该结束了。最后来判断是否发现了丢包
    <span class="variable">isLoss =</span> (TLPRtxOut &gt; <span class="number">0</span>) &amp;&amp;     <span class="comment">/* 不为0说明有一个TLP包不是多余的，也就是说有丢包发生 */</span>
             (ACK不携带任何TLP重传相关的DSACK信息)      <span class="comment">/* 如果包含DSACK信息，也能证明TLP是多余的。所以要排除这种情况 */</span>
    <span class="variable">TLPRtxOut =</span> <span class="number">0</span>
    <span class="keyword">if</span> (isLoss)
        EnterRecovery()
<span class="number">4</span>. TLP探测包的发送条件，除了满足TLP原始算法中步骤<span class="number">2</span>中的条件外，还要满足  
    (<span class="variable">TLPRxtOut =</span>= <span class="number">0</span>) || (SND.<span class="variable">NXT =</span>= TLPHighRxt)
    -- The sender maintains this invariant so that there is at most
       one TLP retransmission <span class="string">"espisode"</span> happening at a time.
</code></pre><hr>
<h4 id="统一了丢包恢复机制">统一了丢包恢复机制</h4>
<p>在原生TCP中，如果丢包发生在packet train的中间，很容易触发快速重传进行丢包恢复；<br>但是如果丢包发生packet train的末端，则基本只能靠RTO超时来恢复。<br>而这就意味着丢包的位置的不同，也可能造成TCP不同的重传机制被触发。这与TCP设计时的common sense不一致。  </p>
<p>如果使用TLP机制，则能避免丢包位置的不同对TCP重传机制的选择造成影响。  </p>
<hr>
<h4 id="恢复任意程度的尾丢包">恢复任意程度的尾丢包</h4>
<p>根据Googler们的讨论，Tail Loss Probe + Early Retransmit能够解决任意程度的尾丢包<br>下面是所有case情境的讨论汇总  </p>
<table>
<thead>
<tr>
<th>number of losses</th>
<th>scoreboard after TLP retrans ACKed</th>
<th>mechanism</th>
<th>final outcome</th>
</tr>
</thead>
<tbody>
<tr>
<td>AAAL</td>
<td>AAAA</td>
<td>TLP loss detection</td>
<td>all repaired</td>
</tr>
<tr>
<td>AALL</td>
<td>AALS</td>
<td>ER</td>
<td>all repaired</td>
</tr>
<tr>
<td>ALLL</td>
<td>ALLS</td>
<td>enhanced ER</td>
<td>all repaired</td>
</tr>
<tr>
<td>LLLL</td>
<td>LLLS</td>
<td>FACK FR</td>
<td>all repaired</td>
</tr>
<tr>
<td>&gt;=5 L</td>
<td>..LS</td>
<td>FACK FR</td>
<td>all repaired</td>
</tr>
</tbody>
</table>
<p>其中：<br>A = ACKed segment<br>L = Lost segment<br>S = SACKed segment  </p>
<p>其中case “ALLL”依赖于Googler们提出的enhanced ER机制，首先这个增加做了什么  </p>
<pre><code>Propose <span class="built_in">to</span> allow <span class="operator">a</span> delayed early retransmit <span class="operator">in</span> <span class="operator">the</span> <span class="keyword">case</span> where there
are <span class="constant">three</span> outstanding segments that have <span class="operator">not</span> been cumulatively
acknowledged <span class="operator">and</span> ont segment that has been fully SACKed.
</code></pre><p>具体来讲，就体现在之前介绍<a href="http://perthcharles.github.io/2015/10/31/wiki-network-tcp-early-retrans/" target="_blank" rel="external">ER的wiki</a>中提到的如下一个代码更改  </p>
<pre><code>@ <span class="keyword">static</span> <span class="keyword">bool</span> tcp_time_to_recover()
-   (tp-&gt;packets_out == (tp-&gt;sacked_out + <span class="number">1</span>) &amp;&amp; tp-&gt;packets_out &lt; <span class="number">4</span>) &amp;&amp; 
+   (tp-&gt;packets_out &gt;= (tp-&gt;sacked_out + <span class="number">1</span>) &amp;&amp; tp-&gt;packets_out &lt; <span class="number">4</span>) &amp;&amp; 
</code></pre><p>具体分析以下，如果是’==’的形式，case”ALLL”会得到”ALLS”的scoreboard，但是这里的packets_out=3，而sacked_out=1所以还无法触发ER。<br>此时解决方法有两种：要么在重传一个TLP探测报，使sacked_out值增长为2，要么放松条件改用”&gt;=”。<br>很明显，Googler们选了后者。<br>而对于case”AALL”这种packets_out=2的情况，一个TLP包引起的dupack就能触发ER，也就无影响了。<br>下面我来讨论一下packets_out=3的情况，其中R表示reorder达到接收端，即没有被丢弃    </p>
<pre><code><span class="number">1</span>. ALLL
    这种使用TLP和enhanced ER能够做到all repaired。没问题
<span class="number">2</span>. ALRR
    这种能够通过ER机制修复。但是如果使用了enhanced ER，那么在收到第一个reorder触发的SACK信息后，
    socreboard为ALS_状态，此时由于使用了enhanced ER，在第二个SACK信息没有收到时就会被判为启动ER。
    因为<span class="variable">packets_out=</span><span class="number">3</span>, <span class="variable">sacked_out =</span> <span class="number">1</span>, 满足enhanced ER的条件
    当然由于enhanced ER还有一个重要的特性是delayed，如果第二SACK信息能够及时的到来，最严重的后果也就是
    early retransmit的timer被设置两次而已。

<span class="number">3</span>. ALLR
    这种情况首先肯定不会触发TLP机制，因为必能能收到一个dupack。应该属于ER机制要解决的范畴。  
    但是它又由于没有足够的dupack，<span class="variable">packet_out=</span><span class="number">3</span>，dupack等于<span class="number">1</span>。标准的ER对此无能为力。  
    只能靠enhanced ER来恢复。
<span class="number">4</span>. ALRL
    <span class="variable">packets_out=</span><span class="number">3</span>,<span class="variable">dupack=</span><span class="number">1</span>。不能触发TLP，标准ER又解决不了。只能靠enhanced ER来恢复。
</code></pre><hr>
<hr>
<h3 id="源码分析">源码分析</h3>
<p>以下代码基于Linux3.10内核  </p>
<hr>
<h4 id="函数调用逻辑">函数调用逻辑</h4>
<pre><code>1. 正常数据的发送流程中，增加调度安装PTO超时计时器的逻辑
   即TLP算法逻辑的第一步。  

__tcp_push_pending_frame()
    =<span class="ruby"><span class="output"><span class="status">=&gt;</span> tcp_write_xmit() with push_one=<span class="number">0</span></span>
</span>        =<span class="ruby"><span class="output"><span class="status">=&gt;</span> tcp_schedule_loss_probe()   /* 尝试安装<span class="constant">PTO</span>超时计时器的安装 *<span class="regexp">/
</span></span></span>
2. 处理ack时，增加调度安装PTO超时计时器和结束TLP状态的逻辑
   即TLP算法的最后一步 

tcp_ack()
    =<span class="ruby"><span class="output"><span class="status">=&gt;</span> if (tp-&gt;tlp_high_seq) tcp_process_tlp_ack();    <span class="regexp">/* 判断是否需要结束TLP状态 */</span></span>
</span>    =<span class="ruby"><span class="output"><span class="status">=&gt;</span> tcp_schedule_loss_probe()</span></span>
</code></pre><hr>
<h4 id="安装PTO超时计时器">安装PTO超时计时器</h4>
<pre><code><span class="comment">/* 返回false代表未设置timer, 返回true代表设置了PTO timer */</span>
<span class="keyword">bool</span> tcp_schedule_loss_probe(<span class="keyword">struct</span> sock *sk)
{
    ...  
    <span class="keyword">u32</span> rtt = tp-&gt;srtt &gt;&gt; <span class="number">3</span>;    <span class="comment">/* tp-&gt;srtt存的实际是RFC中SRTT的8倍 */</span>
    ...  
    <span class="comment">/* TLP is only scheduled when next timer event is RTO. */</span>
    <span class="keyword">if</span> (icsk-&gt;icsk_pending != ICSK_TIME_RETRANS)
        <span class="keyword">return</span> <span class="keyword">false</span>;

    <span class="comment">/* Schedule a loss probe in 2*RTT for SACK capable connections
     * in Open state, that are either limited by cwnd or application.
     */</span>
    <span class="keyword">if</span> (sysctl_tcp_early_retrans &lt; <span class="number">3</span> ||     <span class="comment">/* 没开TLP */</span>
        !rtt ||                             <span class="comment">/* 没有RTTsample可用，没法设置PTO */</span>
        !tp-&gt;packets_out ||                 <span class="comment">/* 网络中没有未被确认的数据包，没必要设置PTO */</span>
        !tcp_is_sack(tp) ||                 <span class="comment">/* 不支持SACK选项 */</span>
        !inet_csk(sk)-&gt;icsk_ca_state != TCP_CA_Open)    <span class="comment">/* 只有在open状态才设置PTO */</span>
        <span class="keyword">return</span> <span class="keyword">false</span>;

    <span class="comment">/* Probe timeout is at lease 1.5*rtt + TCP_DELACK_MAX to account
     * for delayed ack when there's one outstanding packet.
     */</span>
    <span class="comment">/* 这段代码完全符合TLP算法逻辑，不解释了 */</span>
    timeout = rtt &lt;&lt; <span class="number">1</span>;
    <span class="keyword">if</span> (tp-&gt;packets_out == <span class="number">1</span>)
        timeout = max_t(<span class="keyword">u32</span>, timeout, (rtt + (rtt &gt;&gt; <span class="number">1</span>) + TCP_DELACK_MAX));
    timeout = max_t(<span class="keyword">u32</span>, timeout, msecs_to_jiffies(<span class="number">10</span>));

    <span class="comment">/* If RTO is shorter, just schedule TLP in its place. */</span>
    <span class="comment">/* PTO = min(PTO, RTO) */</span>
    tlp_time_stamp = tcp_time_stamp + timeout;
    rto_time_stamp = (<span class="keyword">u32</span>)inet_csk(sk)-&gt;icsk_timeout;
    <span class="keyword">if</span> ((s32)(tlp_time_stamp - rto_time_stamp) &gt; <span class="number">0</span>) {
        s32 delta = rto_time_stamp - tcp_time_stamp;
        <span class="keyword">if</span> (delta &gt; <span class="number">0</span>)
            timeout = delta;
    }

    inet_csk_reset_xmit_timer(sk, ICSK_TIME_LOSS_PROBE, timeout, TCP_RTO_MAX);
    <span class="keyword">return</span> <span class="keyword">true</span>;
}

<span class="comment">// 在tcp_write_timer_handler中会根据event的类型，来做相应的处理</span>
<span class="comment">// 如果是PTO超时，则调用tcp_send_loss_probe(sk)来发送TLP探测包</span>
<span class="comment">/* When probe timeout (PTO) fires, send a new segment if one exists, else
 * retransmit the last segment.
 */</span>
void tcp_send_loss_probe(<span class="keyword">struct</span> sock *sk)
{
    ...
    <span class="comment">/*
     * 如果有新数据可以发送，则发新数据作为探测包
     * TLP用了一个push_one=2的trick来区分是正常的发送包，还是loss probe包
     */</span>
    <span class="keyword">if</span> (tcp_send_head(sk) != NULL) {        
        err = tcp_write_xmit(sk, mss, TCP_NAGLE_OFF, <span class="number">2</span>, GFP_ATOMIC);
        goto rearm_timer;
    }

    <span class="comment">/* At most one outstanding TLP retransmission */</span>
    <span class="keyword">if</span> (tp-&gt;tlp_high_seq)
        goto rearm_timer;

    <span class="comment">/* Retransmit last segment */</span>
    skb = tcp_write_queue_tail(sk);
    <span class="keyword">if</span> (WARN_ON(!skb))
        goto rearm_timer;

    <span class="comment">/* 省略一些判断tcp fragment的代码 */</span>

    <span class="comment">/* Probe with zero data doesn't trigger fast recovery */</span>
    <span class="keyword">if</span> (skb-&gt;len &gt; <span class="number">0</span>)
        err = <span class="number">__</span>tcp_retransmit_skb(sk, skb);

    <span class="comment">/* Record snd_nxt for loss detection */</span>
    <span class="keyword">if</span> (!likely(!err))
        tp-&gt;tlp_high_seq = tp-&gt;snd_nxt;

rearm_timer:
    <span class="comment">/* 重新安装RTO超时计时器 */</span>
    inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS, inet_csk(sk)-&gt;icsk_rto, TCP_RTO_MAX);

    <span class="keyword">if</span> (likely(!err))   <span class="comment">/* 增加计数器的值，可以在/proc/net/snmp中看到，netstat -s也可以 */</span>
        NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPLOSSPROBES);

    <span class="keyword">return</span>;
}
</code></pre><hr>
<h4 id="何时结束一个episode">何时结束一个episode</h4>
<pre><code><span class="comment">/* This routine deals with acks during a TLP episodes. */</span>
<span class="keyword">static</span> void tcp_process_tlp_ack(<span class="keyword">struct</span> sock *sk, <span class="keyword">u32</span> ack, <span class="keyword">int</span> flag)
{
    <span class="keyword">struct</span> tcp_sock *tp = tcp_sk(sk);
    <span class="comment">/* 判断TLP是否是多余的，及产生了多余的dupack。逻辑参考RFC */</span>
    <span class="keyword">bool</span> is_tlp_dupack = (ack == tp-&gt;tlp_high_seq) &amp;&amp;   
                         !(flag &amp; (FLAG_SND_UNA_ADVANCED | 
                                  FLAG_NOT_DUP | FLAG_DATA_SACKED));

    <span class="comment">/* Mark the end of TLP episode on receiving TLP dupack or when
     * ack is after tlp_high_seq.
     */</span>
    <span class="comment">/* 可见实现TLP时，选择了最多有一个TLP包发送出去，所以省去了RFC中的TLPRxtOut计数器 */</span>
    <span class="keyword">if</span> (is_tlp_dupack) {
        tp-&gt;tlp_high_seq = <span class="number">0</span>;
        <span class="keyword">return</span>;
    }

    <span class="keyword">if</span> (after(ack, tp-&gt;tlp_high_seq)) {
        tp-&gt;tlp_high_seq = <span class="number">0</span>;
        <span class="comment">/* Don't reduce cwnd if DSACK arrives for TLP retrans */</span>
        <span class="keyword">if</span> (!(flag &amp; FLAG_DSACKING_ACK)) {
            <span class="comment">/* 折腾这么一圈，最关键的就是降cwnd: ssthresh = 0.7*cwnd; cwnd=ssthresh */</span>
            tcp_init_cwnd_reduction(sk, <span class="keyword">true</span>);
            tcp_set_ca_state(sk, TCP_CA_CWR);
            tcp_end_cwnd_reduction(sk);
            tcp_set_ca_state(sk, TCP_CA_Open);
            NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPLOSSPROBERECOVERY);
        }
    }
}
</code></pre><blockquote>
<p>问题：代码什么地方体现了TLP中的Tail ?<br>&lt; 没有dupack收到，自然就认为是Tail了。并不需要想ER那样判断什么packets_out,sacked_out等。<br>这样的问题可能就是跟RTO抢活了。</p>
</blockquote>
<p>最后说一句，TLP的loss probe次数和loss recovery 次数Linux中都有相应的计数器跟踪，<br>分别对应LINUX_MIB_TCPLOSSPROBES，LINUX_MIB_TCPLOSSPROBERECOVERY。</p>
<hr>
<h4 id="TLP与ER的关系">TLP与ER的关系</h4>
<p>一句话总结  </p>
<pre><code>ER解决的是dupack不够用的情况
TLP解决的是没有dupack可用的情况
</code></pre><hr>
<hr>
<h3 id="TLP性能评测数据">TLP性能评测数据</h3>
<p><a href="http://www.net.in.tum.de/fileadmin/TUM/NET/NET-2014-03-1/NET-2014-03-1_01.pdf" target="_blank" rel="external">Measuring TCP Tail Loss Probe Performance</a>中的测试数据显示</p>
<pre><code>TLP <span class="keyword">is</span> able <span class="keyword">to</span> decrease <span class="keyword">the</span> total transfer <span class="property">time</span> <span class="keyword">in</span> high-speed networks <span class="keyword">by</span> <span class="number">38</span>% <span class="keyword">and</span> <span class="keyword">the</span> <span class="property">time</span> <span class="keyword">until</span> data <span class="keyword">is</span> retransmitted <span class="keyword">by</span> <span class="number">81</span>%.
These improvements decrease significantly <span class="keyword">for</span> higher <span class="command">delay</span> links.
</code></pre><p>文章中用到mininet和iptables的方式来模拟网络倒是点醒了我。之前我干嘛非得搭物理机环境啊。T_T  </p>
<p><a href="http://www.sigcomm.org/sites/default/files/ccr/papers/2015/January/0000000-0000000.pdf" target="_blank" rel="external">An Evaluation of Tail Loss Recovery Mechanisms for TCP</a><br>文章评测了RTO Restart(RTOR)、TLP、TLPR三种技术对尾丢包情境性能的影响。都是TLPR得到的性能更好，当然TLP的性能也不赖。<br>RTOR这个技术主要解决的是现有RTO计时器在每次收到ACK后都会重新reset的问题。而RTOR的timer只要设置好，就不会随着dupack的到来而更改了。这个思路刚好解决了我看RTO代码时的疑问，又是脑洞大开啊。<br>看来paper还是要保持看下去啊，跟住研究的脚本才能了解技术的变迁。也能了解技术发展过程中的方方面面，而看内核代码只能了解被社区选用的技术(暂且不去评论社区选的好坏)。 </p>
<hr>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://tools.ietf.org/html/draft-dukkipati-tcpm-tcp-loss-probe-01" target="_blank" rel="external">Tail Loss Probe (TLP): An Algorithm for Fast Recovery of Tail Losses Probe</a><br><a href="http://www.net.in.tum.de/fileadmin/TUM/NET/NET-2014-03-1/NET-2014-03-1_01.pdf" target="_blank" rel="external">Measuring TCP Tail Loss Probe Performance</a><br><a href="http://www.sigcomm.org/sites/default/files/ccr/papers/2015/January/0000000-0000000.pdf" target="_blank" rel="external">An Evaluation of Tail Loss Recovery Mechanisms for TCP</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>Early Retransmit机制解决了dupack较少，无法触发快速重传的问题。<br>但是如果发生了尾丢包，由于尾包后面没有更多的数据包，也就没有办法触发任何的dupack。<br>为解决这种尾丢包的问题，Google的几位大神提出了TLP算法。通过TLP算法，发送一个loss probe包，来产生足够的SACK/FACK的信息来触发RF。根据Google的测试，TLP能够有效的避免较长的RTO超时，进而提高TCP性能。  </p>
]]>
    
    </summary>
    
      <category term="tlp" scheme="http://perthcharles.github.com/tags/tlp/"/>
    
      <category term="rfc" scheme="http://perthcharles.github.com/tags/rfc/"/>
    
      <category term="wiki-network" scheme="http://perthcharles.github.com/categories/wiki-network/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Early Retransmit for TCP]]></title>
    <link href="http://perthcharles.github.com/2015/10/31/wiki-network-tcp-early-retrans/"/>
    <id>http://perthcharles.github.com/2015/10/31/wiki-network-tcp-early-retrans/</id>
    <published>2015-10-31T02:00:21.000Z</published>
    <updated>2015-10-31T10:52:50.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>Early Retransmit(ER)机制的提出主要解决的是在某些特定场景下，没有足够的<br>dupack触发fast retransmit造成的问题。<br>本质上就是通过检测出某些考虑到的特定场景，然后降低触发FR的dupack threshold值。<br>具体需要考虑那些特定场景后续后详细介绍。  </p>
<a id="more"></a>  

<hr>
<h3 id="RFC5827解读">RFC5827解读</h3>
<p>ER要解决的问题:<br>当无法收到足够的dupack时，TCP标准的Fast Retransmit机制无法被<br>触发，只能等待RTO超时才能进行丢包的重传。而RTO超时不管是时间等待代价，还是<br>性能损耗代价都很大。</p>
<p>ER的解决方法:<br>检测出无法收到足够dupack的场景，进而降低dupack threshold来触发快速重传。<br>从而避免等待RTO超时重传，对性能造成较大的损耗。  </p>
<p>TCP中的标准的重传机制:<br>a. 如果超过RTO时间没有收到ACK包，则会触发RTO超时机制。代价就是cwnd=1，慢启动<br>b. 如果收到三个重复dupack，则会触发快速重传。代价是cwnd减半(视congestion算法而定)，拥塞避免</p>
<p>为什么需要等三个重复dupack ？<br>那是因为dupack即可能是丢包造成的，也可能是网络乱序造成的。所以那帮设计标准的<br>牛牛们，一方面拍拍脑袋，一方面测点实验数据定了这么一个值：3。<br>倒也正好吻合了一句古话：事不过三。哈哈</p>
<p>但是阈值设置为三，也存在一些问题。<br>比如当cwnd较小时(比如3)，当发生丢包后，可能就无法产生足够的dupack来触发快速重传。<br>结果就是只能靠RTO超时来重传丢包了。  </p>
<p>那么什么情况下cwnd会比较小呢？</p>
<pre><code><span class="bullet">1. </span>TCP流经过的链路bandwidth-delay product (BDP)很小，就会导致很小的cwnd

<span class="bullet">2. </span>应用层限制，没有足够的数据可以发送，进而导致cwnd一直很小

<span class="bullet">3. </span>由于接收端的接收窗口的限制，导致cwnd很小
</code></pre><hr>
<p>总结下，出现dupack不够的情况：<br>a. cwnd较小<br>b. 发送窗口里大量的数据包都被丢失了<br>c. 在数据发送的尾端发生丢包时  </p>
<p>但是，上面各种极端的case有共同的特点：<br>m. 无法产生足够的dupack<br>n. 没有新的数据包可以发送进入网络  </p>
<p>Early Retransmit机制就是在判断条件m和n都成立后，选择降低触发Fast Retransmit<br>的阈值，来避免只能通过RTO超时重传的问题。  </p>
<hr>
<h4 id="ER算法">ER算法</h4>
<p>名词解释</p>
<pre><code><span class="label">oseg:</span> outstanding segments, segements sent but not yet acknowledged
    并且是没有被累计确认！及内核中的snd_nxt - snd_una

<span class="label">ER_thresh:</span> 启用ER算法后，触发快速重传的dupack个数阈值
</code></pre><p>算法逻辑</p>
<pre><code>ER_thresh = <span class="number">3</span>   <span class="comment">// 等于3，表示还是标准的FR算法</span>
<span class="keyword">if</span> (oseg &lt; <span class="number">4</span> &amp;&amp; <span class="keyword">new</span> data cannot be sent)    <span class="comment">// 如果满足条件，考虑启用ER算法</span>
    <span class="keyword">if</span> (SACK <span class="keyword">is</span> unsupport)                  <span class="comment">// 如果SACK选项不支持，则使用oseg-1作为阈值</span>
        ER_thresh = oseg - <span class="number">1</span>
    elif (SACKed packet == oseg-<span class="number">1</span>)          <span class="comment">// 否则，只有当oseg-1个包被SACK，才能启用ER    </span>
        ER_thresh = oseg - <span class="number">1</span>
</code></pre><p>RFC的算法的算法主要是看个思路，具体算法的实现和逻辑细节还是要看代码。<br>The code in the real world is another cat compared with RFC’s.  </p>
<hr>
<h4 id="开启SACK的必要性">开启SACK的必要性</h4>
<p>总的来说就是更推荐使用SACK选项的方法  </p>
<pre><code>假设发送了三个数据包，S1，S2，S3，但是S2被丢弃了。
当S1到达接收端时，它是按序到达的。接收方可能会delay这个ACK，所以分两种情况讨论：

a. S1的ack被delay了：这种情况下S3的接收会触发一个ACK被发送（因为delay ack
   机制最多能delay一个数据包）。那么此时如果没有带SACK信息，发送发就会收到
   一个正常的ACK，而不是dupack。这样一个dupack都没有收到过，所以也就不会触发
   ER机制，而只能靠RTO超时来进行重传(而且S2和S3都要重传)。
   而如果有SACK信息，<span class="variable">oseg=</span><span class="number">1</span>，进而ER算法就能被启用。
   具体就是：支持SACK，<span class="variable">oseg=</span><span class="number">1</span>, <span class="variable">oseg-1=</span><span class="number">0</span>     =&gt; 启用ER
             不支持SACK，<span class="variable">oseg=</span><span class="number">2</span>, <span class="variable">oseg-1=</span><span class="number">1</span>   =&gt; 无法启用ER，因为没收到任何dupack

b. 如果ack没有被delay，ER都能被启用。
   具体就是：支持SACK，<span class="variable">oseg=</span><span class="number">1</span>, <span class="variable">oseg-1=</span><span class="number">0</span>     =&gt; 启用ER
             不支持SACK，<span class="variable">oseg=</span><span class="number">2</span>, <span class="variable">oseg-1=</span><span class="number">1</span>   =&gt; 启用ER
</code></pre><hr>
<h4 id="ER的问题">ER的问题</h4>
<p>核心意思就是：如果一条TCP流，cwnd一直很小，然后cwnd内发送的数据<br>每次都乱序到达接收端，这样使用ER算法就可能导致较多的spurious retransmit。<br>比如cwnd=2，而每次这两个包都reorder，结果就是发两个数据包，就ER重传一个。</p>
<p>是的，这就叫TCP设计里面常提到的pathological case.  </p>
<p>一种可能的解决办法就是发送一个TCP层data payload=0的包去增加dupack的个数，<br>但是这会一定程度上浪费网络资源。暂时未找到采用了这一思想的TCP实现。  </p>
<hr>
<h4 id="解决降低DupACK阈值可能带来的问题">解决降低DupACK阈值可能带来的问题</h4>
<p>RFC附录提到了三种缓解ER可能带来问题的方法，具体如下<br>a. 判断ER是否发送了多次spurious retransmit数据，利用的手段就是D-SACK技术<br>b. 如果无法判断ER是否发送了spurious retransmit，则可以暴力的设置一个固定值来限制ER被触发的次数<br>c. 当需要触发ER机制时，等待一个固定长度的时间再重传。<br>   Linux默认选用这种方式</p>
<hr>
<hr>
<h3 id="源码分析">源码分析</h3>
<p>下面的源码分析，基于Linux3.10版本  </p>
<hr>
<h4 id="是否开启ER功能">是否开启ER功能</h4>
<p>既然RFC中说了ER还是实验性的，而不是标准。故Linux kernel提供了选项来开启或关闭ER功能。<br>开关的名字是tcp_early_retrans，当然3.10的代码中还有Tail Loss Probe(TLP)的内容，暂时咱可以<br>忽略，之后再写一篇关于TLP的wiki。 </p>
<pre><code>sysctl_tcp_early_retrans (defalut:<span class="number">3</span>)
    <span class="number">0</span> disables ER
    <span class="number">1</span> enables ER
    <span class="number">2</span> enables ER but delays fast recovery <span class="operator">and</span> fast retransmit <span class="keyword">by</span> <span class="operator">a</span>
    <span class="keyword">fourth</span> <span class="operator">of</span> RTT.
    <span class="number">3</span> enables delayed ER <span class="operator">and</span> TLP.
    <span class="number">4</span> enables TLP only.
</code></pre><p>具体的判断函数就是在TCP sock初始化(tcp_init_sock)时，调用tcp_enable_early_retrans()<br>来判断是否开启  </p>
<pre><code>static inline <span class="keyword">void</span> tcp_enable_early_retrans(<span class="class"><span class="keyword">struct</span> <span class="title">tcp_sock</span> *tp)
</span>{
    tp-&gt;do_early_retrans = 
        sysctl_tcp_early_retrans &amp;&amp;         <span class="comment">/* ER开关是否开启 */</span>
        sysctl_tcp_early_retrans &lt; <span class="number">4</span> &amp;&amp;     <span class="comment">/* ER开关是否开启 */</span>
        !sysctl_tcp_thin_dupack &amp;&amp;          <span class="comment">/* 只有关闭thin-dupack才开ER */</span>
        sysctl_tcp_reordering == <span class="number">3</span>;         <span class="comment">/* 需要默认的reordering是3菜开ER */</span>
}
</code></pre><p>根据3.10内核默认的配置，ER是默认开启的，也就是tp-&gt;do_early_retrans默认等于1</p>
<p>当然了，在下面几种情况下也会disable ER<br>a. 应用程序通过setsockopt设置了TCP_THIN_DUPACK<br>b. TCP层发现了reorder，调用tcp_update_reordering尝试更新了reorder值<br>c. 配置了TCP_METRIC_REORDERING值，改变了reordering值</p>
<hr>
<h4 id="判断是否触发FR中ER判断部分">判断是否触发FR中ER判断部分</h4>
<p>tcp_time_to_recoever这个函数就是判断是否该触发FR的函数  </p>
<pre><code><span class="keyword">static</span> <span class="keyword">bool</span> tcp_time_to_recover(<span class="keyword">struct</span> sock *sk, <span class="keyword">int</span> flag)
{
    ...

    <span class="comment">/* Trick#6: TCP early retransmit, per RFC5827. To avoid spurious
     * retransmissions due to small network reorderings, we implement
     * Mitigation A.3 in the RFC and delay the retransmission for a short
     * interval if appropriate.
     */</span>
    <span class="keyword">if</span> (tp-&gt;do_early_retrans &amp;&amp;                     <span class="comment">/* 内核配置是否开启ER */</span>
        !tp-&gt;retrans_out &amp;&amp;                         <span class="comment">/* 当前没有重传数据 */</span>
        tp-&gt;sacked_out &amp;&amp;                           <span class="comment">/* 当前收到了dupack */</span>
        tp-&gt;packets_out &lt; <span class="number">4</span> &amp;&amp;                      <span class="comment">/* packets_out很小, 及RFC oseg &lt; 4 */</span>
        tp-&gt;packets_out &gt;= (tp-&gt;sacked_out + <span class="number">1</span>) &amp;&amp;  <span class="comment">/* dupack个数满足ER/TLP条件 */</span>
        !tcp_may_send_now(sk))                      <span class="comment">/* 没有新数据可发送 */</span>
        <span class="keyword">return</span> !tcp_pause_early_retransmit(sk, flag);   <span class="comment">/* 判断是否等待一段时间再触发ER */</span>

    <span class="keyword">return</span> <span class="keyword">false</span>;   <span class="comment">// 默认返回false，即不进入fast recovery阶段</span>
}
</code></pre><p>主要需要解释的变量，应该是tp-&gt;sacked_out。<br>如果没有开SACK选项，那么该值就是表示dupack的个数。具体可参考tcp_add_reno_sack()函数相关代码<br>如果开启了SACK选项，那么这个值无疑就是表示被SACK的乱序包的个数。具体可参考tcp_sacktag_one()函数相关代码。  </p>
<p>另外，观察仔细的人也许会发现”tp-&gt;packets_out &gt;= (tp-&gt;sacked_out + 1)”与ER的RFC不一致，<br>应该是’==’，而不是’&gt;=’。至于为什么代码中是这样修改的，暂时还不明确。<br>但可以确定的是这个概念是由于TLP算法的引入而改变的，具体的修改发生在<a href="https://github.com/torvalds/linux/commit/6ba8a3b19e764b6a65e4030ab0999be50c291e6c#diff-d06665370d013ab0df986a88d8e3a128" target="_blank" rel="external">Nandita的这个patch中</a>  </p>
<hr>
<h4 id="等四分之一RTT再触发ER">等四分之一RTT再触发ER</h4>
<p>Linux中选择了等待四分之一RTT再触发ER的方式，来缓解降低dupack threshold可能带来的问题。<br>相关代码在tcp_pause_early_retransmit()中  </p>
<pre><code><span class="comment">// 返回false表示立即进入FR，即立即触发ER；返回ture则是等待一个超时时间后再进入FR</span>
<span class="keyword">static</span> <span class="keyword">bool</span> tcp_pause_early_retransmit(<span class="keyword">struct</span> sock *sk, <span class="keyword">int</span> flag)
{
    <span class="keyword">struct</span> tcp_sock *tp = tcp_sk(sk);
    <span class="keyword">unsigned</span> <span class="keyword">long</span> delay;

    <span class="comment">/* Delay early retransmit and entering fast recovery for
     * max(RTT/4, 2msec) unless ack has ECE mark, mo RTT samples
     * available, or RTO is scheduled to fire first.
     */</span>
    <span class="keyword">if</span> (sysctl_tcp_early_retrans &lt; <span class="number">2</span> ||     <span class="comment">/* kernel就没开delay ER的功能*/</span>
        sysctl_tcp_early_retrans &gt; <span class="number">3</span> ||     <span class="comment">/* kernel跟本就没开ER功能(这个地方与do_early_retrans的判断有重复，感觉有点多余) */</span> 
        (flag &amp; FLAG_ECE) ||                <span class="comment">/* ECE mark，ECN-Echo, Explict Congestion Notification */</span>
        !tp-&gt;srtt)                          <span class="comment">/* 没有RTT采样 */</span>
        <span class="keyword">return</span> <span class="literal">false</span>;

    delay = max_t(<span class="keyword">unsigned</span> <span class="keyword">long</span>, (tp-&gt;srtt &gt;&gt; <span class="number">5</span>), msecs_to_jiffiec(<span class="number">2</span>));     <span class="comment">/* 计算delay ER的时间 */</span>
    <span class="keyword">if</span> (!time_after(inet_csk(sk)-&gt;icsk_timeout, (jiffies + delay)))         <span class="comment">/* 如果RTO先超时 */</span>
        <span class="keyword">return</span> <span class="literal">false</span>;

    <span class="comment">// 设置ER超时计时器</span>
    inet_csk_reset_xmit_timer(sk, ICSK_TIME_EARLY_RETRANS, delay, TCP_RTO_MAX);
    <span class="keyword">return</span> <span class="literal">true</span>;
}
</code></pre><p>ICSK_TIME_EARLY_RETRANS超时后，会调用tcp_resume_early_retransmit(sk)  </p>
<pre><code><span class="keyword">void</span> tcp_resume_early_retransmit(<span class="keyword">struct</span> sock *sk)
{
    strcut tcp_sock *tp = tcp_sk(sk);

    tcp_rearm_rto(sk);  <span class="comment">// 重设RTO计时器</span>

    <span class="comment">/* Stop if ER is disabled after the delayed ER timer is sheduled */</span>
    <span class="keyword">if</span> (!tp-&gt;do_early_retrans)
        <span class="keyword">return</span>;

    <span class="comment">// 进入快速重传阶段</span>
    tcp_enter_recovery(sk, <span class="keyword">false</span>);
    tcp_update_scoreboard(sk, <span class="number">1</span>);
    tcp_xmit_retransmit_queue(sk);
}
</code></pre><hr>
<p>说一句题外话，TCP的具体设计经常需要考虑很多极端的case。<br>这类case，以前一般也就称之为corner case。但是越看RFC，越发现corner已经不足以<br>形容TCP设计的严谨性了，只能用pathological了。T_T</p>
<hr>
<h3 id="参考资料">参考资料</h3>
<p><a href="http://tools.ietf.org/html/rfc5827" target="_blank" rel="external">RFC 5827</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>Early Retransmit(ER)机制的提出主要解决的是在某些特定场景下，没有足够的<br>dupack触发fast retransmit造成的问题。<br>本质上就是通过检测出某些考虑到的特定场景，然后降低触发FR的dupack threshold值。<br>具体需要考虑那些特定场景后续后详细介绍。  </p>
]]>
    
    </summary>
    
      <category term="tcp" scheme="http://perthcharles.github.com/tags/tcp/"/>
    
      <category term="rfc" scheme="http://perthcharles.github.com/tags/rfc/"/>
    
      <category term="wiki-network" scheme="http://perthcharles.github.com/categories/wiki-network/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[在Linux上探测TCP的内部状态]]></title>
    <link href="http://perthcharles.github.com/2015/10/28/inspecting-internal-tcp-state/"/>
    <id>http://perthcharles.github.com/2015/10/28/inspecting-internal-tcp-state/</id>
    <published>2015-10-28T13:28:11.000Z</published>
    <updated>2015-10-28T14:27:48.000Z</updated>
    <content type="html"><![CDATA[<p>发现一篇使用ss获取TCP内部状态信息的好文，不由的记录一笔。<br>并结合之前会的方法适当总结总结。<br><a id="more"></a>  </p>
<hr>
<h3 id="Inspecting_Internal_TCP_State_on_Linux"><a href="https://blogs.janestreet.com/inspecting-internal-tcp-state-on-linux/" target="_blank" rel="external">Inspecting Internal TCP State on Linux</a></h3>
<p>这种好文当然是推荐去读原文了，这里对文章中的方法只做简单摘要。<br>而这类相似方法还有哪些，以及各自的优缺点可以看看下一节的总结。  </p>
<pre><code><span class="comment">// 可查看尽量多的显示socket相关的内部信息  </span>
<span class="preprocessor"># ss -eipn  </span>

Internally, ss uses the tcp_diag kernel module to extract
information (<span class="keyword">this</span> is done via an<span class="constant"> AF_NETLINK </span>socket).

<span class="comment">// 通过crash根据sk的内存地址，获取更多的sk结构体item信息</span>
<span class="preprocessor"># sudo crash -e emacs</span>

crash &gt; <span class="keyword">struct</span> tcp_sock.rcv_nxt,snd_una,reordering ffff8802305a0800
</code></pre><hr>
<h3 id="总结">总结</h3>
<p>目前掌握的获取TCP内部状态的方法，这里讨论的方法都是不需要额外在内核中做开发的：<br>a. 使用tcp_probe内核模块<br>改改tcp_probe几乎可以获取TCP内部的任何状态<br>具体怎么使用tcp_probe模块，在之前的<a href="http://perthcharles.github.io/2014/12/19/tcp-probe-intro/" target="_blank" rel="external">这篇博客</a>中有详细的介绍。  </p>
<pre><code>优点(考虑适当自定制该模块)：
    1. 功能性：可查看TCP流的几乎所有的内部状态
    2. 灵活性：定制一次必须重编一次模块
缺点：
    1. 功能性：不适合线上设备使用，大量不同流的信息混在一起简直是灾难(如何有效的使用过滤策略是一个好问题)
    2. 可用性：如果没有kernel-devel包，无法自定制编译使用内核模块
</code></pre><p>b. 使用systemtap脚本  </p>
<pre><code>优点：
    <span class="number">1</span>. 功能性：几乎可以探测TCP流在任何处理逻辑(内联函数是一个痛点)处的信息
    <span class="number">2</span>. 灵活性：方便设置过滤策略，(相对tcp_probe而言)可方便的统计出想要的信息。
       不管是通过指定脚本参数，还是直接修改脚本，都比修改tcp_probe内核模块方便
缺点：
    <span class="number">1</span>. 可用性：依赖kernel-devel, kernel-debuginfo, kernel-debuginfo-<span class="built_in">common</span>包
       而为了避免暴露自定制内核的内部实现，这些包默认都是不安装的
</code></pre><p>c. ss+crash<br>如果只需要ss默认支持的信息，那这种方法当然是最佳的。<br>但可信的就是ss默认支持的信息，还是太少，因此可能需要crash来补充  </p>
<pre><code>优点：
    <span class="number">1</span>. 功能性：在仅需要<span class="literal">ss</span>默认支持的信息时，最实用。只要安装<span class="literal">ss</span>软件即可
       本质上<span class="literal">ss</span>输出的信息，是内核统计的，<span class="literal">ss</span>只是一个输出工具而已
缺点：
    <span class="number">1</span>. 功能性：受限于内核统计的信息，受限与<span class="literal">ss</span>工具的选择的输出信息
    <span class="number">2</span>. 可用性：如果试图通过<span class="literal">ss</span>得到的sk内存地址，利用crash进一步获得信息，则需要内核image能找到。
       这点在线上设备上也显然是不现实的
</code></pre><p>不过受ss+crash这种方法的启发，既然能拿到sk结构体的内存地址，有没有更简单，<br>方便的方法来获取sk内部item的值呢？<br>如果大家有更好的方法，非常欢迎留言交流。  </p>
]]></content>
    <summary type="html">
    <![CDATA[<p>发现一篇使用ss获取TCP内部状态信息的好文，不由的记录一笔。<br>并结合之前会的方法适当总结总结。<br>]]>
    
    </summary>
    
      <category term="ss" scheme="http://perthcharles.github.com/tags/ss/"/>
    
      <category term="crash" scheme="http://perthcharles.github.com/tags/crash/"/>
    
      <category term="networking" scheme="http://perthcharles.github.com/categories/networking/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[阅读周记(第三期)]]></title>
    <link href="http://perthcharles.github.com/2015/10/26/wiki-weekly-readlist-20151026/"/>
    <id>http://perthcharles.github.com/2015/10/26/wiki-weekly-readlist-20151026/</id>
    <published>2015-10-26T13:30:23.000Z</published>
    <updated>2015-11-02T14:49:30.000Z</updated>
    <content type="html"><![CDATA[<hr>
<h2 id="DigitalOcean如何在红海市场做用户增长"><a href="https://strace.co/cn/post/growth-hacking-digitalocean.html" target="_blank" rel="external">DigitalOcean如何在红海市场做用户增长</a></h2>
<pre><code>摘要：
    1. 先确立独特点，研究增长计划  
    2. 做产品而非服务，产品更容易扩张  
    3. 加入创业加速器，获得初期用户和商业关系网络  
    4. 漂亮的增长数字和对未来清晰的定位，是打动顶级风投的亮点
    5. Freemium模式
    6. 获取并了解前100个客户(找一个高水准的技术聚会是一个很好的切入点)
    7. 针对高智商的开发者用户的口碑营销和社区营销
    8. 测量各个推广渠道的转化率
点评：
    1. 学到一个新词：<span class="function">freemium</span>(免费增值),即通过为少部分有更高需求的用户提供增值服务赢利
    2. digitalocean在linode已经拥有大量客户的时候，才进入VPS服务器这个红海市场，
       依然能做起来。至今成为行业第二，足以说明它的战术和战略都是很成功的。
       找机会得去体验一把digitalocean。
</code></pre><a id="more"></a>  

<hr>
<h2 id="好的架构是进化来的，不是设计来的"><a href="http://news.oneapm.com/shenjian-oneapm-course/?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io" target="_blank" rel="external">好的架构是进化来的，不是设计来的</a></h2>
<pre><code>摘要：
    <span class="number">1.</span> 创业初期，成本是设计架构的重要因素
    <span class="number">2.</span> 在每一个阶段，找到对应该阶段网站架构所面临的问题，然后在不断解决这些问题的过程中，
       真个战略的架构就是在不断的演进了
    <span class="number">3.</span> 第一阶段：<span class="literal">ALL</span> <span class="keyword">IN</span> ONE。特点：单机系统，程序耦合，逻辑核心是CURD
    <span class="number">4.</span> 中等规模：流量跨过十万阶段，数据库成为瓶颈。特点：分布式系统，动静分离，读写分离
    <span class="number">5.</span> 进一步：静态数据使用CDN服务，MVC结构，负载均衡
    <span class="number">6.</span> 大流量：将整个windows技术体系转向了Java体系
    <span class="number">7.</span> 高可用：进一步垂直拆分，分层抽象，水平拆分
    <span class="number">8.</span> 技术：反向代理，智能DNS
    <span class="number">9.</span> 当架构变成蜘蛛网，人肉已很难搞定
点评：
    <span class="number">1.</span> 架构这个东西不是想出来的，而是做出来的
    <span class="number">2.</span> 同时，做也要聪明的做。前期好的设计，好的远见很重要
    <span class="number">3.</span> learn <span class="keyword">to</span> <span class="keyword">do</span>(学会去做), learning <span class="keyword">by</span> doing(从实践中学)
</code></pre><hr>
<h2 id="The_50_Most_Popular_MOOCs_of_All_Time"><a href="http://www.onlinecoursereport.com/the-50-most-popular-moocs-of-all-time/" target="_blank" rel="external">The 50 Most Popular MOOCs of All Time</a></h2>
<pre><code>摘要：
    <span class="number">50.</span> Internet History, Technology, <span class="operator">and</span> Security / University <span class="operator">of</span> Michigan
    <span class="number">39.</span> Social Network Analysis / University <span class="operator">of</span> Michigan
    <span class="number">37.</span> Introduction <span class="built_in">to</span> Databases / Stanford University
    <span class="number">34.</span> Statistics – Making Sense <span class="operator">of</span> Data / University <span class="operator">of</span> Toronto
    <span class="number">33.</span> Critical Thinking <span class="operator">in</span> Global Challenges / The University <span class="operator">of</span> Edinburgh
    <span class="number">29.</span> A History <span class="operator">of</span> <span class="operator">the</span> World Since <span class="number">1300</span> / Princeton University
    <span class="number">28.</span> Justice / Harvard University
    <span class="number">23.</span> Data Analysis / Johns Hopkins Bloomberg School
    <span class="number">20.</span> Introduction <span class="built_in">to</span> Financial Accounting / University <span class="operator">of</span> Pennsylvania / Wharton
    <span class="number">17.</span> Financial Markets / Yale University
    <span class="number">16.</span> Computational Investing, Part I / Georgia Institute <span class="operator">of</span> Technology
    <span class="number">9.</span> Think Again: How <span class="built_in">to</span> Reason <span class="operator">and</span> Argue / Duke University
    <span class="number">2.</span> Introduction <span class="built_in">to</span> Philosophy / University <span class="operator">of</span> Edinburgh
</code></pre><hr>
<h2 id="相信技术的力量，出门问问获谷歌投资"><a href="http://www.infoq.com/cn/news/2015/10/chumenwenwen-the-new-milestone" target="_blank" rel="external">相信技术的力量，出门问问获谷歌投资</a></h2>
<pre><code>点评：了解了解出门问问
</code></pre><p>相关阅读:<br><a href="http://www.ifanr.com/378180" target="_blank" rel="external">出门问问李志飞：我们想做 Google 那样的公司</a><br><a href="http://www.csdn.net/article/2014-11-13/2822638-From-Hardcore-Coder-to-Startup-TechManager" target="_blank" rel="external">雷欣：从技术极客到核心管理的秘密</a><br><a href="http://www.huxiu.com/article/42572/1.html" target="_blank" rel="external">出门问问CEO李志飞: 那些牛逼的工程师适合创业吗?</a>  </p>
<hr>
<h2 id="Five_Things_Old_Programmers_Should_Remember"><a href="https://medium.com/@garywiz/five-things-old-programmers-need-to-remember-e78caf0b0973?imm_mid=0daeb8&amp;cmp=em-prog-na-na-newsltr_20151024#.bpqamw9yz" target="_blank" rel="external">Five Things Old Programmers Should Remember</a></h2>
<pre><code>摘要：
    <span class="number">1.</span> The industry I joined was an industry <span class="keyword">of</span> specialists.
       Commitment <span class="keyword">and</span> discipline were a requirement. 
    <span class="number">2.</span> <span class="keyword">If</span> I may be so bold, it was a mistake <span class="keyword">for</span> you <span class="keyword">to</span> accept promotion.
       Commanding a starship <span class="keyword">is</span> your first, best destiny;
       anything <span class="keyword">else</span> <span class="keyword">is</span> a waste <span class="keyword">of</span> material. — Spock (引自星际迷航)
    <span class="number">3.</span> It’s what you signed up <span class="keyword">for</span>, <span class="keyword">and</span> <span class="keyword">if</span> you really want <span class="keyword">to</span> contribute,
       you need <span class="keyword">to</span> rope <span class="keyword">in</span> the demons <span class="keyword">of</span> getting old <span class="keyword">and</span> be different
       than most everybody you grew up <span class="keyword">with</span>. Go out <span class="keyword">on</span> a limb, <span class="keyword">and</span> enjoy
       the fact that life <span class="keyword">is</span> <span class="keyword">not</span> ending, it <span class="keyword">is</span> always just beginning.
    <span class="number">4.</span> Just <span class="keyword">like</span> any accessible sport, most people are amateurs,
       a few have promise, <span class="keyword">and</span> very few reach the Olympics.
    <span class="number">5.</span> Your Health <span class="keyword">Is</span> Your <span class="keyword">New</span> Business Partner.
点评：
    <span class="number">1.</span> 选你所爱，爱你所选
    <span class="number">2.</span> <span class="keyword">do</span> one thing, <span class="keyword">do</span> onething perfectly
    <span class="number">3.</span> 安心做技术人，忌浮躁。太多的潜力项目、公司都是被半吊子的技术型管理人员搞挂的。
       <span class="keyword">Do</span> <span class="keyword">not</span> be one <span class="keyword">of</span> them !
    <span class="number">4.</span> 这篇博文给国内一种<span class="string">"程序员是年轻人的职业"</span>的论调一记响亮的耳光。
       博主和评论中的诸多older coders都非常高龄。
    <span class="number">5.</span> 正确看待你的工作，用心认真对待它。它是你的事业，也是一生中重要的标记，可以引以为豪的标记。
</code></pre><hr>
<h2 id="过一过ArchSummit的PPT">过一过ArchSummit的PPT</h2>
<p>百度云盘地址: <a href="http://pan.baidu.com/s/1hqngEqg" target="_blank" rel="external">http://pan.baidu.com/s/1hqngEqg</a></p>
<hr>
<h2 id="不要使用公共DNS服务"><a href="http://mawenjian.net/p/281.html" target="_blank" rel="external">不要使用公共DNS服务</a></h2>
<p>多一些看待公共DNS服务的视角</p>
<hr>
<h2 id="过一个QCon的PPT">过一个QCon的PPT</h2>
<p>重点了解跟网络相关的部分，无论网络运维、网络虚拟化、网络加速、网络架构、网络加速。  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<h2 id="DigitalOcean如何在红海市场做用户增长"><a href="https://strace.co/cn/post/growth-hacking-digitalocean.html" target="_blank" rel="external">DigitalOcean如何在红海市场做用户增长</a></h2>
<pre><code>摘要：
    1. 先确立独特点，研究增长计划  
    2. 做产品而非服务，产品更容易扩张  
    3. 加入创业加速器，获得初期用户和商业关系网络  
    4. 漂亮的增长数字和对未来清晰的定位，是打动顶级风投的亮点
    5. Freemium模式
    6. 获取并了解前100个客户(找一个高水准的技术聚会是一个很好的切入点)
    7. 针对高智商的开发者用户的口碑营销和社区营销
    8. 测量各个推广渠道的转化率
点评：
    1. 学到一个新词：<span class="function">freemium</span>(免费增值),即通过为少部分有更高需求的用户提供增值服务赢利
    2. digitalocean在linode已经拥有大量客户的时候，才进入VPS服务器这个红海市场，
       依然能做起来。至今成为行业第二，足以说明它的战术和战略都是很成功的。
       找机会得去体验一把digitalocean。
</code></pre>]]>
    
    </summary>
    
      <category term="digitalocean" scheme="http://perthcharles.github.com/tags/digitalocean/"/>
    
      <category term="wiki-阅读周记" scheme="http://perthcharles.github.com/categories/wiki-%E9%98%85%E8%AF%BB%E5%91%A8%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[阅读周记(第二期)]]></title>
    <link href="http://perthcharles.github.com/2015/10/19/wiki-weekly-readlist-20151019/"/>
    <id>http://perthcharles.github.com/2015/10/19/wiki-weekly-readlist-20151019/</id>
    <published>2015-10-19T02:57:45.000Z</published>
    <updated>2015-10-26T01:31:07.000Z</updated>
    <content type="html"><![CDATA[<hr>
<h2 id="从学渣到学霸_-_我的100天阅读简史"><a href="http://mp.weixin.qq.com/s?__biz=MjM5OTA3MjUwMA==&amp;mid=400032224&amp;idx=1&amp;sn=335f870597a6f888d219daf687357fdd&amp;scene=2&amp;srcid=1018D0eWR4z8X0yo9xV2Gg0s&amp;from=timeline&amp;isappinstalled=0#rd" target="_blank" rel="external">从学渣到学霸 - 我的100天阅读简史</a></h2>
<pre><code>点评：
    1. 行动力是第一的，有想法就要去实际动手。作者就是一个行动派，敬佩！  
    2. 每天早上起床后的时间，也是可以利用的。对我个人而言，早睡一会，早起一个小时。然后利用这一个小时，花几个番茄钟去读书！
    3. 对于不同的性质的书，要采用不同的方式阅读  
    4. 自己能够成为一个行动派？真正成为一个爱读书的人？纸上得来终觉浅，绝知此事要躬行。  
    5. 每读完一段书，写一个短评(如125字)去总结，是一个便于梳理知识的好方法。  
</code></pre><a id="more"></a>  

<hr>
<h2 id="一个可以显示Linux命令运行进度的伟大工具"><a href="https://linux.cn/article-4741-weibo.html" target="_blank" rel="external">一个可以显示Linux命令运行进度的伟大工具</a></h2>
<pre><code>摘要：
    <span class="number">1</span>. Coreutils Viewer（cv）是一个简单的程序，它可以用于显示任何核心组件命令
    （如：<span class="keyword">cp</span>、mv、dd、tar、gzip、gunzip、<span class="keyword">cat</span>、<span class="keyword">grep</span>、fgrep、egrep、cut、<span class="built_in">sort</span>、xz、exiting）的进度
点评：
    <span class="number">1</span>. 不过感觉没那么实用，就指放在这里做个备忘吧  
</code></pre><hr>
<h2 id="网易163/126邮箱过亿数据泄漏"><a href="http://www.wooyun.org/bugs/wooyun-2015-0147763" target="_blank" rel="external">网易163/126邮箱过亿数据泄漏</a></h2>
<pre><code>点评：
    网络世界无安全啊，还是忧伤的去改相关密码吧。  
</code></pre><hr>
<h2 id="What’s_New_in_CPUs_Since_the_80s_and_How_Does_It_Affect_Programmers?"><a href="http://danluu.com/new-cpu-features/" target="_blank" rel="external">What’s New in CPUs Since the 80s and How Does It Affect Programmers?</a></h2>
<pre><code>摘要：
    <span class="number">1.</span> Memory/Caches: The solution <span class="keyword">to</span> <span class="keyword">the</span> problem <span class="keyword">of</span> having relatively slow memory has been <span class="keyword">to</span> add
       caching, which provides fast access <span class="keyword">to</span> frequently used data, <span class="keyword">and</span> prefetching, which preloads
       data <span class="keyword">into</span> caches <span class="keyword">if</span> <span class="keyword">the</span> access pattern <span class="keyword">is</span> predictable.  
    <span class="number">2.</span> TLBs(CPU中最重要的特殊功能的cache):
        a. TLBs, which are caches <span class="keyword">for</span> virtual memory lookups(done via
           a <span class="number">4</span>-level page table structure <span class="function_start"><span class="keyword">on</span></span> x86). 
        b. If you use <span class="number">4</span>k pages, <span class="keyword">the</span> limited size <span class="keyword">of</span> TLBs limits <span class="keyword">the</span> amount
           <span class="keyword">of</span> memory you can address <span class="keyword">without</span> incurring a TLB miss.
        c. X87 also supports <span class="number">2</span>MB <span class="keyword">and</span> <span class="number">1</span>GB pages; <span class="keyword">some</span> applications will
           benefits a lot <span class="keyword">from</span> using larger page sizes.
        d. Also, <span class="keyword">first</span>-level caches are ususally limited <span class="keyword">by</span> <span class="keyword">the</span> page size <span class="keyword">times</span>
           <span class="keyword">the</span> associativity <span class="keyword">of</span> <span class="keyword">the</span> cache. 
           Haswell has an <span class="number">8</span>-way associative cache <span class="keyword">and</span> <span class="number">4</span>kB pages. Its L1 data cache
           <span class="keyword">is</span> `<span class="number">8</span> * <span class="number">4</span> kB = <span class="number">32</span>kB.
    <span class="number">3.</span> Out <span class="keyword">of</span> Order Execution/Serialization: For a couple decades now, x86 chips
       have been able <span class="keyword">to</span> speculatively execute <span class="keyword">and</span> re-order execution(<span class="keyword">to</span> avoid
       blocking <span class="function_start"><span class="keyword">on</span></span> a single stalled resource).
    <span class="number">4.</span> Memory/Concurrency(即多核):
        a. <span class="keyword">if</span> core0 <span class="keyword">and</span> core1 interact, there’s no guarantee <span class="keyword">that</span> their interaction <span class="keyword">is</span> ordered.
        b. To make a sequence atomic, we can use xchg <span class="keyword">or</span> cmpxchg, which are always locked <span class="keyword">as</span> compare-<span class="keyword">and</span>-swap primitives.
    <span class="number">5.</span> Memory/Non-Temporal Stores/Write-Combine Memory:
        a. UC memory: uncacheable memory
        b. WC: <span class="command">write</span> combine
        c. WC <span class="keyword">is</span> kind <span class="keyword">of</span> eventually consistent UC. Writes have <span class="keyword">to</span> eventually
           make <span class="keyword">it</span> <span class="keyword">to</span> memory, <span class="keyword">but</span> they can be buffered internally.
    <span class="number">6.</span> Memory/NUMA:
        a. Non-uniform memory access, <span class="keyword">where</span> memory latencies <span class="keyword">and</span> bandwidth are
           different <span class="keyword">for</span> different processors.
        b. The takeaway here <span class="keyword">is</span> <span class="keyword">that</span> threads <span class="keyword">that</span> share memory should be
           <span class="function_start"><span class="keyword">on</span></span> <span class="keyword">the</span> same socket, <span class="keyword">and</span> a memory-mapped I/O heavy thread should
           make sure <span class="keyword">it</span>'s <span class="function_start"><span class="keyword">on</span></span> <span class="keyword">the</span> socket <span class="keyword">that</span>'s colsest <span class="keyword">to</span> <span class="keyword">the</span> I/O device <span class="keyword">it</span>'s
           talking <span class="keyword">to</span>.
    <span class="number">7.</span> Context Switches/Syscalss:
        a. A side effect <span class="keyword">of</span> all <span class="keyword">the</span> caching <span class="keyword">that</span> modern cores have <span class="keyword">is</span> <span class="keyword">that</span>
           context switches are expensive, which causes syscalls <span class="keyword">to</span> be expensive.
        b. The high cost <span class="keyword">of</span> syscalls <span class="keyword">is</span> <span class="keyword">the</span> reason people have switched <span class="keyword">to</span> using
           batched versions <span class="keyword">of</span> syscalls <span class="keyword">for</span> high-performance code (e.g., epoll, <span class="keyword">or</span> recvmmsg)
           <span class="keyword">and</span> <span class="keyword">the</span> reason <span class="keyword">that</span> perple who need very high performance I/O often use userspace I/O
           stacks.
        c. More generally, <span class="keyword">the</span> cost <span class="keyword">of</span> context switches <span class="keyword">is</span> why high-performance code
           <span class="keyword">is</span> often thread-per-core(<span class="keyword">or</span> even single threaded <span class="function_start"><span class="keyword">on</span></span> a pinned thread) <span class="keyword">and</span> <span class="keyword">not</span>
           thread-per-logical-task.
    <span class="number">8.</span> SIMD(Single Instruction Multiple Data):
        a. Since <span class="keyword">it</span>’s common <span class="keyword">to</span> want <span class="keyword">to</span> do <span class="keyword">the</span> same operation multiple <span class="keyword">times</span>,
           Intel added instructions <span class="keyword">that</span> will let you operate <span class="function_start"><span class="keyword">on</span></span> a <span class="number">128</span>-bit
           chunk <span class="keyword">of</span> data <span class="keyword">as</span> <span class="number">2</span> <span class="number">64</span>-bit chunks, <span class="number">4</span> <span class="number">32</span>-bit chunks, <span class="number">8</span> <span class="number">16</span>-bit chunks, etc. 
        b. It’s pretty common <span class="keyword">to</span> <span class="keyword">get</span> a <span class="number">2</span>x-<span class="number">4</span>x speedup <span class="keyword">from</span> using SIMD instructions;
           <span class="keyword">it</span>’s definitely worth looking <span class="keyword">into</span> <span class="keyword">if</span> you’ve got a computationally heavy workload.

点评：
    <span class="number">1.</span> Out <span class="keyword">of</span> Order Execution/Serialization:
        a. 乱序的最大限度，受限于CPU OFO buffer大小
        b. 乱序执行是对分支预测技术的一个重要支撑
        c. 乱序并不是意味着没有约束，读后读，读后写，写后读都是限制乱序执行是否允许的
    <span class="number">2.</span> Memory/Concurrency(即多核):
        a. MESI protocol是一个解决多核访问时，cache不一致问题的重要知识点
           M: Modified  E: Exclusive  S: Shared  I: Invalid
    <span class="number">3.</span> NUMA的由来：cache一致性问题(多核之间交互一致性信息开销大，复杂），从而让每个socket负责
       一个region的memory。因此形成了NUMA结构。但NUMA结构的缺点也就很明显：在跨socket访问memory
       时，延迟开销较大。
    <span class="number">4.</span> GPU(Graphical Processing Units): 就是数量取胜。通过大量的负责专用计算用途(浮点计算，矩阵运算)的
       小核组成。  
    <span class="number">5.</span> Branches: 作者的意思是说分支预测其实开销已经很小了。
        一方面，Haswell架构的CPU，分支预测错误的额外开销也就<span class="number">14</span>个cycle；
        同时，分支预测错误率现在也已经很低了（作者通过perf stat测试了常用程序后得出的结论），即分支预测已经做的很好了，预测成功的概率很大了。
    <span class="number">6.</span> Alignment: 强迫症似得去对齐page-size现在已经没有必要了，CPU已经对这类代码优化的很好了。
       现在还强制的区对其可能还会造成性能损耗。  
    <span class="number">7.</span> Self-modifying code: 暂时不动self-modifying code是个神马意思。待查。。。
</code></pre><hr>
<h2 id="Use_multiple_CPU_Cores_with_your_Linux_commands_—_awk,_sed,_bzip2,_grep,_wc,_etc-"><a href="http://www.rankfocus.com/use-cpu-cores-linux-commands/" target="_blank" rel="external">Use multiple CPU Cores with your Linux commands — awk, sed, bzip2, grep, wc, etc.</a></h2>
<pre><code>点评：目前的功能内容，不太设计超大文件的文本处理，所以现在还可以接收。
    这篇文章提到的parallel用法确实挺吸引人的，所以放在这里备忘。  
    不过针对我个人的情况，如果偶尔需要处理超大文件，或许可以用下面这个思路解决：
    首先通过<span class="built_in">split</span>命令将大文件切割，然后在用多进程去利用多核进行处理。  
相关：http:<span class="comment">//blog.sciencenet.cn/blog-548663-812884.html</span>
</code></pre><hr>
<h2 id="手把手教你用Strace诊断问题"><a href="http://huoding.com/2015/10/16/474" target="_blank" rel="external">手把手教你用Strace诊断问题</a></h2>
<pre><code>摘要：
    1. 运行<span class="attribute">top</span>时,按<span class="attr_selector">[1]</span>打开CPU列表,按<span class="attr_selector">[shift+p]</span>以CPU排序
    2. 内核态的函数调用跟踪用<span class="attr_selector">[strace]</span>,用户态的函数调用跟踪用<span class="attr_selector">[ltrace]</span>
    3. strace使用实例
        # strace -<span class="tag">p</span> &lt;PID&gt;               <span class="comment">// 使用strace跟踪某个进程的系统调用，不过就等着被刷屏吧</span>
        # strace -cp &lt;PID&gt;              <span class="comment">// 使用[-c]选项可以汇总各个操作的总耗时，调用次数等信息，很实用</span>
        # strace -T -e clone -<span class="tag">p</span> &lt;PID&gt;   <span class="comment">// -T选项获得操作实际消耗的时间，-e指定单独跟踪后一个函数</span>
点评：
    1. 文章介绍的strace选项很少，但排查问题的思路却很值得学习
    2. 问题排查思路：
        <span class="tag">a</span>. 通过<span class="attribute">top</span>找到系统资源瓶颈，进而找到对应的进程(比如如果系统CPU消耗较高，就找到CPU最高的进程)
        <span class="tag">b</span>. CPU的消耗是需要区分内核态<span class="attr_selector">[sy]</span>还是用户态<span class="attr_selector">[us]</span>的，根据此来决定是通过strace还是ltrace来排查
        c. 使用strace排查问题时，先使用-c来找到进程中的最耗时的系统调用
        d. 然后使用-T, -e来针对具体的函数调用来排查
        e. 最终结合真实的业务代码，来定位前面排查的函数对应的代码部分
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<hr>
<h2 id="从学渣到学霸_-_我的100天阅读简史"><a href="http://mp.weixin.qq.com/s?__biz=MjM5OTA3MjUwMA==&amp;mid=400032224&amp;idx=1&amp;sn=335f870597a6f888d219daf687357fdd&amp;scene=2&amp;srcid=1018D0eWR4z8X0yo9xV2Gg0s&amp;from=timeline&amp;isappinstalled=0#rd" target="_blank" rel="external">从学渣到学霸 - 我的100天阅读简史</a></h2>
<pre><code>点评：
    1. 行动力是第一的，有想法就要去实际动手。作者就是一个行动派，敬佩！  
    2. 每天早上起床后的时间，也是可以利用的。对我个人而言，早睡一会，早起一个小时。然后利用这一个小时，花几个番茄钟去读书！
    3. 对于不同的性质的书，要采用不同的方式阅读  
    4. 自己能够成为一个行动派？真正成为一个爱读书的人？纸上得来终觉浅，绝知此事要躬行。  
    5. 每读完一段书，写一个短评(如125字)去总结，是一个便于梳理知识的好方法。  
</code></pre>]]>
    
    </summary>
    
      <category term="读书" scheme="http://perthcharles.github.com/tags/%E8%AF%BB%E4%B9%A6/"/>
    
      <category term="CPU" scheme="http://perthcharles.github.com/tags/CPU/"/>
    
      <category term="strace" scheme="http://perthcharles.github.com/tags/strace/"/>
    
      <category term="wiki-阅读周记" scheme="http://perthcharles.github.com/categories/wiki-%E9%98%85%E8%AF%BB%E5%91%A8%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[阅读周记(第一期)]]></title>
    <link href="http://perthcharles.github.com/2015/10/15/wiki-weekly-readlist-20151015/"/>
    <id>http://perthcharles.github.com/2015/10/15/wiki-weekly-readlist-20151015/</id>
    <published>2015-10-15T05:15:52.000Z</published>
    <updated>2015-10-19T01:55:45.000Z</updated>
    <content type="html"><![CDATA[<hr>
<h2 id="Save_Some_Bandwidth_By_Turning_Off_TCP_Timestamps"><a href="http://highscalability.com/blog/2015/10/14/save-some-bandwidth-by-turning-off-tcp-timestamps.html" target="_blank" rel="external">Save Some Bandwidth By Turning Off TCP Timestamps</a></h2>
<pre><code>想法: tcp timestamp选项会引入额外的<span class="number">12</span>字节的包头开销，因此关闭tcp timestamp选项理论上能够少量的提高有效数据的吞吐率
评测: 使用qperf benchmark评测关闭tcp timestamp后，能提升大约<span class="number">1</span>%的吞吐率
      对于<span class="number">10</span>GE NIC，关闭timestamp能将下载速度从<span class="number">9370</span>Mbits/s提升至<span class="number">9460</span>Mbits/s
点评: 关闭timestamp正常情况下确实能提高有效数据的吞吐率，但在某些情况下可能就不那么理想了。
      比如timestamp提出的初衷之一就是解决RTT测量不准，导致spurious retransmission的情况。如果关闭timestamp导致了更多的RTO，则肯定是划不来的。  
      正如文中建议的：
        Results show <span class="keyword">that</span> <span class="keyword">it</span> <span class="keyword">is</span> reasonable <span class="keyword">to</span> turn off timestamps <span class="function_start"><span class="keyword">on</span></span> <span class="number">10</span>GE interfaces, 
        <span class="keyword">but</span> keep <span class="keyword">in</span> mind <span class="keyword">that</span> <span class="keyword">it</span> should be performed only <span class="keyword">in</span> low latency networks.
      使用<span class="number">10</span>GE网卡是为了<span class="number">1</span>%的提升效果更明显，强调低延迟是因为RTO有系统最小值<span class="number">200</span>ms限制。低延迟下更难出现spurious retransmission
</code></pre><p>相关阅读：<br><a href="http://serverfault.com/questions/566889/is-it-fine-to-turn-off-tcp-window-scaling-and-tcp-timestamps-on-server" target="_blank" rel="external">Is it fine to turn off tcp window scaling and tcp timestamps on server?</a><br><a href="http://stackoverflow.com/questions/7880383/what-benefit-is-conferred-by-tcp-timestamp" target="_blank" rel="external">What benefit is conferred by TCP timestamp?</a>  </p>
<a id="more"></a>  

<hr>
<h2 id="优秀管理者需要具备的气质"><a href="http://www.zhihu.com/question/35959303" target="_blank" rel="external">优秀管理者需要具备的气质</a></h2>
<pre><code>摘要：
    1. 管理者需要懂得妥协，越是困难的事，管理者就越要协调更多资源参与。管理者需要做的就是在冲突域妥协中找到平衡点。  
    2. 基层是操作层，中层是执行层，高层是创造层和领导层，这是分工标准。  
    3. 提到工作本身，管理者的条件（处理问题的能力）一定要胜过下属，才是第一保障。  
点评：
    了解公司管理者需要具备的素质与气质，在职业生涯初期能有助于辨别出（不）好的领导。
    正所谓良禽择木而栖，跟对一个优秀的领导对于职业发展是有重大帮助的。  
</code></pre><hr>
<h2 id="The_Best_DevOps_Tools_on_OSX"><a href="https://dzone.com/articles/the-best-devops-tools-on-osx" target="_blank" rel="external">The Best DevOps Tools on OSX</a></h2>
<pre><code>点评：一个推荐工具的blog，质量确实不错。另外为什么要关注DevOps的工具呢？毕竟想通往<span class="keyword">Full</span>-<span class="keyword">Stack</span>啊^_^  
</code></pre><hr>
<h2 id="How_to_make_your_code_self-documenting"><a href="http://codeutopia.net/blog/2014/12/01/how-to-make-your-code-self-documenting/" target="_blank" rel="external">How to make your code self-documenting</a></h2>
<pre><code>摘要：
    <span class="number">1</span>. There are three basic methods <span class="keyword">for</span> <span class="keyword">self</span>-documenting code:
        Nameing things: Use names <span class="keyword">to</span> explain the purpose <span class="keyword">of</span> variables, functions, ect.
        Extracting <span class="function"><span class="keyword">function</span>:</span> Move code <span class="keyword">into</span> functions <span class="keyword">to</span> clarify purpose
        Introduce a variable: Move expressions <span class="keyword">into</span> dedicated variables <span class="keyword">to</span> clarify them
    <span class="number">2</span>. addition methods:
        <span class="keyword">Class</span> <span class="keyword">and</span> <span class="keyword">module</span> interfaces: What functions your classes <span class="keyword">and</span> modules expose effect the clarity <span class="keyword">of</span> the code
        Code grouping: You can indicate relatinships between different pieces <span class="keyword">of</span> code <span class="keyword">with</span> grouping
点评：
    <span class="number">1</span>. 这篇文章提出了一些增强代码<span class="keyword">self</span>-documentating的技巧，那为什么需要代码<span class="keyword">self</span>-documenting呢？
    尽管可以通过添加注释来解释代码，但实践中往往还是可读性更好的代码更易维护，更易理解。
    那么可读性好是什么？我的定义：一个相同领域的工程师，在不需要额外的文档、注释的情况下，
    就是很快的理解代码的逻辑和功能。
    <span class="number">2</span>. 关于Extracing <span class="function"><span class="keyword">function</span>之前我的理解还只是一个函数负责单一的一个逻辑。
    没有意识到，这样做还能帮助减少<span class="title">duplicate</span> <span class="title">code</span>，甚至能优化设计<span class="params">(improve your architecture)</span>。
    更没意识到的是，下例所展示出的一个作用:</span>

        优化前: 
            <span class="keyword">var</span> width = (value - <span class="number">0.5</span>) *<span class="number">16</span>;
        优化后: 
            <span class="keyword">var</span> width = emToPixel(value);

            <span class="function"><span class="keyword">function</span> <span class="title">emToPixels</span><span class="params">(ems)</span> <span class="comment">{
                return (ems - 0.5) * 16;
            }</span>

    优化前，如果不额外添加注释，时间长了很难记着这一行到底在干嘛。
    优化后，尽管没有注释，不管过了多久，一看代码就会知道完成的作用就是单位转换。
    同理文章还有一个将复杂的判断逻辑放到一个函数中去的例子，出发点是相同的。这里就不罗列了。  
    在这一点上，还需要在以后的实践中多多注意和体会。  </span>
</code></pre><p>相关阅读：<br><a href="http://perthcharles.github.io/2014/04/20/the-art-of-readable-code/" target="_blank" rel="external">强烈推荐之前读过的:The Art of Readable Code</a>  </p>
<hr>
<h2 id="KCon_2015_黑客安全大会"><a href="http://www.ichunqiu.com/course/775" target="_blank" rel="external">KCon 2015 黑客安全大会</a></h2>
<p>看看视频，了解了解KCon.  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<h2 id="Save_Some_Bandwidth_By_Turning_Off_TCP_Timestamps"><a href="http://highscalability.com/blog/2015/10/14/save-some-bandwidth-by-turning-off-tcp-timestamps.html" target="_blank" rel="external">Save Some Bandwidth By Turning Off TCP Timestamps</a></h2>
<pre><code>想法: tcp timestamp选项会引入额外的<span class="number">12</span>字节的包头开销，因此关闭tcp timestamp选项理论上能够少量的提高有效数据的吞吐率
评测: 使用qperf benchmark评测关闭tcp timestamp后，能提升大约<span class="number">1</span>%的吞吐率
      对于<span class="number">10</span>GE NIC，关闭timestamp能将下载速度从<span class="number">9370</span>Mbits/s提升至<span class="number">9460</span>Mbits/s
点评: 关闭timestamp正常情况下确实能提高有效数据的吞吐率，但在某些情况下可能就不那么理想了。
      比如timestamp提出的初衷之一就是解决RTT测量不准，导致spurious retransmission的情况。如果关闭timestamp导致了更多的RTO，则肯定是划不来的。  
      正如文中建议的：
        Results show <span class="keyword">that</span> <span class="keyword">it</span> <span class="keyword">is</span> reasonable <span class="keyword">to</span> turn off timestamps <span class="function_start"><span class="keyword">on</span></span> <span class="number">10</span>GE interfaces, 
        <span class="keyword">but</span> keep <span class="keyword">in</span> mind <span class="keyword">that</span> <span class="keyword">it</span> should be performed only <span class="keyword">in</span> low latency networks.
      使用<span class="number">10</span>GE网卡是为了<span class="number">1</span>%的提升效果更明显，强调低延迟是因为RTO有系统最小值<span class="number">200</span>ms限制。低延迟下更难出现spurious retransmission
</code></pre><p>相关阅读：<br><a href="http://serverfault.com/questions/566889/is-it-fine-to-turn-off-tcp-window-scaling-and-tcp-timestamps-on-server" target="_blank" rel="external">Is it fine to turn off tcp window scaling and tcp timestamps on server?</a><br><a href="http://stackoverflow.com/questions/7880383/what-benefit-is-conferred-by-tcp-timestamp" target="_blank" rel="external">What benefit is conferred by TCP timestamp?</a>  </p>
]]>
    
    </summary>
    
      <category term="tcp" scheme="http://perthcharles.github.com/tags/tcp/"/>
    
      <category term="管理" scheme="http://perthcharles.github.com/tags/%E7%AE%A1%E7%90%86/"/>
    
      <category term="devops" scheme="http://perthcharles.github.com/tags/devops/"/>
    
      <category term="KCon" scheme="http://perthcharles.github.com/tags/KCon/"/>
    
      <category term="wiki-阅读周记" scheme="http://perthcharles.github.com/categories/wiki-%E9%98%85%E8%AF%BB%E5%91%A8%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[2015 Q2 Akamai互联网状态报告]]></title>
    <link href="http://perthcharles.github.com/2015/10/15/wiki-report-internet-state-2015Q2/"/>
    <id>http://perthcharles.github.com/2015/10/15/wiki-report-internet-state-2015Q2/</id>
    <published>2015-10-15T01:39:33.000Z</published>
    <updated>2015-10-17T08:27:49.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>这篇博客分享一下Akamai发布的互联网状态报告，推荐每一个网络从业人员读一读。<br>不一定要细看，多看看图，了解了解趋势。若能触发一些自己的思考便是极好的。<br>甚至以后做报告，做PTT时想要一些网络相关的图表，多看看看这个系列的报告也是收益良多的。  </p>
<p>另外也推荐阅读后续将发布的<a href="https://www.stateoftheinternet.com/resources-web-security-2015-q2-internet-security-report.html" target="_blank" rel="external">安全报告</a>,<br>尤其是被DDoS坑过的小伙伴们。T_T…<br>着急的可以先看看这个<a href="https://www.stateoftheinternet.com/downloads/pdfs/Q2-2015-SOTI-Connectivity-Executive-Summary.pdf" target="_blank" rel="external">summary</a>  </p>
<p>最后也推荐有兴趣的小伙伴订阅一下stateoftheinternet网站的RSS，保持跟进。  </p>
<hr>
<h3 id="What_you_need_to_know">What you need to know</h3>
<pre><code>&gt;&gt; Global average connection speed increased <span class="number">17</span>% <span class="property">year</span>-<span class="keyword">over</span>-<span class="property">year</span>; South Korea leads <span class="keyword">at</span> <span class="number">23.1</span> Mbps.
&lt;&lt; 全球平均网速(connection speed)每年增加<span class="number">17</span>%; 韩国领跑全球，达到<span class="number">23.1</span>Mbps.

&gt;&gt; Global average peak connection speed reached <span class="number">32.5</span> Mbps; up <span class="number">26</span>% <span class="property">year</span>-<span class="keyword">over</span>-<span class="property">year</span>.
&lt;&lt; 全球平均峰值网速达到<span class="number">32.5</span>Mbps，每年增长<span class="number">26</span>%。 

&gt;&gt; Gabon, Cameroon, Nepal <span class="keyword">and</span> Iraq experienced significant Internet disruptions.
&lt;&lt; 加蓬、喀麦隆、尼泊尔和伊拉克存在严重的网络干扰。（呵呵一笑）  

&gt;&gt; Mobile data traffic grew <span class="keyword">around</span> <span class="number">15</span>% <span class="keyword">between</span> <span class="keyword">the</span> Q1 <span class="keyword">and</span> Q2, <span class="keyword">and</span> increased <span class="number">55</span>% <span class="property">year</span> <span class="keyword">over</span> <span class="property">year</span> <span class="keyword">between</span> <span class="keyword">the</span> Q2 <span class="number">2014</span> <span class="keyword">and</span> Q2 <span class="number">2015</span>, based <span class="function_start"><span class="keyword">on</span></span> traffic data collected <span class="keyword">by</span> Ericsson.
&lt;&lt; 基于Ericsson的统计数据，移动数据流量Q2季度增长了<span class="number">15</span>%左右，每年的增长量在<span class="number">55</span>%左右。 （移动流量真是疯涨啊）  
</code></pre><p><a id="more"></a>  </p>
<hr>
<h3 id="Spotlight:_Internet_and_Broadband_Adoption">Spotlight: Internet and Broadband Adoption</h3>
<pre><code>The State <span class="operator">of</span> <span class="operator">the</span> Internet reports <span class="command"><span class="keyword">on</span> <span class="title">25</span> <span class="title">Mbps</span> <span class="title">broadband</span> <span class="title">connectivity</span>, <span class="title">reflecting</span> <span class="title">the</span> <span class="title">U</span>.<span class="title">S</span>. <span class="title">Federal</span> <span class="title">Communications</span> <span class="title">Commission</span>’<span class="title">s</span> (<span class="title">FCC</span>) <span class="title">adoption</span> <span class="title">of</span> <span class="title">25</span> <span class="title">Mbps</span> <span class="title">as</span> <span class="title">the</span> <span class="title">new</span> <span class="title">benchmark</span> <span class="title">broadband</span> <span class="title">speed</span>.</span>

&gt;&gt; Globally, <span class="number">4.9</span>% <span class="operator">of</span> unique IP addresses connected <span class="built_in">to</span> Akamai <span class="keyword">at</span> <span class="built_in">average</span> speeds <span class="operator">of</span> <span class="keyword">at</span> least <span class="number">25</span> Mbps, <span class="operator">a</span> <span class="number">7.5</span>% increase over <span class="operator">the</span> previous quarter.
&lt;&lt; 全球范围内，连接至Akamai的<span class="number">4.9</span>%的IP的平均速率超过<span class="number">25</span>Mbps, 这一比例相比于上一季度增长了<span class="number">7.5</span>%.  

&gt;&gt; In <span class="operator">the</span> United States, <span class="constant">five</span> states had <span class="number">10</span>% <span class="operator">or</span> more <span class="operator">of</span> unique IP addresses connect <span class="built_in">to</span> Akamai <span class="keyword">at</span> <span class="built_in">average</span> speeds <span class="operator">of</span> <span class="keyword">at</span> least <span class="number">25</span> Mbps.
&lt;&lt; 在美国，五个州存在超过<span class="number">10</span>%的连接至Akamai的IP的平均速率超过<span class="number">25</span>Mbps。

&gt;&gt; Japan (<span class="number">16.4</span> Mbps) saw <span class="operator">the</span> largest quarterly gain <span class="operator">in</span> <span class="built_in">average</span> speed <span class="keyword">at</span> <span class="number">7.8</span>%.The <span class="built_in">global</span> <span class="built_in">average</span> connection speed increased <span class="number">3.5</span>% <span class="built_in">to</span> <span class="number">5.1</span> Mbps
&lt;&lt; 日本(<span class="number">16.4</span>Mbps)在上一个季度的平均网速增长最快，增长了<span class="number">7.8</span>%。全球平均网络增长了<span class="number">3.5</span>%，达到了<span class="number">5.1</span>Mbps.

&gt;&gt; Global <span class="built_in">average</span> peak connection speeds increased <span class="number">12</span>% <span class="built_in">to</span> <span class="number">32.5</span> Mbps. Average peak connection speeds increased <span class="number">100</span>% <span class="operator">in</span> Egypt (<span class="number">23.4</span> Mbps).
&lt;&lt; 全球的平均峰值网速增长了<span class="number">12</span>%，达到了<span class="number">32.5</span>Mbps。埃及的增速达到<span class="number">100</span>%，增至<span class="number">23.4</span>%。  

&gt;&gt; <span class="number">27</span>% <span class="operator">of</span> unique IP addresses globally connected <span class="built_in">to</span> Akamai <span class="keyword">at</span> <span class="built_in">average</span> speeds above <span class="number">10</span> Mbps, <span class="operator">an</span> increase <span class="operator">of</span> <span class="number">2.1</span>%.
&lt;&lt; 全球<span class="number">27</span>%连接至Akamai的IP的平均网速超过<span class="number">10</span>Mbps，增长了<span class="number">2.1</span>%.  

&gt;&gt; Among <span class="operator">the</span> top <span class="number">10</span> countries, Singapore rose <span class="operator">the</span> most (<span class="number">8.4</span>%) <span class="built_in">to</span> achieve <span class="number">50</span>% adoption <span class="operator">of</span> <span class="number">10</span> Mbps <span class="operator">or</span> higher.
&lt;&lt; 在网速做好的前<span class="number">10</span>个国家中，新加坡超过<span class="number">10</span>Mbps的比例增长最多(<span class="number">8.4</span>%)，达到了<span class="number">50</span>%的覆盖率。  

&gt;&gt; Among all countries, Kazakhstan rose <span class="operator">the</span> most (<span class="number">118</span>%) <span class="built_in">to</span> reach <span class="number">16</span>% adoption <span class="operator">of</span> <span class="number">10</span> Mbps <span class="operator">or</span> higher.
&lt;&lt; 所有国家中，哈萨克斯坦超过<span class="number">10</span>Mbps的比例增长最多(<span class="number">118</span>%)，达到了<span class="number">16</span>%的覆盖率。  

&gt;&gt; Reversing <span class="operator">the</span> trend seen <span class="operator">in</span> <span class="operator">the</span> <span class="keyword">first</span> quarter, <span class="operator">the</span> <span class="built_in">number</span> <span class="operator">of</span> unique IPv4 addresses worldwide connecting <span class="built_in">to</span> Akamai dropped <span class="keyword">by</span> about <span class="number">8.6</span> million <span class="operator">in</span> Q2.
&lt;&lt; 与第一季度的趋势相反，全球连接至Akamai的IPv4地址减少了<span class="number">8.7</span>million。

&gt;&gt; Six <span class="operator">of</span> <span class="operator">the</span> top <span class="number">10</span> countries saw <span class="operator">a</span> quarterly decline <span class="operator">in</span> unique IPv4 address.
&lt;&lt; 前<span class="number">10</span>的国家中，有六个国家检测到了IPv4地址的季度性下滑

&gt;&gt; Roughly half <span class="operator">of</span> <span class="operator">the</span> countries <span class="operator">and</span> regions had <span class="operator">an</span> increase <span class="operator">in</span> unique IPv4 address counts, <span class="operator">with</span> <span class="number">34</span> growing <span class="number">10</span>% <span class="operator">or</span> more.
&lt;&lt; 接近一半的国家和地区IPv4地址数量在增加，其中有<span class="number">34</span>个的增长率超过<span class="number">10</span>%。

&gt;&gt; European countries continued <span class="built_in">to</span> dominate <span class="operator">the</span> <span class="number">10</span> countries <span class="operator">and</span> regions <span class="operator">with</span> <span class="operator">the</span> largest percentage <span class="operator">of</span> content requests made <span class="built_in">to</span> Akamai over IPv6.
&lt;&lt; 在通过IPv6连接至Akamai的内容请求中，欧洲国家依然占据着前<span class="number">10</span>名中的大多数。

&gt;&gt; The only <span class="constant">two</span> non-European counties <span class="operator">among</span> <span class="operator">the</span> top <span class="number">10</span> were <span class="operator">the</span> U.S. <span class="operator">and</span> Peru. Both <span class="operator">of</span> which had significant double-digit quarterly improvements <span class="built_in">to</span> adoption rates <span class="operator">of</span> <span class="number">19</span>% <span class="operator">and</span> <span class="number">17</span>%, respectively.
&lt;&lt; 两个非欧洲国家分别是美国和秘鲁。两者该季度都有两位数的覆盖率的增长，分别达到了<span class="number">19</span>%和<span class="number">17</span>%。
</code></pre><hr>
<h2 id="报告正文摘要">报告正文摘要</h2>
<h3 id="Section_1:_internet_penetration">Section 1: internet penetration</h3>
<p>Akamai在该季度发现了804 million个IPv4地址连接到了Akamai的服务，连接请求分别来自242个国家和地区。(注：IPv4的理论总数约4.2 billion，可见Akamai的实力啊。Orz…)</p>
<p>尽管只发现了804 million个IPv4地址，但Akamai推测这背后至少有1 billion个网名用户。因为有许多用户是通过代理，NAT等技术来访问网络的。  </p>
<p><img src="/resources/2015-q2-state-of-the-internet-report-figures-charts-graphs/figure_1.jpg" alt=""><br>如果出现图片打不开的情况，可以自行前往下载: <a href="https://www.stateoftheinternet.com/downloads/pdfs/2015-q2-state-of-the-internet-report-figures-charts-graphs.zip" target="_blank" rel="external">Figures</a><br>从上图中可以看到，美国和中国是IPv4地址的大户(很显然嘛)，英国、日本和韩国的IPv4使用量每年还在以超过10%的速度在增长。<br>但就Q1和Q2季度而言，前十中有六个国家的IPv4地址数量在下降。Akamai的解释是认为新技术和IPv6地址的普及造成了这一现象。  </p>
<p><img src="/resources/2015-q2-state-of-the-internet-report-figures-charts-graphs/figure_2.jpg" alt=""><br><img src="/resources/2015-q2-state-of-the-internet-report-figures-charts-graphs/figure_3.jpg" alt=""><br><img src="/resources/2015-q2-state-of-the-internet-report-figures-charts-graphs/figure_4.jpg" alt=""><br>这三张图，反应的是Reginal Internet Registries(RIRs)该季度的IPv4地址存货量和分配量。<br>ARIN(American Registry for Internet Numbers)这个机构也是够拼的，几乎卖光了。  </p>
<p><img src="/resources/2015-q2-state-of-the-internet-report-figures-charts-graphs/figure_5.jpg" alt=""><br>比利时和瑞士的IPv6流量都超过20%了啊，欧洲真是走在网络基础设置更新的前列啊。  </p>
<hr>
<h3 id="Section_2-6:_geography_global/usa/americas/apac/emea">Section 2-6: geography global/usa/americas/apac/emea</h3>
<p>这几章主要是各个国家和地区的网速对比，看着略伤心。列几个图吧。<br><img src="/resources/2015-q2-state-of-the-internet-report-figures-charts-graphs/figure_7.jpg" alt=""><br><img src="/resources/2015-q2-state-of-the-internet-report-figures-charts-graphs/figure_10.jpg" alt=""><br><img src="/resources/2015-q2-state-of-the-internet-report-figures-charts-graphs/figure_24.jpg" alt=""><br>第三张图显示的数据也是让人心碎，Global Rank排名92(总计242个国家地区)，而且统计的平均网速还在下降！！！太可怜了。。。  </p>
<hr>
<h3 id="Section_7:_mobile_connectivity">Section 7: mobile connectivity</h3>
<p>这次关于mobile的内容由于Akamai的统计技术在做调整，因此只有下面这一张图的数据。<br>不过还是能反映整体mobile这边的趋势的。  </p>
<p><img src="/resources/2015-q2-state-of-the-internet-report-figures-charts-graphs/figure_34.jpg" alt="">  </p>
<hr>
<h3 id="Section_8:_Situational_Performance">Section 8: Situational Performance</h3>
<p>这章是Akamai通过它的Real User Monitoring(RUM)技术获取的真实数据，还挺有意思的。  </p>
<p><img src="/resources/2015-q2-state-of-the-internet-report-figures-charts-graphs/figure_35.jpg" alt=""><br>可以看到尽管表中很多国家在平均网络在前面的数据上看起来落后领先国家较多，但真实的页面平均加载时间上却并没有落后太多。<br>比如Hong Kong在平均网络方面要远好于Indonesia，但是从平均页面加载时间来看，Indonesia在Broadband方面也就慢500ms左右，<br>而且在Mobile方面甚至远好于Hong Kong.  </p>
<p>Akamai对此的解释有如下几点：<br>a. 数据采集不全，这受限于RUM技术<br>b. 这种相应时间受多方面因素影响，而不仅仅是网速。比如页面的总大小，页面的组成以及页面是否针对移动网络优化(这点可能是导致有不少地区mobile时间还小于broadboard时间的原因)都对平均加载时间有影响。<br>关于第二点，我表示十分认同。因为就我自身的上网经验而言，由于直接使用手机3G网络访问网络性能实在不能忍，所以基本都是在有WiFi时才去访问。<br>另外如果我在一个3G或4G网络本身就很快的地区，我可能就会任性的直接使用手机网络。甚至使用手机3G网络做比如看视频，下载文件这类耗流量的事情，<br>也就更有可能访问page weight大的网页，造成统计平均页面加载时间相对教程的现象。</p>
<hr>
<h3 id="Section_9:_Internet_disruptions_+_events">Section 9: Internet disruptions + events</h3>
<p>这章到底在讲什么？下面是Akamai对于disruption的解释。  </p>
<pre><code>These disruptions may be accidental (backhoes <span class="keyword">or</span> ship anchors severing buried fiber), 
<span class="typename">natural</span> (hurricanes <span class="keyword">or</span> earthquakes), <span class="keyword">or</span> political (governments shutting off Internet <span class="keyword">access</span> <span class="keyword">in</span> response <span class="keyword">to</span> unrest). 
</code></pre><p>好了，理解了disruption的发生理由，大家随便看看这章就好。躺枪的国家有：Gabon, Cameroon, Nepal, Iraq。</p>
<p><img src="/resources/2015-q2-state-of-the-internet-report-figures-charts-graphs/_appendix.jpg" alt=""><br>最后是整体网络相关指标的的表格，方便对比查看。  </p>
<hr>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.stateoftheinternet.com/resources-connectivity-2015-q2-state-of-the-internet-report.html" target="_blank" rel="external">AKAMAI’S STATE OF THE INTERNET: Q2 2015 REPORT</a><br><a href="https://www.stateoftheinternet.com/downloads/pdfs/Q2-2015-SOTI-Connectivity-Executive-Summary.pdf" target="_blank" rel="external">Q2 2015 STATE OF THE INTERNET SUMMARY</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>这篇博客分享一下Akamai发布的互联网状态报告，推荐每一个网络从业人员读一读。<br>不一定要细看，多看看图，了解了解趋势。若能触发一些自己的思考便是极好的。<br>甚至以后做报告，做PTT时想要一些网络相关的图表，多看看看这个系列的报告也是收益良多的。  </p>
<p>另外也推荐阅读后续将发布的<a href="https://www.stateoftheinternet.com/resources-web-security-2015-q2-internet-security-report.html" target="_blank" rel="external">安全报告</a>,<br>尤其是被DDoS坑过的小伙伴们。T_T…<br>着急的可以先看看这个<a href="https://www.stateoftheinternet.com/downloads/pdfs/Q2-2015-SOTI-Connectivity-Executive-Summary.pdf" target="_blank" rel="external">summary</a>  </p>
<p>最后也推荐有兴趣的小伙伴订阅一下stateoftheinternet网站的RSS，保持跟进。  </p>
<hr>
<h3 id="What_you_need_to_know">What you need to know</h3>
<pre><code>&gt;&gt; Global average connection speed increased <span class="number">17</span>% <span class="property">year</span>-<span class="keyword">over</span>-<span class="property">year</span>; South Korea leads <span class="keyword">at</span> <span class="number">23.1</span> Mbps.
&lt;&lt; 全球平均网速(connection speed)每年增加<span class="number">17</span>%; 韩国领跑全球，达到<span class="number">23.1</span>Mbps.

&gt;&gt; Global average peak connection speed reached <span class="number">32.5</span> Mbps; up <span class="number">26</span>% <span class="property">year</span>-<span class="keyword">over</span>-<span class="property">year</span>.
&lt;&lt; 全球平均峰值网速达到<span class="number">32.5</span>Mbps，每年增长<span class="number">26</span>%。 

&gt;&gt; Gabon, Cameroon, Nepal <span class="keyword">and</span> Iraq experienced significant Internet disruptions.
&lt;&lt; 加蓬、喀麦隆、尼泊尔和伊拉克存在严重的网络干扰。（呵呵一笑）  

&gt;&gt; Mobile data traffic grew <span class="keyword">around</span> <span class="number">15</span>% <span class="keyword">between</span> <span class="keyword">the</span> Q1 <span class="keyword">and</span> Q2, <span class="keyword">and</span> increased <span class="number">55</span>% <span class="property">year</span> <span class="keyword">over</span> <span class="property">year</span> <span class="keyword">between</span> <span class="keyword">the</span> Q2 <span class="number">2014</span> <span class="keyword">and</span> Q2 <span class="number">2015</span>, based <span class="function_start"><span class="keyword">on</span></span> traffic data collected <span class="keyword">by</span> Ericsson.
&lt;&lt; 基于Ericsson的统计数据，移动数据流量Q2季度增长了<span class="number">15</span>%左右，每年的增长量在<span class="number">55</span>%左右。 （移动流量真是疯涨啊）  
</code></pre><p>]]>
    
    </summary>
    
      <category term="wiki-好文共享" scheme="http://perthcharles.github.com/categories/wiki-%E5%A5%BD%E6%96%87%E5%85%B1%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[剖析free命令]]></title>
    <link href="http://perthcharles.github.com/2015/09/28/wiki-tool-free/"/>
    <id>http://perthcharles.github.com/2015/09/28/wiki-tool-free/</id>
    <published>2015-09-28T03:07:21.000Z</published>
    <updated>2015-09-28T05:42:14.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>Linux中有许多的查看系统状态的命令，但是如果没有一些相关的背景知识就很容易<br>造成误解。free命令就是一个明显的例子。本系列wiki就结合一些好的资料并<br>结合自身理解来尝试剖析一些常用又常被误解的Linux命令。  </p>
<p><a id="more"></a><br>本文最要参考<a href="http://www.linuxnix.com/2013/05/find-ram-size-in-linuxunix.html" target="_blank" rel="external">这篇好文</a>,英文无压力的建议再读读原文。  </p>
<hr>
<h3 id="从一则free使用实例说开">从一则free使用实例说开</h3>
<pre><code><span class="preprocessor"># free</span>
             total       used       free     shared    buffers     cached
<span class="label">Mem:</span>      <span class="number">16426628</span>   <span class="number">16372464</span>      <span class="number">54164</span>          <span class="number">0</span>      <span class="number">35408</span>   <span class="number">10861984</span>
-/+ buffers/cache:    <span class="number">5475072</span>   <span class="number">10951556</span>
<span class="label">Swap:</span>     <span class="number">32764556</span>    <span class="number">7985476</span>   <span class="number">24779080</span>
</code></pre><p>第一行和第三行字面意思都好立即，第二行往往很多人不理解。主要是看不懂”-/+ buffers/cache”<br>到底是什么鬼。<br>也正是很多人不理解第二行，往往看到类似上面的free结果后，就认为系统已经没有空闲内存给新进程使用了。<br>下面给出一个计算公式，基本一看就能懂了。  </p>
<pre><code><span class="attribute">line1[used] - (line1[buffers] + line1[cached]) </span>=<span class="string"> line2[used]
line1[total] - line2[used] = line2[free]</span>
</code></pre><p>根据实例验证一下  </p>
<pre><code><span class="attribute">16372464 - (35408 + 10861984) </span>=<span class="string"> 5475072
16426628 - 5475072 = 10951556</span>
</code></pre><p>那么当有人问起，看到这样一个free结果时，系统还有多少可用的空闲内存呢(free RAM available) ?<br>我们的回答应该是line2[free]而不是line1[free]。下面会详细解释。  </p>
<hr>
<h3 id="buffers和cached到底是什么">buffers和cached到底是什么</h3>
<p>buffers是被一个特定进程使用的用于<em>临时</em>存放数据的内存空间，这些内容不会被其他进程访问。<br><a href="http://www.linuxnix.com/2013/05/find-ram-size-in-linuxunix.html" target="_blank" rel="external">这篇文章</a>用了带宽的概念来<br>类比，非常贴切。<br>当你试图通过网络发送大量的突发数据时，如果网卡的带宽(capacity)仅支持发送一部分时，<br>它会将剩下的数据存在buffers中，用于后续发送。</p>
<p>而cached用于存放频繁访问的一些数据，目的是做到更快的数据访问。<br>比如多个进程需要读同一个文件，此时内存可能就分配一片cached区域，用于作为CPU到磁盘<br>之间的cache。  </p>
<p>buffers和cached的区别：<br>a. buffers是供单个进程使用的，而cached可供多个进程使用<br>b. buffers是一次性的，而cached是可以反复使用的<br>buffers和cached的共同之处就在于它们都是临时性的存储，如果后续有进程需要使用<br>这些内存空间，Linux会释放(free)这些临时性占用的内存。</p>
<hr>
<h3 id="swap分区">swap分区</h3>
<p>swap分区的目的是将一些不被频繁访问的内存数据放到磁盘，但是当需要时又能尽快的恢复到内存中去  </p>
<hr>
<h3 id="参考资料">参考资料</h3>
<p><a href="http://www.linuxnix.com/2013/05/find-ram-size-in-linuxunix.html" target="_blank" rel="external">Understanding free command in Linux/Unix</a><br><a href="http://www.linuxatemyram.com/" target="_blank" rel="external">Linux ate my ram! Don’t Panic! Your ram is fine!</a><br><a href="http://www.linuxatemyram.com/play.html" target="_blank" rel="external">Experiments and fun with the Linux disk cache</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>Linux中有许多的查看系统状态的命令，但是如果没有一些相关的背景知识就很容易<br>造成误解。free命令就是一个明显的例子。本系列wiki就结合一些好的资料并<br>结合自身理解来尝试剖析一些常用又常被误解的Linux命令。  </p>
<p>]]>
    
    </summary>
    
      <category term="free" scheme="http://perthcharles.github.com/tags/free/"/>
    
      <category term="linux" scheme="http://perthcharles.github.com/tags/linux/"/>
    
      <category term="shell" scheme="http://perthcharles.github.com/tags/shell/"/>
    
      <category term="wiki-tools" scheme="http://perthcharles.github.com/categories/wiki-tools/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用ssh forward跨局域网访问]]></title>
    <link href="http://perthcharles.github.com/2015/09/22/ssh-forward/"/>
    <id>http://perthcharles.github.com/2015/09/22/ssh-forward/</id>
    <published>2015-09-22T13:02:36.000Z</published>
    <updated>2015-09-22T14:17:40.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>在平时需要夸局域网访问某台设备时，都是选择先ssh登录跳板机，然后通过跳板机<br>再去访问目的设备。但在某些时候可能比较麻烦，比如涉及到图形化界面时。<br>这篇文章就来介绍一下如何使用ssh forward功能，达到在跨局域网访问时，<br>像访问同一局域网设备一样方便。  </p>
<a id="more"></a>  

<hr>
<h3 id="网络拓扑">网络拓扑</h3>
<p>假设存在一下网络拓扑，这是一个非常常见的办公网络环境拓扑  </p>
<pre><code><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>                 <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>
<span class="comment">|</span>    <span class="comment">设备A</span>    <span class="comment">|</span>                 <span class="comment">|</span>    <span class="comment">设备B</span>     <span class="comment">|</span>
<span class="comment">|</span> <span class="comment">192</span><span class="string">.</span><span class="comment">168</span><span class="string">.</span><span class="comment">1</span><span class="string">.</span><span class="comment">11|</span>   &lt;<span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;   <span class="comment">|</span> <span class="comment">192</span><span class="string">.</span><span class="comment">168</span><span class="string">.</span><span class="comment">1</span><span class="string">.</span><span class="comment">22</span> <span class="comment">|</span>
<span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>                 <span class="comment">|</span>              <span class="comment">|</span>
                                <span class="comment">|</span>              <span class="comment">|</span>
<span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>                 <span class="comment">|</span>              <span class="comment">|</span>
<span class="comment">|</span>    <span class="comment">设备C</span>    <span class="comment">|</span>                 <span class="comment">|</span>              <span class="comment">|</span>
<span class="comment">|</span> <span class="comment">192</span><span class="string">.</span><span class="comment">168</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">11|</span>   &lt;<span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>&gt;   <span class="comment">|</span> <span class="comment">192</span><span class="string">.</span><span class="comment">168</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">22</span> <span class="comment">|</span>
<span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>                 <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>
</code></pre><p>平时如果设备A想要访问设备C，可以首先登陆设备B，然后再登陆设备C，即</p>
<pre><code><span class="variable">@A</span> <span class="comment"># ssh usr@192.168.1.22</span>
<span class="variable">@B</span> <span class="comment"># ssh usr@192.168.2.11</span>
</code></pre><p>此时设备B发挥的作用一般就称为跳板机。<br>但假设这样一种情景，设备C提供了视频web服务，想直接使用设备A上面的浏览器<br>播放，此时会有两种办法。  </p>
<h5 id="配置正确的路由和网关信息">配置正确的路由和网关信息</h5>
<p>比如  </p>
<pre><code><span class="variable">@A</span> <span class="comment"># route add -net 192.168.2.0 netmask 255.255.255.0 gw 192.168.1.22 dev eth1</span>
<span class="variable">@C</span> <span class="comment"># route add -net 192.168.1.0 netmask 255.255.255.0 gw 192.168.2.22 dev eth1</span>
<span class="variable">@B</span> <span class="comment"># echo 1 &gt; /proc/sys/net/ipv4/ip_forward    // 开启ip forward</span>
</code></pre><p>可以看到，这种方法需要在三台机器上进行route相关的配置，比较麻烦。<br>并且很多时候，设备A的用户是没有修改设备C和设备B的系统配置的权限的。  </p>
<h5 id="配置ssh_forward">配置ssh forward</h5>
<p>这种方法使用方便，目的性强（也就意味着适用性差）。具体操作如下  </p>
<pre><code><span class="variable">@A</span> <span class="comment"># ssh -L 8000:192.168.2.11:80  usr@192.168.1.22</span>
</code></pre><p>man ssh里面的解释最准确简介，直接贴上来  </p>
<pre><code>-L [bind_address:]port:host:hostport
    Specifies that <span class="operator">the</span> given port <span class="command"><span class="keyword">on</span> <span class="title">the</span> <span class="title">local</span> (<span class="title">client</span>) <span class="title">host</span> <span class="title">is</span> <span class="title">to</span> <span class="title">be</span></span>
    forwarded <span class="built_in">to</span> <span class="operator">the</span> given host <span class="operator">and</span> port <span class="command"><span class="keyword">on</span> <span class="title">the</span> <span class="title">remote</span> <span class="title">side</span>.  <span class="title">This</span></span>
    works <span class="keyword">by</span> allocating <span class="operator">a</span> <span class="built_in">socket</span> <span class="built_in">to</span> listen <span class="built_in">to</span> port <span class="command"><span class="keyword">on</span> <span class="title">the</span> <span class="title">local</span> <span class="title">side</span>,</span>
    optionally bound <span class="built_in">to</span> <span class="operator">the</span> specified bind_address.  Whenever <span class="operator">a</span> con-
    nection is made <span class="built_in">to</span> this port, <span class="operator">the</span> connection is forwarded over
    <span class="operator">the</span> secure channel, <span class="operator">and</span> <span class="operator">a</span> connection is made <span class="built_in">to</span> host port
    hostport <span class="built_in">from</span> <span class="operator">the</span> remote machine.  Port forwardings can also be
    specified <span class="operator">in</span> <span class="operator">the</span> configuration <span class="built_in">file</span>.  IPv6 addresses can be spec-
    ified <span class="keyword">by</span> enclosing <span class="operator">the</span> address <span class="operator">in</span> square brackets.  Only <span class="operator">the</span>
    superuser can forward privileged ports.  By default, <span class="operator">the</span> <span class="built_in">local</span>
    port is bound <span class="operator">in</span> accordance <span class="operator">with</span> <span class="operator">the</span> GatewayPorts setting.  How-
    ever, <span class="operator">an</span> explicit bind_address may be used <span class="built_in">to</span> bind <span class="operator">the</span> connection
    <span class="built_in">to</span> <span class="operator">a</span> specific address.  The bind_address <span class="operator">of</span> <span class="string">''</span>localhost<span class="string">''</span> indi-
    cates that <span class="operator">the</span> listening port be bound <span class="keyword">for</span> <span class="built_in">local</span> use only, <span class="keyword">while</span>
    <span class="operator">an</span> <span class="constant">empty</span> address <span class="operator">or</span> <span class="string">'*'</span> indicates that <span class="operator">the</span> port should be avail-
    able <span class="built_in">from</span> all interfaces. 
</code></pre><p>执行上面命令后，会将访问本地的8000端口的数据转到192.168.2.11:80，反向也一样。<br>此时即可直接在设备A上打开浏览器，输入localhost:8000地址，即可访问设备C提供的web服务</p>
<hr>
<h3 id="更进一步">更进一步</h3>
<p>如果存在以下拓扑，设备A想要访问设备D的web服务，如果使用配置route方式，则会更加麻烦。<br>而使用ssh forward方式，只需要简单的两条命令就能搞定  </p>
<pre><code>---------------                 ----------------
<span class="string">|    设备A    |                 |    设备B     |</span>
<span class="string">| 192.168.1.11|   &lt;---------&gt;   | 192.168.1.22 |</span>
---------------                 <span class="string">|              |</span>
                                <span class="string">|              |</span>
---------------                 <span class="string">|              |</span>
<span class="string">|    设备C    |                 | 192.168.2.22 |</span>
<span class="string">| 192.168.2.11|   &lt;---------&gt;   ----------------</span>
<span class="string">|             |                 </span>
<span class="string">|             |                 </span>
<span class="string">|             |                 ----------------</span>
<span class="string">| 192.168.3.11|   &lt;---------&gt;   |    设备D     |</span>
---------------                 <span class="string">| 192.168.3.22 |</span>
                                ----------------

@A <span class="preprocessor"># ssh -gL 8000:设备B:8000 usr@设备B</span>
@B <span class="preprocessor"># ssh -L  8000:设备D:80   usr@设备C</span>
</code></pre><p>其中-g的含义如下  </p>
<pre><code>-g  Allows remote hosts <span class="built_in">to</span> connect <span class="built_in">to</span> <span class="built_in">local</span> forwarded ports
</code></pre><p>由上面的例子可知，可以很方便的配置多个ssh forward，用以实现跨多个局域网的网络访问。<br>想要了解更多理论和具体的解释，强烈推荐看看参考资料。   </p>
<hr>
<h3 id="参考资料">参考资料</h3>
<p><a href="http://www.ibm.com/developerworks/cn/linux/l-cn-sshforward/" target="_blank" rel="external">实战SSH端口转发</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>在平时需要夸局域网访问某台设备时，都是选择先ssh登录跳板机，然后通过跳板机<br>再去访问目的设备。但在某些时候可能比较麻烦，比如涉及到图形化界面时。<br>这篇文章就来介绍一下如何使用ssh forward功能，达到在跨局域网访问时，<br>像访问同一局域网设备一样方便。  </p>
]]>
    
    </summary>
    
      <category term="Linux" scheme="http://perthcharles.github.com/tags/Linux/"/>
    
      <category term="ssh" scheme="http://perthcharles.github.com/tags/ssh/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Taming the Elephants -- New TCP Slow Start]]></title>
    <link href="http://perthcharles.github.com/2015/09/15/wiki-hybird-slow-start/"/>
    <id>http://perthcharles.github.com/2015/09/15/wiki-hybird-slow-start/</id>
    <published>2015-09-15T15:13:26.000Z</published>
    <updated>2015-09-17T01:05:13.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>这篇文章给出了对于老古董技术Slow Start的诸多现有性能问题评测分析，<br>并最后提出一种叫Hybird Slow Start (Hystart)的技术来尝试解决分析的一些问题。<br>这篇文章是理解最新的slow start技术的关键文章。<br><a id="more"></a>  </p>
<hr>
<h3 id="现有Slow-Start的性能问题">现有Slow-Start的性能问题</h3>
<p>长肥网络<a href="https://en.wikipedia.org/wiki/Bandwidth-delay_product" target="_blank" rel="external">[1]</a>中的TCP性能问题是现代TCP设计的一个重要领域。这不，连那么naive的slow start都在长肥网络中遇到的诸多性能问题。  </p>
<p>a. 标准的Slow Start算法可能引起严重的网络丢包<br>在ssthreshold值设置的过高时，慢启动一段时间后，cwnd的指数增长会显得过快。<br>有可能在上一个RTT，cwnd刚好等于BDP；下一个RTT，cwnd就等于2BDP了。<br>这样就可能导致多出的一个BDP的数据包被丢弃。这类丢包属于burst packet losses  </p>
<p>b. Slow start可能导致系统负载过高，尤其是在使用SACK机制时<br>关于SACK选项可能引起CPU utilization过高的问题已经有了普遍的认识<a href="http://www.ibm.com/developerworks/cn/linux/l-tcp-sack/index.html" target="_blank" rel="external">[2]</a><br>这篇论文给出的一个数据倒是令我比较感兴趣：  </p>
<pre><code>The problems consistently occur <span class="operator">in</span> all <span class="constant">three</span> dominant operating systems,
Linux, Windows XP <span class="operator">and</span> FreeBSD during more than <span class="number">40</span>% <span class="operator">of</span> slow start runs
<span class="operator">in</span> large BDP networks.  
</code></pre><p>解决Slow Start问题两个明显的思路：  </p>
<pre><code>1. 继续优化SACK的处理机制，提高遍历重传队列的效率
    -<span class="ruby">- 这也是目前较热的一个研究和工程趋势
</span>2. 解决slow start可能带来的burst losses，进而也能缓解SACK性能问题 
    -<span class="ruby">- 这是这篇论文所主要关心的思路</span>
</code></pre><p>吐个小槽：这篇论文的数据来看，Window XP被黑的不轻啊，╮(╯▽╰)╭  </p>
<hr>
<h3 id="Hybird-Slow-Start">Hybird-Slow-Start</h3>
<p>本文提出一种叫做Hybird Slow Start的算法来解决上述问题，论文中有不少精妙的<br>理论分析，这里就不再赘述。  </p>
<p>主要想解释一下packet train是个什么样的概念。<br>举个栗子，下图是我理解的一个packet train的样子，[Packet1]这些是表示一个具体<br>的数据包，’-‘用于表示两个数据包之间的发送时间间隔。<br>那么这样一个packet train能用来干嘛呢？计算带宽利用率！<br>具体来说，图中四个数据包的数据总量可以求和得到，然后总的时间间隔也可以得到<br>(timestamp4 - timestamp1)。</p>
<pre><code><span class="attr_selector">[Packet1]</span> <span class="tag">--</span> <span class="attr_selector">[Packet2]</span> <span class="tag">------</span> <span class="attr_selector">[Packet3]</span> <span class="tag">----</span> <span class="attr_selector">[Packet4]</span>
</code></pre><p>那这篇论文就利用的类似的思路，通过ACK train信息判断一个Safe Exit Point<br>for Slow Start. 同时为了避免计算带宽，通过一个巧妙的转换(具体建议看论文)，只要判断时间差<br>是否超过Forward one-way delay(Dmin)来决定是否退出慢启动。</p>
<p>总的来说，Hystart算法可以总结如下  </p>
<pre><code>Hystart算法通过以下两个技术来判断是否应该退出慢启动
<span class="bullet">1. </span>一个窗口内的数据包的总传输间隔是否超过Dmin
<span class="bullet">2. </span>数据包的RTT sample是否出现较大幅度的增长
</code></pre><p>论文给出的伪代码如下图所示<br><img src="/resources/hybird-slow-start.png" alt="">  </p>
<hr>
<h3 id="内核源码分析">内核源码分析</h3>
<p>从上面的hystart算法伪代码可以看出，hystart算法主要包括两个方面：<br>a. 在每个RTT区间开始时，重置hystart算法相关变量<br>b. 对于每个收到的ACK，根据ack train算法和RTT波动来判断是否应该退出slow start  </p>
<p>在Linux 3.10内核中，hybird slow start算法被集成在了默认的CUBIC算法中。<br>在tcp_cubic.c文件中有两个函数分别对应以上两个步骤，<br>分别是bictcp_hystart_reset()和hystart_update()。<br>这两个函数几乎是严格按照上述伪代码来实现的，所以也就没有接着展开解释的必要。<br>下面主要从整体的处理逻辑方面来分析源码  </p>
<pre><code>// cubic算法的关键数据结构  
static struct tcp_congestion_ops <span class="variable">cubictcp =</span> {
    .<span class="variable">init           =</span> bictcp_init,              // 在TCP流建立之初调用
    .<span class="variable">ssthresh       =</span> bictcp_recalc_ssthresh,
    .<span class="variable">cong_avoid     =</span> bictcp_cong_avoid,
    .<span class="variable">set_state      =</span> bictcp_state,
    .<span class="variable">undo_cwnd      =</span> bictcp_undo_cwnd,
    .<span class="variable">pkts_acked     =</span> bictcp_acked,             // 每次收到ACK数据包后调用
    .<span class="variable">owner          =</span> THIS_MODULE,
    .<span class="variable">name           =</span> <span class="string">"cubic"</span>,
};
</code></pre><p>上面是cubic算法的关键结构体的初始化部分，bictcp_init()负责TCP流建立时的初始化动作，<br>bictcp_acked()负责在每次收到ACK包后，更新相关信息。所有hystart算法上面的两个<br>函数也分别是在cubic的这两个函数中。下面依次看cubic中这两个函数的实现  </p>
<pre><code><span class="keyword">static</span> void bictcp_init(<span class="keyword">struct</span> sock *sk)
{
    bictcp_reset(inet_csk_ca(sk));

    <span class="keyword">if</span> (hystart)                    <span class="comment">// 如果开启(默认开启)，则进行hystart相关变量的初始化</span>
        bictcp_hystart_reset(sk);

    <span class="keyword">if</span> (!hystart &amp;&amp; initial_ssthresh)
        tcp_sk(sk)-&gt;snd_ssthresh = initial_ssthresh;
}

<span class="keyword">static</span> void bictcp_acked(<span class="keyword">struct</span> sock *sk, <span class="keyword">u32</span> cnt, s32 rtt_us)
{
    ...
    <span class="comment">/* first time call or link delay decreases */</span>
    <span class="keyword">if</span> (ca-&gt;delay_min == <span class="number">0</span> || ca-&gt;delay_min &gt; delay)
        ca-&gt;delay_min = delay;

    <span class="comment">/* hystart triggers when cwnd is larger than some threshold */</span>
    <span class="keyword">if</span> (hystart &amp;&amp; tp-&gt;snd_cwnd &lt;= tp-&gt;snd_ssthresh &amp;&amp; tp-&gt;snd_cwnd &gt;= hystart_low_window)
        hystart_update(sk, delay);
}
</code></pre><hr>
<h3 id="参考资料">参考资料</h3>
<p><a href="http://netsrv.csc.ncsu.edu/export/hystart_techreport_2008.pdf" target="_blank" rel="external">Taming the Elephant: New TCP Slow Start</a><br><a href="http://www.ibm.com/developerworks/cn/linux/l-oprof/index.html" target="_blank" rel="external">用OProfile彻底了解性能</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>这篇文章给出了对于老古董技术Slow Start的诸多现有性能问题评测分析，<br>并最后提出一种叫Hybird Slow Start (Hystart)的技术来尝试解决分析的一些问题。<br>这篇文章是理解最新的slow start技术的关键文章。<br>]]>
    
    </summary>
    
      <category term="TCP" scheme="http://perthcharles.github.com/tags/TCP/"/>
    
      <category term="SACK" scheme="http://perthcharles.github.com/tags/SACK/"/>
    
      <category term="OProfile" scheme="http://perthcharles.github.com/tags/OProfile/"/>
    
      <category term="wiki-paper" scheme="http://perthcharles.github.com/categories/wiki-paper/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用ip命令修改初始拥塞窗口和接收窗口]]></title>
    <link href="http://perthcharles.github.com/2015/09/14/ip-route-initcwnd/"/>
    <id>http://perthcharles.github.com/2015/09/14/ip-route-initcwnd/</id>
    <published>2015-09-14T10:14:04.000Z</published>
    <updated>2015-09-14T14:16:31.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>在不修改内核的情况下，Linux提供了一种使用ip命令修改初始拥塞窗口和接收窗口的机制。<br>具体的例子可看<a href="http://www.cdnplanet.com/blog/tune-tcp-initcwnd-for-optimum-performance/" target="_blank" rel="external">这篇文章</a><br><a id="more"></a>  </p>
<hr>
<h3 id="修改初始拥塞窗口">修改初始拥塞窗口</h3>
<p>使用如下命令可修改init cwnd  </p>
<pre><code>sudo ip route change <span class="keyword">default</span> via <span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span> dev eth0  proto <span class="keyword">static</span> initcwnd <span class="number">10</span>
</code></pre><p>内核源码分析  </p>
<pre><code><span class="comment">// 初始化cwnd的函数，会判断是否设置了route来指定initcwnd  </span>
<span class="number">__u32</span> tcp_init_cwnd(<span class="keyword">const</span> <span class="keyword">struct</span> tcp_sock *tp, <span class="keyword">const</span> <span class="keyword">struct</span> dst_entry *dst)
{
    <span class="number">__u32</span> cwnd = (dst ? dst_metric(dst, RTAX_INITCWND) : <span class="number">0</span>);

    <span class="keyword">if</span> (!cwnd)
        cwnd = TCP_INIT_CWND;
    <span class="keyword">return</span> min_t(<span class="number">__u32</span>, cwnd, tp-&gt;snd_cwnd_clamp);
}

<span class="comment">// 内核中一个典型的调用序列  </span>
tcp_finish_connect()
    =&gt; tcp_init_metrics()
        =&gt; tp-&gt;snd_cwnd = tcp_init_cwnd(tp, dst);
</code></pre><hr>
<h3 id="修改初始接收窗口">修改初始接收窗口</h3>
<p>使用如下命令可修改init rwnd  </p>
<pre><code>sudo ip route change <span class="keyword">default</span> via <span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span> dev eth0  proto <span class="keyword">static</span> initrwnd <span class="number">10</span>
</code></pre><p>内核源码分析  </p>
<pre><code><span class="regexp">//</span> 一个典型的调用序列
tcp_connect_init<span class="function"><span class="params">()</span>
    =&gt;</span> tcp_select_inital_window<span class="function"><span class="params">()</span>
        =&gt;</span> dst_metric(dst, RTAX_INITRWND)
</code></pre><h3 id="参考资料">参考资料</h3>
<p><a href="http://www.cdnplanet.com/blog/tune-tcp-initcwnd-for-optimum-performance/" target="_blank" rel="external">Tuning initcwnd for optimum performance</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>在不修改内核的情况下，Linux提供了一种使用ip命令修改初始拥塞窗口和接收窗口的机制。<br>具体的例子可看<a href="http://www.cdnplanet.com/blog/tune-tcp-initcwnd-for-optimum-performance/" target="_blank" rel="external">这篇文章</a><br>]]>
    
    </summary>
    
      <category term="ip" scheme="http://perthcharles.github.com/tags/ip/"/>
    
      <category term="tool" scheme="http://perthcharles.github.com/tags/tool/"/>
    
      <category term="Networking" scheme="http://perthcharles.github.com/categories/Networking/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[聊一聊重传次数]]></title>
    <link href="http://perthcharles.github.com/2015/09/07/wiki-tcp-retries/"/>
    <id>http://perthcharles.github.com/2015/09/07/wiki-tcp-retries/</id>
    <published>2015-09-07T13:40:02.000Z</published>
    <updated>2015-09-08T05:28:05.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>在<a href="http://perthcharles.github.io/2015/09/06/wiki-rtt-estimator/" target="_blank" rel="external">RTO的计算方法</a>中，介绍了RFC6298对于RTO的计算和RTO timer的管理算法。<br>但有一个重要的问题RFC没有提到，那就是如果出现了超时重传，那重传多少次可以放弃呢？<br>当然这是一个实现相关的细节，不同的操作系统可能有不同的实现策略。<br>在这篇wiki中，就来介绍一下Linux中是怎么限制超时重传次数的。<br><a id="more"></a>  </p>
<hr>
<h3 id="听说Linux有两个参数限制超时重传次数">听说Linux有两个参数限制超时重传次数</h3>
<p>没错，Linux中确实定义了两个参数来限定超时重传的次数的，以下是源码中Documentation/networking/ip-sysctl.txt文档中的描述  </p>
<pre><code>tcp_retries1 - INTEGER
    This <span class="built_in">value</span> influences <span class="operator">the</span> <span class="built_in">time</span>, <span class="keyword">after</span> which TCP decides, that
    something is wrong due <span class="built_in">to</span> unacknowledged RTO retransmissions,
    <span class="operator">and</span> reports this suspicion <span class="built_in">to</span> <span class="operator">the</span> network layer.
    See tcp_retries2 <span class="keyword">for</span> more details.

    RFC <span class="number">1122</span> recommends <span class="keyword">at</span> least <span class="number">3</span> retransmissions, which is <span class="operator">the</span>
    default.

tcp_retries2 - INTEGER
    This <span class="built_in">value</span> influences <span class="operator">the</span> timeout <span class="operator">of</span> <span class="operator">an</span> alive TCP connection,
    when RTO retransmissions remain unacknowledged.
    Given <span class="operator">a</span> <span class="built_in">value</span> <span class="operator">of</span> N, <span class="operator">a</span> hypothetical TCP connection following
    exponential backoff <span class="operator">with</span> <span class="operator">an</span> initial RTO <span class="operator">of</span> TCP_RTO_MIN would
    retransmit N times <span class="keyword">before</span> killing <span class="operator">the</span> connection <span class="keyword">at</span> <span class="operator">the</span> (N+<span class="number">1</span>)th RTO.

    The default <span class="built_in">value</span> <span class="operator">of</span> <span class="number">15</span> yields <span class="operator">a</span> hypothetical timeout <span class="operator">of</span> <span class="number">924.6</span>
    <span class="built_in">seconds</span> <span class="operator">and</span> is <span class="operator">a</span> <span class="built_in">lower</span> bound <span class="keyword">for</span> <span class="operator">the</span> <span class="keyword">effective</span> timeout.
    TCP will effectively <span class="built_in">time</span> out <span class="keyword">at</span> <span class="operator">the</span> <span class="keyword">first</span> RTO which exceeds <span class="operator">the</span>
    hypothetical timeout.

    RFC <span class="number">1122</span> recommends <span class="keyword">at</span> least <span class="number">100</span> <span class="built_in">seconds</span> <span class="keyword">for</span> <span class="operator">the</span> timeout,
    which corresponds <span class="built_in">to</span> <span class="operator">a</span> <span class="built_in">value</span> <span class="operator">of</span> <span class="keyword">at</span> least <span class="number">8.</span>
</code></pre><p>就是这样一段话，可能由于过于概括，会令人产生很多疑问，甚至产生一些误解。<br>比如常见的问题有：<br>a. 超过tcp_retries1这个阈值后，到底是report了怎样一种suspicion呢？<br>b. tcp_retries1和tcp_retries2的数字是表示RTO重传的次数上限，对吗？<br>c. 文档中提到，924.6s is a lower bound for the effective timeout。<br>这里的effective timeout是指什么？<br>为什么是lower bound，tcp_retries2不应该是限制重传次数的upper bound吗？  </p>
<p>下面就结合Linux 3.10的源码来逐个解释一下以上几个问题。并在最后给出一个总结。  </p>
<hr>
<h3 id="重传超过tcp_retries1会怎样">重传超过tcp_retries1会怎样</h3>
<p>文档中说的suspicion到底是什么呢？来看一下tcp_retries1相关的代码部分  </p>
<pre><code>// RTO timer的处理函数是tcp_retransmit_timer()，与tcp_retries1相关的代码调用关系如下  
tcp_retransmit_timer()
    =&gt; tcp_write_timeout()  // 判断是否重传了足够的久
        =&gt; retransmit_timed_out(sk, sysctl_tcp_retries1, <span class="number">0</span>, <span class="number">0</span>)  // 判断是否超过了阈值

// tcp_write_timeout()的具体相关内容  
<span class="keyword">...</span>
<span class="keyword">if</span> ((<span class="number">1</span> &lt;&lt; sk-&gt;sk_state) &amp; (TCPF_SYN_SENT | TCPF_SYN_RECV)) {
    // 如果超时发生在三次握手期间，此时有专门的tcp_syn_retries来负责限定重传次数
    <span class="keyword">...</span>
} <span class="keyword">else</span> {    // 如果超时发生在数据发送期间
    // 这个函数负责判断重传是否超过阈值，返回真表示超过。后续会详细分析这个函数  
    <span class="keyword">if</span> (retransmits_timed_out(sk, sysctl_tcp_retries1, <span class="number">0</span>, <span class="number">0</span>)) { 
        /* Black hole detection */
        tcp_mtu_probing(icsk, sk);  // 如果开启tcp_mtu_probing(默认关闭)了，则执行PMTU

        dst_negative_advice(sk);    // 更新路由缓存
    }
    <span class="keyword">...</span>
}
</code></pre><p>从以上的代码可以看到，一旦重传超过阈值tcp_retries1，主要的动作就是更新路由缓存。<br>用以避免由于路由选路变化带来的问题。  </p>
<hr>
<h3 id="重传超过tcp_retries2会怎样">重传超过tcp_retries2会怎样</h3>
<p>会直接放弃重传，关闭TCP流  </p>
<pre><code>// 依然还是在tcp_write_timeout()中，retry_until一般是tcp_retries2
<span class="keyword">...</span>
<span class="keyword">if</span> (retransmits_timed_out(sk, retry_until, syn_set ? <span class="number">0</span> : icsk-&gt;icsk_user_timeout, syn_set)) {
    /* Has it gone just too far? */
    tcp_write_err(sk);      // 调用tcp_done关闭TCP流
    <span class="keyword">return</span> <span class="number">1</span>;
}
</code></pre><hr>
<h3 id="retries限制的重传次数吗">retries限制的重传次数吗</h3>
<p>咋一看文档，很容易想到retries的数字就是限定的重传的次数，甚至源码中对于retries常量注释中都写着”This is how many retries it does…”  </p>
<pre><code><span class="comment">#define TCP_RETR1       3   /*</span>
                             * This is how many retries <span class="keyword">it</span> does <span class="keyword">before</span> <span class="keyword">it</span>
                             * tries <span class="built_in">to</span> figure out <span class="keyword">if</span> <span class="operator">the</span> gateway is
                             * down. Minimal RFC <span class="built_in">value</span> is <span class="number">3</span>; <span class="keyword">it</span> corresponds
                             * <span class="built_in">to</span> ~<span class="number">3</span><span class="built_in">sec</span>-<span class="number">8</span><span class="built_in">min</span> depending <span class="command"><span class="keyword">on</span> <span class="title">RTO</span>.</span>
                             */

<span class="comment">#define TCP_RETR2       15  /*</span>
                             * This should take <span class="keyword">at</span> least
                             * <span class="number">90</span> minutes <span class="built_in">to</span> <span class="built_in">time</span> out.
                             * RFC1122 says that <span class="operator">the</span> limit is <span class="number">100</span> <span class="built_in">sec</span>.
                             * <span class="number">15</span> is ~<span class="number">13</span>-<span class="number">30</span><span class="built_in">min</span> depending <span class="command"><span class="keyword">on</span> <span class="title">RTO</span>.</span>
                             */
</code></pre><p>那就就来看看retransmits_timed_out的具体实现，看看到底是不是限制的重传次数  </p>
<pre><code>/* This <span class="reserved">function</span> calculates a <span class="string">"timeout"</span> which <span class="keyword">is</span> equivalent to the timeout <span class="keyword">of</span> a
 * TCP connection after <span class="string">"boundary"</span> unsuccessful, exponentially backed-<span class="literal">off</span>
 * retransmissions <span class="reserved">with</span> an initial RTO <span class="keyword">of</span> TCP_RTO_MIN <span class="keyword">or</span> TCP_TIMEOUT_INIT <span class="keyword">if</span>
 * syn_set flag <span class="keyword">is</span> set.
 */
static bool retransmits_timed_out(struct sock *sk,
                              unsigned int boundary,
                              unsigned int timeout,
                              bool syn_set)
{
    unsigned int linear_backoff_thresh, start_ts;
    <span class="regexp">//</span> 如果是在三次握手阶段，syn_set为真
    unsigned int rto_base = syn_set ? TCP_TIMEOUT_INIT : TCP_RTO_MIN;

    <span class="keyword">if</span> <span class="function"><span class="params">(!inet_csk(sk)-&gt;icsk_retransmits)</span>
            <span class="title">return</span> <span class="title">false</span>;

    // <span class="title">retrans_stamp</span>记录的是数据包第一次发送的时间，在<span class="title">tcp_retransmit_skb</span><span class="params">()</span>中设置
    <span class="title">if</span> <span class="params">(unlikely(!tcp_sk(sk)-&gt;retrans_stamp))</span>
            <span class="title">start_ts</span> = <span class="title">TCP_SKB_CB</span><span class="params">(tcp_write_queue_head(sk))</span>-&gt;</span><span class="keyword">when</span>;
    <span class="keyword">else</span>
            start_ts = tcp_sk<span class="function"><span class="params">(sk)</span>-&gt;</span>retrans_stamp;

    <span class="regexp">//</span> 如果用户态未指定timeout，则算一个出来
    <span class="keyword">if</span> (likely(timeout == <span class="number">0</span>)) {
            /* 下面的计算过程，其实就是算一下如果以rto_base为第一次重传间隔，
             * 重传boundary次需要多长时间
             */
            linear_backoff_thresh = ilog2(TCP_RTO_MAX/rto_base);

            <span class="keyword">if</span> (boundary &lt;= linear_backoff_thresh)
                    timeout = ((<span class="number">2</span> &lt;&lt; boundary) - <span class="number">1</span>) * rto_base;
            <span class="keyword">else</span>
                    timeout = ((<span class="number">2</span> &lt;&lt; linear_backoff_thresh) - <span class="number">1</span>) * rto_base +
                            (boundary - linear_backoff_thresh) * TCP_RTO_MAX;
    }
    <span class="regexp">//</span> 如果数据包第一次发送的时间距离现在的时间间隔，超过了timeout值，则认为重传超于阈值了
    <span class="keyword">return</span> (tcp_time_stamp - start_ts) &gt;= timeout;
}
</code></pre><p>从以上的代码分析可以看到，真正起到限制重传次数的并不是真正的重传次数。<br>而是以tcp_retries1或tcp_retries2为boundary，以rto_base(如TCP_RTO_MIN 200ms)为初始RTO，计算得到一个timeout值出来。如果重传间隔超过这个timeout，则认为超过了阈值。<br>上面这段话太绕了，下面举两个个例子来说明  </p>
<pre><code>以判断是否放弃TCP流为例，如果<span class="variable">tcp_retries2=</span><span class="number">15</span>，那么计算得到的<span class="variable">timeout=</span><span class="number">924600</span>ms。

<span class="number">1</span>. 如果RTT比较小，那么RTO初始值就约等于下限<span class="number">200</span>ms
   由于timeout总时长是<span class="number">924600</span>ms，表现出来的现象刚好就是重传了<span class="number">15</span>次，超过了timeout值，从而放弃TCP流

<span class="number">2</span>. 如果RTT较大，比如RTO初始值计算得到的是<span class="number">1000</span>ms
   那么根本不需要重传<span class="number">15</span>次，重传总间隔就会超过<span class="number">924600</span>ms。
   比如我测试的一个<span class="variable">RTT=</span><span class="number">400</span>ms的情况，当<span class="variable">tcp_retries2=</span><span class="number">10</span>时，仅重传了<span class="number">3</span>次就放弃了TCP流
</code></pre><hr>
<h3 id="另外几个小问题">另外几个小问题</h3>
<p>理解了Linux决定重传次数的真实机制，就不难回答一下几个问题了  </p>
<pre><code><span class="input"><span class="prompt">&gt;&gt;</span> effective timeout指的是什么？  </span>
<span class="input"><span class="prompt">&lt;&lt; 就是retransmits_timed_out计算得到的timeout值

&gt;&gt;</span> <span class="number">924.6</span>s是怎么算出来的？</span>
&lt;&lt; <span class="number">924.6</span>s = (( <span class="number">2</span> &lt;&lt; <span class="number">9</span>) -<span class="number">1</span>) * <span class="number">200</span>ms + (<span class="number">15</span> - <span class="number">9</span>) * <span class="number">120</span>s
<span class="input"><span class="prompt">
&gt;&gt;</span> 为什么<span class="number">924.6</span>s是lower bound？</span>
&lt;&lt; 重传总间隔必须大于timeout值，即 (tcp_time_stamp - start_ts) &gt;= timeout
<span class="input"><span class="prompt">
&gt;&gt;</span> 那<span class="constant">RTO</span>超时的间隔到底是不是源码注释的<span class="string">"15 is ~13-30min depending on RTO."</span>呢？  </span>
&lt;&lt; 显然不是! 虽然<span class="number">924.6</span>s(<span class="number">15</span>min)是一个lower bound，但是它同时也是一个upper bound!
   怎么理解？举例说明  
        <span class="number">1</span>. 如果某个<span class="constant">RTO</span>值导致，在已经重传了<span class="number">14</span>次后，总重传间隔开销是<span class="number">924</span>s
        那么它还需要重传第<span class="number">15</span>次，即使离<span class="number">924.6</span>s只差<span class="number">0</span>.<span class="number">6</span>s。这就是发挥了lower bound的作用
        <span class="number">2</span>. 如果某个<span class="constant">RTO</span>值导致，在重传了<span class="number">10</span>次后，总重传间隔开销是<span class="number">924</span>s
        重传第<span class="number">11</span>次后，第<span class="number">12</span>次超时触发时计算得到的总间隔变为<span class="number">1044</span>s，超过<span class="number">924.6</span>s
        那么此时会放弃第<span class="number">12</span>次重传，这就是<span class="number">924.6</span>s发挥了upper bound的作用
   总的来说，在<span class="constant">Linux3</span>.<span class="number">10</span>中，如果tcp_retres2设置为<span class="number">15</span>。总重传超时周期应该在如下范围内
        [<span class="number">924.6</span>s, <span class="number">1044.6</span>s)
</code></pre><p>所以综合上述，Linux并不是直接拿tcp_retries1和tcp_retries2来限制重传次数的，而是用计算得到<br>的一个timeout值来判断是否要放弃重传的。真正的重传次数同时与RTT相关。  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>在<a href="http://perthcharles.github.io/2015/09/06/wiki-rtt-estimator/" target="_blank" rel="external">RTO的计算方法</a>中，介绍了RFC6298对于RTO的计算和RTO timer的管理算法。<br>但有一个重要的问题RFC没有提到，那就是如果出现了超时重传，那重传多少次可以放弃呢？<br>当然这是一个实现相关的细节，不同的操作系统可能有不同的实现策略。<br>在这篇wiki中，就来介绍一下Linux中是怎么限制超时重传次数的。<br>]]>
    
    </summary>
    
      <category term="rto" scheme="http://perthcharles.github.com/tags/rto/"/>
    
      <category term="tcp" scheme="http://perthcharles.github.com/tags/tcp/"/>
    
      <category term="wiki-network" scheme="http://perthcharles.github.com/categories/wiki-network/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[RTO的计算方法(基于RFC6298和Linux 3.10)]]></title>
    <link href="http://perthcharles.github.com/2015/09/06/wiki-rtt-estimator/"/>
    <id>http://perthcharles.github.com/2015/09/06/wiki-rtt-estimator/</id>
    <published>2015-09-06T04:51:17.000Z</published>
    <updated>2015-09-06T10:03:58.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>RTO的准确计算对于TCP的可靠性传输和性能都具有重要作用。<br>这篇文章首先介绍最新的RFC中对于RTO的计算方法，然后结合Linux 3.10的源码对<br>具体的实现进行分析和理解。  </p>
<a id="more"></a>  

<hr>
<h3 id="RTO计算算法">RTO计算算法</h3>
<pre><code><span class="number">1.1</span>. 在没有任何rtt sample的时候，RTO &lt;- TCP_TIMEOUT_INIT (<span class="number">1</span>s)
   多次重传时同样适用指数回避算法(backoff)增加RTO  

<span class="number">1.2</span>. 获得第一个RTT sample后，
    SRTT &lt;- RTT
    RTTVAR &lt;- RTT/<span class="number">2</span>
    RTO &lt;- SRTT + max(G, K * RTTVAR)
其中K=<span class="number">4</span>, G表示timestamp的粒度(在CONFIG_HZ=<span class="number">1000</span>时，粒度为<span class="number">1</span>ms)

<span class="number">1.3</span>. 后续获得更多RTT sample后，
    RTTVAR &lt;- (<span class="number">1</span> - beta) * RTTVAR + beta * |SRTT - R|
    SRTT &lt;- (<span class="number">1</span> - alpha) * SRTT + alpha * R
其中beta = <span class="number">1</span>/<span class="number">4</span>, alpha = <span class="number">1</span>/<span class="number">8</span>

<span class="number">1.4</span>. Whenever RTO <span class="keyword">is</span> computed, <span class="keyword">if</span> <span class="keyword">it</span> <span class="keyword">is</span> <span class="keyword">less than</span> <span class="number">1</span> <span class="keyword">second</span>, <span class="keyword">then</span> <span class="keyword">the</span>
   RTO SHOULD be rounder up <span class="keyword">to</span> <span class="number">1</span> <span class="keyword">second</span>.

<span class="number">1.5</span>. A maximum value MAY be placed <span class="function_start"><span class="keyword">on</span></span> RTO provided <span class="keyword">it</span> <span class="keyword">is</span> <span class="keyword">at</span> least <span class="number">60</span> seconds.
</code></pre><p>RTTVAR表示的是平滑过的平均偏差，SRTT表示的平滑过的RTT。这两个值的具体含义会在后面介绍<br>具体实现的时候进一步的解释。<br>以上是计算一个初始RTO值的过程，当连续出现RTO超时后，<br>RTO值会用一个叫做指数回避的策略进行调整，下面来具体介绍。  </p>
<hr>
<h3 id="RTO_timer的管理">RTO timer的管理</h3>
<pre><code><span class="number">2.1</span>. 发送一个带有数据的包后，如果RTO <span class="built_in">timer</span>未启动，启动RTO <span class="built_in">timer</span>  

<span class="number">2.2</span>. 当所有发送的数据都被确认后，关闭RTO <span class="built_in">timer</span>

<span class="number">2.3</span>. 当收到一个ACK确认了新数据后，重新设置RTO时间为当前RTO值

如果RTO超时了
<span class="number">2.4</span>. 重传最早的一个未被确认的数据包(序号最小的，即tp-&gt;snd_una)

<span class="number">2.5</span>. RTO &lt;- RTO * <span class="number">2</span> (<span class="string">"back off the timer"</span>，即指数回避策略)

<span class="number">2.6</span>. 重现设定RTO时间为当前RTO值

<span class="number">2.7</span>. 如果是在等待SYN包的ACK时RTO超时的，在连接建立之后，会将RTO从TCP_TIMEOUT_INIT
   改为TCP_TIMEOUT_FALLBACK(<span class="number">3</span>s)
   就是如果syn包被重传过，则上一节第一步中的RTO则会从<span class="number">1</span>s被重设为<span class="number">3</span>s。
</code></pre><hr>
<h3 id="RFC6298中的其他要点">RFC6298中的其他要点</h3>
<pre><code>Note that <span class="operator">a</span> TCP implementation MAY <span class="built_in">clear</span> SRTT <span class="operator">and</span> RTTVAR <span class="keyword">after</span>
backing off <span class="operator">the</span> timer multiple times <span class="keyword">as</span> <span class="keyword">it</span> is likely that <span class="operator">the</span> current
SRTT <span class="operator">and</span> RTTVAR are bogus <span class="operator">in</span> this situation.  Once SRTT <span class="operator">and</span> RTTVAR
are cleared, they should be initialized <span class="operator">with</span> <span class="operator">the</span> next RTT sample
taken per (<span class="number">1.2</span>) rather than <span class="keyword">using</span> (<span class="number">1.3</span>). 

<span class="number">1.1</span>和<span class="number">2.7</span>是RFC6298与RFC2988的主要不同，RFC6298在Appendix A中详细解释了为什么将INIT_RTO从
<span class="number">3</span>s降到<span class="number">1</span>s。里面有一些dataset的测试数据证明，有兴趣的话可以看一看。  
</code></pre><hr>
<h3 id="Linux实现之RTO计算">Linux实现之RTO计算</h3>
<p>以下开始分析Linux 3.10关于RTO的具体实现，序号与RFC原理中的需要一一对应。<br>首先是RTO计算相关的部分。<br>在理解这部分代码之前，有几个关键变量需要解释一下。<br>tp-&gt;srtt实际上存的是8<em>SRTT，而tp-&gt;rttvar实际上存储的是4</em>RTTVAR。<br>所以在后续代码注释中，也会使用大小写加以区分。使用大写时与RFC定义的变量含义一致。  </p>
<pre><code><span class="number">1.1</span><span class="built_in">.</span> 对应在net/ipv4/tcp<span class="built_in">.</span>c line372 tcp_init_sock()
    <span class="attribute">...</span>
    tcp_init_xmit_timers(sk);       <span class="comment">// 初始化tcp中timer对应的处理函数</span>
    <span class="attribute">...</span>
    icsk<span class="subst">-&gt;</span>icsk_rto <span class="subst">=</span> TCP_TIMEOUT_INIT;  <span class="comment">// 初始RTO设为1s</span>
    tp<span class="subst">-&gt;</span>mdev <span class="subst">=</span> TCP_TIMEOUT_INIT;        <span class="comment">// 初始medium deviation为1s</span>
    <span class="attribute">...</span>

<span class="number">1.2</span><span class="built_in">.</span> 对应net/ipv4/tcp_input<span class="built_in">.</span>c line639 tcp_rtt_estimator()
    <span class="attribute">...</span>
    <span class="keyword">if</span> (tp<span class="subst">-&gt;</span>srtt <span class="subst">!=</span> <span class="number">0</span>) {
        <span class="attribute">...</span>
    } <span class="keyword">else</span> {    <span class="comment">// 第一次获取RTT sample</span>
        tp<span class="subst">-&gt;</span>srtt <span class="subst">=</span> m <span class="subst">&lt;&lt;</span> <span class="number">3</span>;  <span class="comment">// SRTT = RTT, 需要注意的是tp-&gt;srtt存的是8*SRTT</span>

        <span class="comment">/* RTTVAR = RTT/2, 需要注意的是tp-&gt;rttvar存的是4*RTTVAR
         * tcp_rto_min(sk)限制了rttvar的最小值为TCP_RTO_MIN(HZ/5)=200ms */</span>
        tp<span class="subst">-&gt;</span>mdev <span class="subst">=</span> m <span class="subst">&lt;&lt;</span> <span class="number">1</span>;  
        tp<span class="subst">-&gt;</span>mdev_max <span class="subst">=</span> tp<span class="subst">-&gt;</span>rttvar <span class="subst">=</span> <span class="keyword">max</span>(tp<span class="subst">-&gt;</span>mdev, tcp_rto_min(sk));

        <span class="comment">/* 记录引起rttvar改变的序列号，用于后续判断是否过了一个RTT，这是常用技巧 */</span>
        tp<span class="subst">-&gt;</span>rtt_seq <span class="subst">=</span> tp<span class="subst">-&gt;</span>snd_nxt;  <span class="comment">// 注意这里是snd_nxt，不是snd_una</span>
    }

<span class="number">1.3</span><span class="built_in">.</span> 对应net/ipv4/tcp_input<span class="built_in">.</span>c line639 tcp_rtt_estimator()
    long m <span class="subst">=</span> mrtt; <span class="comment">// RTT</span>
    <span class="keyword">if</span> (m <span class="subst">==</span> <span class="number">0</span>)
        m <span class="subst">=</span> <span class="number">1</span>;
    <span class="keyword">if</span> (tp<span class="subst">-&gt;</span>srtt <span class="subst">!=</span> <span class="number">0</span>) {
        m <span class="subst">-=</span> (tp<span class="subst">-&gt;</span>srtt <span class="subst">&gt;&gt;</span> <span class="number">3</span>);   <span class="comment">// m = RTT - SRTT</span>
        tp<span class="subst">-&gt;</span>srtt <span class="subst">+=</span> m;          <span class="comment">// 8SRTT = 7 * SRTT + 1 * RTT</span>
        <span class="keyword">if</span> (m <span class="subst">&lt;</span> <span class="number">0</span>) {
            m <span class="subst">=</span> <span class="attribute">-m</span>;             <span class="comment">// m = |RTT - SRTT|</span>
            m <span class="subst">-=</span> (tp<span class="subst">-&gt;</span>mdev <span class="subst">&gt;&gt;</span> <span class="number">2</span>);   <span class="comment">// m = |RTT - SRTT| - RTTVAR</span>
            <span class="keyword">if</span> (m <span class="subst">&gt;</span> <span class="number">0</span>)  
                <span class="comment">/* 此处m&gt;0意味着，RTT与SRTT之间的波动过大，甚至烧过了RTTVAR
                 * 因此选择使用更小的beta值= 1/(4*8)
                 *      执行下面语句后，再执行tp-&gt;mdev += m则会得到如下结果
                 *      RTTVAR = (1-1/32)RTTVAR + |RTT - SRTT|
                 * 这样做的目的是避免突发的RTT变化，对RTTVAR的历史记录造成过大的影响
                 */</span>
                m <span class="subst">&gt;&gt;=</span> <span class="number">3</span>;    <span class="comment">// m = 1/8 (|RTT - SRTT| - RTTVAR)</span>
        } <span class="keyword">else</span> {
            m <span class="subst">-=</span> (tp<span class="subst">-&gt;</span>mdev <span class="subst">&gt;&gt;</span> <span class="number">2</span>);   <span class="comment">// m = |RTT - SRTT| - RTTVAR</span>
        }
        tp<span class="subst">-&gt;</span>mdev <span class="subst">+=</span> m;              <span class="comment">// 4RTTVAR = 3RTTVAR + |RTT - SRTT|</span>
        <span class="keyword">if</span> (tp<span class="subst">-&gt;</span>mdev <span class="subst">&gt;</span> tp<span class="subst">-&gt;</span>mdev_max) {
            tp<span class="subst">-&gt;</span>mdev_max <span class="subst">=</span> tp<span class="subst">-&gt;</span>mdev;
            <span class="keyword">if</span> (tp<span class="subst">-&gt;</span>mdev_max <span class="subst">&gt;</span> tp<span class="subst">-&gt;</span>rttvar)
                <span class="comment">/* 真正的RTTVAR会取一个RTT中最大的RTTVAR，是一种相对保守的策
                 * 因为计算略微偏大的RTO不会引起大问题，
                 * 但如果计算的RTO偏小则可能引起spurious retransmission
                tp-&gt;rttvar = tp-&gt;mdev_max;  
        }
        /* 如果过了一个RTT，则重置mdev_max，并适当调整rttvar */</span>
        <span class="keyword">if</span> (after(tp<span class="subst">-&gt;</span>snd_una, tp<span class="subst">-&gt;</span>rtt_seq)) {  
            <span class="comment">/* 目前看到的代码里面唯一可能导致mdev_max &lt; rttvar的代码就是
             *      tp-&gt;mdev_max = tcp_rto_min(sk);
             */</span>
            <span class="keyword">if</span> (tp<span class="subst">-&gt;</span>mdev_max <span class="subst">&lt;</span> tp<span class="subst">-&gt;</span>rttvar)
                tp<span class="subst">-&gt;</span>rttvar <span class="subst">-=</span> (tp<span class="subst">-&gt;</span>rttvar <span class="subst">-</span> tp<span class="subst">-&gt;</span>mdev_max) <span class="subst">&gt;&gt;</span> <span class="number">2</span>;
            tp<span class="subst">-&gt;</span>rtt_seq <span class="subst">=</span> tp<span class="subst">-&gt;</span>snd_nxt;
            tp<span class="subst">-&gt;</span>mdev_max <span class="subst">=</span> tcp_rto_min(sk);     <span class="comment">// 每过一个RTT重置mdev_max</span>
        }
    }

<span class="number">1.4</span> 根据代码和实际测量值，均未发现Linux有将RTO设置round <span class="keyword">to</span> <span class="number">1</span>s了

<span class="number">1.5</span> net/ipv4/tcp_input<span class="built_in">.</span>c line705 tcp_set_rto()
    <span class="comment">/*1.2和1.3都只是计算srtt和rttvar，并未计算rto */</span>
    inet_csk(sk)<span class="subst">-&gt;</span>icsk_rto <span class="subst">=</span> __tcp_set_rto(tp);     <span class="comment">// 根据srtt和rttvar计算rto</span>
    tcp_bound_rto(sk);                              <span class="comment">// 限制rto的最大值</span>

其中，__tcp_set_rto(tp)和tcp_bound_rto(sk)的代码如下：
    static <span class="keyword">inline</span> u32 __tcp_set_rto(const struct tcp_sock <span class="subst">*</span>tp)
    {
        <span class="keyword">return</span> (tp<span class="subst">-&gt;</span>srtt <span class="subst">&gt;&gt;</span> <span class="number">3</span>) <span class="subst">+</span> tp<span class="subst">-&gt;</span>rttvar;    <span class="comment">// RTO = SRTT + 4 * RTTVAR</span>
    }

    static <span class="keyword">inline</span> <span class="literal">void</span> tcp_bound_rto(const struct sock <span class="subst">*</span>sk)
    {
        <span class="keyword">if</span> (inet_csk(sk)<span class="subst">-&gt;</span>icsk_rto <span class="subst">&gt;</span> TCP_RTO_MAX)
            inet_csk(sk)<span class="subst">-&gt;</span>icsk_rto <span class="subst">=</span> TCP_RTO_MAX;   <span class="comment">// TCP_RTO_MAX = 120s</span>
    }
</code></pre><p>为了更好的理解RTT采样和RTO的整体流程，可以参考<a href="http://blog.csdn.net/zhangskd/article/details/7196707" target="_blank" rel="external">这篇资料</a>，尤其是最后一张函数关系调用图。<br>关键就是理解下面这个函数的调用过程  </p>
<pre><code><span class="keyword">void</span> tcp_valid_rtt_meas(<span class="class"><span class="keyword">struct</span> <span class="title">sock</span> *sk, u32 seq_rtt)
</span>{
    tcp_rtt_estimator(sk, seq_rtt);     <span class="comment">// 根据RTT sample，更新SRTT和RTTVAR</span>
    tcp_set_rto(sk);                    <span class="comment">// 重新计算RTO值</span>
    inet_csk(sk)-&gt;icsk_backoff = <span class="number">0</span>;     <span class="comment">// 将backoff清零</span>
}
</code></pre><hr>
<h3 id="Linux实现之RTO_timer的管理">Linux实现之RTO timer的管理</h3>
<pre><code><span class="number">2.1</span> net/ipv4/tcp_output.c line72 tcp_event_new_data_sent()
<span class="keyword">...</span>
unsigned int prior_packets = tp-&gt;packets_out;
<span class="keyword">...</span>
tp-&gt;packets_out += tcp_skb_pcount(skb); // 更新已经发出未被确认的数据包数目
<span class="keyword">if</span> (!prior_packets      // 如果prior_packets=<span class="number">0</span>，表示之前未发送过数据，因此需要启动timer
    ||<span class="keyword">...</span>)
    tcp_rearm_rto(sk);  // 启动RTO timer

<span class="number">2.2</span> net/ipv4/tcp_input.c line2926 tcp_rearm_rto()
<span class="keyword">...</span>
/* 如果packet_out=<span class="number">0</span>，则停掉RTO timer */
<span class="keyword">if</span> (!tp-&gt;packets_out) {
    inet_csk_clear_xmit_timer(sk, ICSK_TIME_RETRANS);   
}

<span class="number">2.3</span> net/ipv4/tcp_input.c line3105 tcp_clean_rtx_queue()
<span class="keyword">...</span>
<span class="keyword">if</span> (flag &amp; FLA_ACKED) {
    <span class="keyword">...</span>
    tcp_ack_update_rtt(sk, flag, seq_rtt);  // 得到一个RTT sample，更新RTO
    tcp_rearm_rto(sk);                      // 重设RTO timer
    <span class="keyword">...</span>
}

<span class="number">2.4</span>+<span class="number">2.5</span>+<span class="number">2.6</span> net/ipv4/tcp_timer.c line340 tcp_retransmit_timer()
<span class="keyword">...</span>
tcp_enter_loss(sk, <span class="number">0</span>);  // 进入RTO超时重传阶段
<span class="keyword">if</span> (tcp_retransmit_skb(sk, tcp_write_queue_head(sk)) &gt; <span class="number">0</span>) // 重传第一个未确认的数据包
<span class="keyword">...</span>

/* 如果这是一个thin的TCP流，则不适用backoff机制 
 * 什么是thin tcp呢？就是网络中in_flight的数据包很少的流
 * 具体请看tcp_stream_is_thin(tp)
 */
<span class="keyword">if</span> (STREAM IS THIN ?) { 
    icsk-&gt;icsk_backoff = <span class="number">0</span>;
    icsk-&gt;icsk_rto = min(__tcp_set_rto(tp), TCP_RTO_MAX);
} <span class="keyword">else</span> {
    /* Use normal (exponential) backoff */  
    icsk-&gt;icsk_rto = min(icsk-&gt;icsk_rto &lt;&lt; <span class="number">1</span>, TCP_RTO_MAX); // 步骤<span class="number">2.5</span>
}
/* 步骤<span class="number">2.6</span> 重设RTO timer */
inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS, icsk-&gt;icsk_rto, TCP_RTO_MAX);

<span class="number">2.7</span> net/ipv4/tcp_metrics.c line441 tcp_init_metrics()
/* tcp_init_metrics是在TCP建立连接之后进行的初始化动作
 * 一个明显的例子： tcp_finish_connect() =&gt; tcp_init_metrics()
 */
<span class="keyword">...</span>
<span class="keyword">if</span> (tp-&gt;srtt == <span class="number">0</span>) {
    /* 如果在3WHS阶段没有获得srtt，基本就意味着发生了重传 */
    tp-&gt;mdev = tp-&gt;mdev_max = tp-&gt;rttvar = TCP_TIMEOUT_FALLBACK;
    inet_csk(sk)-&gt;icsk_rto = TCP_TIMEOUT_FALLBACK;
}  
</code></pre><p>至此，基本上把Linux 3.10中关于RTO的基本逻辑弄清楚了。RFC6298中proposed的算法的<br>主要步骤也找到了对应的代码实现位置。   </p>
<hr>
<h3 id="参考资料">参考资料</h3>
<p><a href="http://tools.ietf.org/html/rfc6298" target="_blank" rel="external">RFC 6298</a><br><a href="http://blog.csdn.net/zhangskd/article/details/7196707" target="_blank" rel="external">TCP中RTT的测量和RTO的计算</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>RTO的准确计算对于TCP的可靠性传输和性能都具有重要作用。<br>这篇文章首先介绍最新的RFC中对于RTO的计算方法，然后结合Linux 3.10的源码对<br>具体的实现进行分析和理解。  </p>
]]>
    
    </summary>
    
      <category term="rtt" scheme="http://perthcharles.github.com/tags/rtt/"/>
    
      <category term="rto" scheme="http://perthcharles.github.com/tags/rto/"/>
    
      <category term="rfc6298" scheme="http://perthcharles.github.com/tags/rfc6298/"/>
    
      <category term="wiki-network" scheme="http://perthcharles.github.com/categories/wiki-network/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[TCP timestamp]]></title>
    <link href="http://perthcharles.github.com/2015/08/27/timestamp-intro/"/>
    <id>http://perthcharles.github.com/2015/08/27/timestamp-intro/</id>
    <published>2015-08-27T13:00:35.000Z</published>
    <updated>2015-08-30T13:31:14.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>tcp_timestamps是在<a href="http://tools.ietf.org/html/rfc1323" target="_blank" rel="external">RFC 1323</a>中定义的一个TCP选项。<br>这篇wiki介绍一下timestamps的设计目的和相关原理，尤其强调一些比较tricky的地方。<br><a id="more"></a>  </p>
<hr>
<h3 id="关于RFC1323">关于RFC1323</h3>
<p>这是一篇介绍针对High-bandwidth, Long delay链路设计的一些TCP扩展选项的资料。强烈推荐阅读！<br>但这篇RFC其实已经被<a href="http://tools.ietf.org/html/rfc7323" target="_blank" rel="external">RFC7323</a>所取代，不过RFC1323对于了解timestamp相关的基本概念来说还是足够了的。关于RFC7323也会在后续的wiki中详细的介绍。  </p>
<p>High-bandiwidth, Long delay链路面临的性能问题  </p>
<pre><code>a. Window Size limit  
TCP头部仅16字节用于存放receive window，这在高BDP的链路中往往是不够用的  
解决办法就是引入window scale选项，然后real<span class="emphasis">_rcv_</span>wnd = rcv<span class="emphasis">_wnd_</span>in<span class="emphasis">_tcp_</span>header * (2^win_scale)  

b. Recovery from Losses  
当BDP很大时，意味着需要更大的cwnd来充分利用带宽。如果发生网络丢包，则对这类链路的影响是巨大的。  
优化办法(真的不能说解决T_T)就是引入[<span class="link_label">SACK</span>](<span class="link_url">https://tools.ietf.org/html/rfc2018</span>)机制，来为发送方重传提供更加准确的信息。  

c. Round-Trip Measurement  
TCP作为可靠的传输协议，一个重要的机制就是超时重传。因此如何计算一个准确(合适)的
RTO对于TCP性能有着重要的影响。而tcp_timestamp选项正是<span class="emphasis">*主要*</span>为此而设计的。  
</code></pre><p>上一句话强调”主要”是因为tcp_timestamp还被用于PAWS机制，而这一重要用途却时常被忽略。<br>作为一个可靠的传输协议，TCP除了考虑如何应对性能问题，还需要考虑可靠性问题。<br>即使这些问题发生的概率较低，PAWS就是其中一个例子。<br>PAWS(Protect Against Wrapped Sequence numbers)一句话解释如下，后面会详细介绍  </p>
<pre><code>在高带宽下，TCP序列号可能在较短的时间内就被重复使用(recycle/wrapped)
就可能导致同一条TCP流在短时间内出现序号一样的两个合法的数据包及其确认包！
</code></pre><p>补充一句：什么用wrapped形容序列号被重复使用？因为压圈了呀 :)  </p>
<hr>
<h3 id="tcp_timestamps_的设计">tcp_timestamps 的设计</h3>
<p>tcp_timestamps的本质是记录数据包的发送时间。基本的步骤如下  </p>
<pre><code><span class="bullet">1. </span>发送方在发送数据时，将一个timestamp(表示发送时间)放在包里面
<span class="bullet">2. </span>接收方在收到数据包后，在对应的ACK包中将收到的timestamp返回给发送方(echo back)
<span class="bullet">3. </span>发送发收到ACK包后，用当前时刻now - ACK包中的timestamp就能得到准确的RTT
</code></pre><p>当然实际运用中要考虑到RTT的波动，因此有了后续的(Round-Trip Time Measurement)RTTM机制</p>
<p>TCP Timestamps Option (TSopt)具体设计如下  </p>
<pre><code>Kind: 8             // 标记唯一的选项类型，比如window scale是3
<span class="header">Length: 10 bytes    // 标记Timestamps选项的字节数
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span>
<span class="header">| Kind=8 | Length=10 | TS Value (TSval) | TS ECho Reply (TSecr) |
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span>
<span class="code">    1          1             4                       4</span>
</code></pre><p>timestamps一个双向的选项，当一方不开启时，两方都将停用timestamps。<br>比如client端发送的SYN包中带有timestamp选项，但server端并没有开启该选项。<br>则回复的SYN-ACK将不带timestamp选项，同时client后续回复的ACK也不会带有timestamp选项。<br>当然，如果client发送的SYN包中就不带timestamp，双向都将停用timestamp。  </p>
<hr>
<h3 id="为什么需要timestamp">为什么需要timestamp</h3>
<p>如果没有timestamp，RTT的计算会怎样？  </p>
<pre><code><span class="number">1</span>. <span class="constant">TCP层</span>在发送出一个<span class="constant">SKB时</span>，使用skb-&gt;<span class="keyword">when</span>记录发送出去的时间
<span class="number">2</span>. <span class="constant">TCP层</span>在收到<span class="constant">SKB数</span>据包的确认时，使用now - skb-&gt;<span class="keyword">when</span>来计算<span class="constant">RTT</span>
</code></pre><p>但上面的机制在丢包发生时会有问题，比如</p>
<pre><code><span class="bullet">1. </span>TCP层第一次发送SKB的时间是send<span class="emphasis">_time1, TCP层重传一个数据包的时间是send_</span>time2
<span class="bullet">2. </span>当TCP层收到SKB的确认包的时间是recv_time
</code></pre><p>但是RTT应该是 (recv_time - send_time1)呢，还是(recv_time - send_time2)呢？  </p>
<p>以上两种方式都不可取！因为无法判断出recv_time对应的ACK是确认第一次数据包的发送还是确认<br>重传数据包。因此TCP协议栈只能选择非重传数据包进行RTT采样。但是当出现严重丢包(比如整个窗口全部丢失)时，就完全没有数据包可以用于RTT采样。这样后续计算SRTT和RTO就会出现较大的偏差。  </p>
<p>timestamp选项很好的解决了上述问题，因为ACK包里面带的TSecr值，一定是触发这个ACK的数据包在发送端发送的时间。不管数据包是否重传都能准确的计算RTT(前提是TSecr遵循RTTM中的计算原则)。  </p>
<p>当然timestamp不仅解决了RTT计算的问题，还很好的为PAWS机制提供的信息依据。  </p>
<hr>
<h3 id="开启timestamp会有什么负面影响?">开启timestamp会有什么负面影响?</h3>
<p>这部分内容以后会根据更多的实际经验来补充。目前列举一些找到的分析。  </p>
<pre><code><span class="number">1.</span> <span class="number">10</span>字节的TCP header开销

<span class="number">2.</span> The TCP Timestamp when enabled will allow you <span class="built_in">to</span> guess <span class="operator">the</span> uptime
   <span class="operator">of</span> <span class="operator">a</span> target <span class="keyword">system</span> (nmap v -O . Knowing how <span class="keyword">long</span> <span class="operator">a</span> <span class="keyword">system</span> has been
   up will enable you <span class="built_in">to</span> determine whether security patches that <span class="built_in">require</span>
   reboot has been applied <span class="operator">or</span> <span class="operator">not</span>.
        引自：<span class="keyword">http</span>://stackoverflow.com/questions/<span class="number">7880383</span>/what-benefit-is-conferred-<span class="keyword">by</span>-tcp-timestamp
        注：如果通过热补丁修复bug，是否就能够避免这个问题？  
</code></pre><hr>
<h3 id="什么是RTTM">什么是RTTM</h3>
<p>RTTM规定了一些使用TSecr计算RTT的原则，具体如下<br>(英文水平有限，为保持原意就使用RFC中的原话了)  </p>
<pre><code><span class="operator">a</span>.  A TSecr <span class="built_in">value</span> received <span class="operator">in</span> <span class="operator">a</span> segment is used <span class="built_in">to</span> update <span class="operator">the</span>
    averaged RTT measurement only <span class="keyword">if</span> <span class="operator">the</span> segment acknowledges
    some <span class="built_in">new</span> data
b.  The data-sender TCP must measure <span class="operator">the</span> <span class="keyword">effective</span> RTT, including <span class="operator">the</span> additional
    <span class="built_in">time</span> due <span class="built_in">to</span> delayed ACKs. Thus, when delayed ACKs are <span class="operator">in</span> use, <span class="operator">the</span> receiver should
    reply <span class="operator">with</span> <span class="operator">the</span> TSval field <span class="built_in">from</span> <span class="operator">the</span> earliest
c.  An ACK <span class="keyword">for</span> <span class="operator">an</span> out-<span class="operator">of</span>-order segment should therefore contain <span class="operator">the</span> 
    timestamp <span class="built_in">from</span> <span class="operator">the</span> most recent segment that advanced <span class="operator">the</span> window
d.  The timestamp <span class="built_in">from</span> <span class="operator">the</span> latest segment (which filled <span class="operator">the</span> hole) must be echoed
        在ACK被重传的数据时，应该使用重传数据包中的TSval进行回复
</code></pre><p>如果对以上的特殊情况有疑问，还请直接去看RFC，里面有example解释。  </p>
<p>最后，实际上计算RTO除了以上使用TSecr的原则外，还有一些更复杂的计算方法<a href="http://tools.ietf.org/html/rfc7323" target="_blank" rel="external">RFC 7323</a>。<br>比如对于每一个RTT采样R，  </p>
<pre><code><span class="constant">RTTVAR</span> = (<span class="number">1</span> - beta) * RTTVAR + beta * |SRTT - R|
<span class="constant">SRTT</span> = (<span class="number">1</span> - alpha) * SRTT + alpha * R
</code></pre><hr>
<h3 id="什么是PAWS">什么是PAWS</h3>
<p>PAWS — Protect Againest Wrapped Sequence numbers<br>目的是解决在高带宽下，TCP序号可能被重复使用而带来的问题。  </p>
<p>PAWS同样依赖于timestamp，并且假设在一个TCP流中，<em>按序</em>收到的所有TCP包的timestamp值<br>都是线性递增的。而在正常情况下，每条TCP流<em>按序</em>发送的数据包所带的timestamp值<br>也确实是线性增加的。<br>至于为什么要强调<em>按序</em>，请先自行思考。:)  </p>
<p>首先给出几个变量的定义，之后具体介绍PAWS的工作过程  </p>
<pre><code>Per-Connection State Variables
<span class="label">    TS.Recent:</span>       Latest received Timestamp
<span class="label">    Last.ACK.sent:</span>   Last ACK field sent

<span class="preprocessor">Option</span> Fields <span class="keyword">in</span> Current <span class="built_in">Segment</span>
<span class="label">    SEG.TSval:</span>   TSval field from TSopt <span class="keyword">in</span> current <span class="built_in">segment</span>.
<span class="label">    SEG.TSecr:</span>   TSecr field from TSopt <span class="keyword">in</span> current <span class="built_in">segment</span>.
</code></pre><p>TS.Recent存放着<em>按序</em>达到的所有TCP数据包的最晚的一个时间戳，即只有在<br><code>SEG.SEQ &lt;= Last.ACK.sent &lt; SEG.SEG + SEG.LEN</code>(有新的数据被按序确认了)时，<br>才会去更新TS.Recent的值。  </p>
<pre><code>假设三个数据包的*第一次*发送时间分别是<span class="literal">A</span>，B和C(<span class="literal">A</span> &lt; B &lt; C)，但<span class="literal">A</span>和C含有相同的序列号。
而<span class="literal">A</span>数据包由于某种原因，在阻塞在了网络中，因此发送方进行了重传，重传时间为A2

PAWS要解决的主要问题就是：
    当接收端在接收到A2后，又接着确认到了数据包B，下一个想接收的数据是数据包C
    此时如果收到了数据包<span class="literal">A</span>(<span class="literal">A</span>从阻塞中恢复过来了，但并未真的丢失)，
    由于<span class="literal">A</span>与C的序列号是相同的。如果没有别的保护措施就会出现数据紊乱，没有做到可靠传输

PAWS的做法就是，如果收到的一个TCP数据包的timestamp值小于TS.Recnt，则会丢弃该数据包。  
因此数据包<span class="literal">A</span>到达接收方后，接收方的TS.Recent应该是数据包B中的timestamp
而<span class="literal">A</span> &lt; B，故<span class="literal">A</span>包就会被丢弃。而真正有效的数据C到达接收后，由于B &lt; C，因此能被正常接收
</code></pre><p>PAWS的更多细节  </p>
<pre><code><span class="number">1.</span> It is recommended that RST segments NOT carry timestamps, <span class="operator">and</span> that
RST segments be acceptable regardless <span class="operator">of</span> their timestamp.

<span class="number">2.</span> PAWS is defined strictly <span class="operator">within</span> <span class="operator">a</span> single connection; <span class="operator">the</span> <span class="keyword">last</span> timestamp is
TS.Recent is kept <span class="operator">in</span> <span class="operator">the</span> connection control block, <span class="operator">and</span>
discarded when <span class="operator">a</span> connection is closed.

<span class="number">3.</span> An additional mechanism could be added <span class="built_in">to</span> <span class="operator">the</span> TCP, <span class="operator">a</span> per-host
cache <span class="operator">of</span> <span class="operator">the</span> <span class="keyword">last</span> timestamp received <span class="built_in">from</span> <span class="keyword">any</span> connection.
This <span class="built_in">value</span> could <span class="keyword">then</span> be used <span class="operator">in</span> <span class="operator">the</span> PAWS mechanism <span class="built_in">to</span> reject
old duplicate segments <span class="built_in">from</span> earlier incarnations <span class="operator">of</span> <span class="operator">the</span>
connection, <span class="keyword">if</span> <span class="operator">the</span> timestamp clock can be guaranteed <span class="built_in">to</span> have
ticked <span class="keyword">at</span> least once since <span class="operator">the</span> old connection was <span class="built_in">open</span>.
</code></pre><p>从第三点可以看到，如果针对per-host的使用PAWS中的机制，则会解决TIME-WAIT中考虑的上一个流<br>的数据包在下一条流中被当做有效数据包的情况，这样就没有必要等待2*MSL来结束TIME-WAIT了。<br>只要等待足够的RTO，解决好需要重传最后一个ACK的情况就可以了。<br>因此Linux就实现了这样一种机制：</p>
<pre><code>当timestamp和tw_recycle两个选项同时开启的情况下，开启per-host的PAWS机制。
从而能快速回收处于<span class="typename">TIME</span>-<span class="keyword">WAIT</span>状态的TCP流。
</code></pre><p>但这样真的就能完美的解决令无数人头疼的TIME-WAIT吗？答案是否定的！<br>因为公网中存在太多的NAT设置，当使用per-host的PAWS机制时，是无法保证timestamp是线性递增这一假设的。因为使用同一个NAT地址的两个真实的机器，他们的timestamp是不能保证同步的(其实一致也没有用，NAT就是per-host PAWS机制的死敌)。<br>关于这个问题也会在以后的一篇介绍TIME-WAIT的wiki中进一步详细介绍。  </p>
<hr>
<h3 id="总结">总结</h3>
<pre><code>timestamp为TCP/IP协议栈提供了两个功能：  
    <span class="operator">a</span>. 更加准确的RTT测量数据，尤其是有丢包时  <span class="comment">-- RTTM  </span>
    b. 保证了在极端情况下，TCP的可靠性        <span class="comment">-- PAWS  </span>
</code></pre><hr>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt" target="_blank" rel="external">Documentation: ip-sysctl.txt</a><br><a href="http://tools.ietf.org/html/rfc1323" target="_blank" rel="external">RFC 1323: TCP Extensions for High Performance</a><br><a href="http://tools.ietf.org/html/rfc7323" target="_blank" rel="external">RFC 7323: TCP Extensions for High Performance</a><br><a href="https://tools.ietf.org/html/rfc2018" target="_blank" rel="external">SACK</a><br><a href="http://stackoverflow.com/questions/7880383/what-benefit-is-conferred-by-tcp-timestamp" target="_blank" rel="external">What benefit is conferred by TCP timestamp?</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>tcp_timestamps是在<a href="http://tools.ietf.org/html/rfc1323" target="_blank" rel="external">RFC 1323</a>中定义的一个TCP选项。<br>这篇wiki介绍一下timestamps的设计目的和相关原理，尤其强调一些比较tricky的地方。<br>]]>
    
    </summary>
    
      <category term="timestamp" scheme="http://perthcharles.github.com/tags/timestamp/"/>
    
      <category term="RTTM" scheme="http://perthcharles.github.com/tags/RTTM/"/>
    
      <category term="PAWS" scheme="http://perthcharles.github.com/tags/PAWS/"/>
    
      <category term="wiki-network" scheme="http://perthcharles.github.com/categories/wiki-network/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[一个NAT问题引起的思考]]></title>
    <link href="http://perthcharles.github.com/2015/08/27/timestamp-NAT/"/>
    <id>http://perthcharles.github.com/2015/08/27/timestamp-NAT/</id>
    <published>2015-08-27T12:45:17.000Z</published>
    <updated>2015-08-31T08:11:07.000Z</updated>
    <content type="html"><![CDATA[<hr>
<h3 id="问题">问题</h3>
<p>当服务器同时开启tcp_timestamps和tcp_tw_recycle选项时，会导致客户反馈连接成功率降低的情况。<br>but why ???<br><a id="more"></a>  </p>
<hr>
<h3 id="公网NAT的存在">公网NAT的存在</h3>
<p>NAT的全称是：<a href="https://en.wikipedia.org/wiki/Network_address_translation" target="_blank" rel="external">Network Address Translation</a>。<br>一个具体的例子就是家用的局域网络。<br>当使用一台无线路由器进行上网拨号后，其他的终端设备只要连接进入该无线路由器的WiFi<br>网络内就可以访问外网了。此时正是NAT在发挥作用。<br>每一台终端设备在接入无线路由器后，只是获得一个局域网IP地址，而当你在百度输入我的IP的时候<br>你看到的IP地址则是你无线路由器的公网IP地址。家用无线路由器完成的一个主要工作正是将终端<br>的局域网IP地址进行NAT转换为公网IP地址。  </p>
<p>从上面这个简单的例子可以看到NAT在真实的互联网中是普遍存在的，比如你所在学校，单位都会一定程度上的使用NAT机制。  </p>
<hr>
<h3 id="Per-host_PAWS机制">Per-host PAWS机制</h3>
<p>在<a href="http://perthcharles.github.io/2015/08/27/timestamp-intro/" target="_blank" rel="external">这篇介绍TCP timestamp</a><br>的文章中提到了一种针对per-host的PAWS机制。这种机制要求所有来个同一个host IP的TCP数据包的<br>timestamp值是递增的。当收到一个timestamp值，小于服务端记录的对应值后，则会认为这是一个过期的数据包，然后会将其丢弃。  </p>
<hr>
<h3 id="解答问题">解答问题</h3>
<p>至此就不难解释为什么在同时开启tcp_timestamp和tcp_tw_recycle时，会遇到客户反馈连接成功率降低的情况了，基本的逻辑如下：  </p>
<pre><code><span class="bullet">1. </span>同时开启tcp<span class="emphasis">_timestamp和tcp_</span>tw_recycle会启用TCP/IP协议栈的per-host的PAWS机制
<span class="bullet">2. </span>经过同一NAT转换后的来自不同真实client的数据流，在服务端看来是于同一host打交道
<span class="bullet">3. </span>虽然经过同一NAT转化，但由于不同真实client会携带各自的timestamp值
因而无法保证整过NAT转化后的数据包携带的timestamp值严格递增
<span class="bullet">4. </span>当服务器的per-host PAWS机制被触发后，会丢弃timestamp值不符合递增条件的数据包
</code></pre><p>解决办法就是不建议同时开启tcp_timestamp和tcp_tw_recycle。<br>那到底怎么配置？  </p>
<pre><code>开启tcp_timestamp，但不要开tcp_tw_recycle  
开启tcp_timestamp，但不要开tcp_tw_recycle  
开启tcp_timestamp，但不要开tcp_tw_recycle  
</code></pre><p>因为timestamp有更多其他的作用，而tcp_tw_recycle本身就是依赖于timestamp的。在不开启timestamp的情况下，单独开启tcp_tw_recycle并没有什么用<br>其实上述强调三遍的配置，正是目前Linux的默认配置。所以说啊，不真正搞懂内核的参数选项，就不要盲目修改。尤其是在官方文档对tcp_tw_recycle已经强调了不要盲目修改的情况下  </p>
<pre><code>那为什么有人推荐同时开启tcp_timestamp和tcp_tw_recycle呢？
因为同时开启后，能够更快的回收<span class="typename">TIME</span>-<span class="keyword">WAIT</span>状态的socket    &lt;== 这也正是PAWS从per-conn在配置后扩展到per-host的目的  
只可惜逻辑是对的，但是没有考虑到公网广泛存在的NAT机制可能带来的问题。  
</code></pre><hr>
<h3 id="源码细节分析">源码细节分析</h3>
<p>这部分是linux 3.10源码部分的分析，算是对于以上理论分析提供的依据，不关系细节的话可以忽略本节  </p>
<pre><code><span class="comment">// tcp_v4_conn_request(), net/ipv4/tcp_ipv4.c line 1551</span>
<span class="keyword">if</span> (tmp_opt.saw_tstamp &amp;&amp;      <span class="comment">// 是否见到过tcp_timestamp选项</span>
    tcp_death_row.sysctl_tw_recycle &amp;&amp;   <span class="comment">// 接着判断是否开启recycle</span>
    (dst = inet_csk_route_req(sk, &amp;fl4, req)) != NULL &amp;&amp;    <span class="comment">// 最终判断saddr是否有相关记录在route表中</span>
    fl4.daddr == saffr) {
    <span class="keyword">if</span> (!tcp_peer_is_proven(req, dst, <span class="keyword">true</span>)) {  <span class="comment">// 如果这个建连请求不能被proven，则会被丢弃</span>
        NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_PAWSPASSIVEREJECTED);
        goto drop_and_release;
    }
}

<span class="comment">// tcp_peer_is_proven() net/ipv4/tcp_metrics.c line 536</span>
<span class="comment">// 负责判断接收到的request请求的timestamp是否符合要求，最重要的一段代码如下</span>
<span class="keyword">if</span> (tm &amp;&amp;
    <span class="comment">// 判断保存tcpm_ts_stamp值是否有效，TCP_PAWS_MSL=60</span>
    (<span class="keyword">u32</span>)get_seconds() - tm-&gt;tcpm_ts_stamp &lt; TCP_PAWS_MSL &amp;&amp;
    <span class="comment">// 如果记录值大于当前收到的req中的timestamp值，则丢弃。TCP_PAWS_WINDOW=1</span>
    (<span class="keyword">u32</span>)(tm-&gt;tcpm_ts - req-&gt;ts_recent) &gt; TCP_PAWS_WINDOW) {
        ret = <span class="keyword">false</span>;
}
</code></pre><p>至此可以看到：在tcp_timestamp和tcp_tw_recycle同时开启时，会触发Linux的per-host的PAWS机制  </p>
<p>接下来分析开启tcp_tw_recycle和tcp_timestamp时，是怎么快速回收TIME-WAIT的  </p>
<pre><code>// tcp_time_wait() net/ipv4/tcp_minisocks.c  line <span class="number">267</span>
<span class="keyword">...</span>
// ts_recent_stamp依赖于timestamp选项的开启，可进tcp_minisocks.c验证  
<span class="keyword">if</span> (tcp_death_row.sysctl_tw_recycle &amp;&amp; tp-&gt;rx_opt.ts_recent_stamp)
    recycle_ok = tcp_remember_stamp(s);
<span class="keyword">...</span>
// 如果能够recycle，则使用更短的rto作为timeout，从而更快回收TIME-WAIT
<span class="keyword">if</span> (timeo &lt; rto)
    timeo = rto;
<span class="keyword">if</span> (recycle_ok) {
    tw-&gt;tw_timeout = rto;
} <span class="keyword">else</span> {
    tw-&gt;tw_timeout = TCP_TIMEWAIT_LEN;
    <span class="keyword">if</span> (state == TCP_TIME_WAIT) 
        timeo = TCP_TIMEWAIT_LEN;    
}
inet_twsh_schedule(tw, &amp;tcp_death_row, timeo, TCP_TIMEWAIT_LEN);

// tcp_timewait_state_process() net/ipv4/tcp_minisocks.c line <span class="number">94</span>
// 另一条进入time-wait的路线有类似的代码
<span class="keyword">if</span> (tcp_death_row.sysctl_tw_recycle &amp;&amp;
    tcptw-&gt;tw_ts_recent_stamp &amp;&amp;
    tcp_tw_remember_stamp(tw))
        inet_twsk_schedule(tw, &amp;tcp_death_row, tw-&gt;tw_timeout,
                           TCP_TIMEWAIT_LEN);
<span class="keyword">else</span>
        inet_twsk_schedule(tw, &amp;tcp_death_row, TCP_TIMEWAIT_LEN,
                           TCP_TIMEWAIT_LEN);
</code></pre><hr>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt" target="_blank" rel="external">Documentation: ip-sysctl.txt</a><br><a href="http://tools.ietf.org/html/rfc1323" target="_blank" rel="external">RFC 1323:  TCP Extensions for High Performance</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<h3 id="问题">问题</h3>
<p>当服务器同时开启tcp_timestamps和tcp_tw_recycle选项时，会导致客户反馈连接成功率降低的情况。<br>but why ???<br>]]>
    
    </summary>
    
      <category term="tcp" scheme="http://perthcharles.github.com/tags/tcp/"/>
    
      <category term="NAT" scheme="http://perthcharles.github.com/tags/NAT/"/>
    
      <category term="time_wait" scheme="http://perthcharles.github.com/tags/time-wait/"/>
    
      <category term="Networking" scheme="http://perthcharles.github.com/categories/Networking/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[GIT系列五：小知识点及FAQ]]></title>
    <link href="http://perthcharles.github.com/2015/08/25/git-faq/"/>
    <id>http://perthcharles.github.com/2015/08/25/git-faq/</id>
    <published>2015-08-25T07:38:40.000Z</published>
    <updated>2015-08-31T14:20:20.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>git作为一个强大的工具，也就意味着它也同样的复杂。<br>长期使用下来难免会遇到很多奇奇怪怪的问题和一些小的知识点，<br>这个帖子就用来记录一下那些年某人踩过的的坑T_T  </p>
<p>这篇会慢慢更新，当某个点内容较多后，会独立出去成为一篇独立的wiki<br><a id="more"></a>  </p>
<hr>
<h3 id="小知识点">小知识点</h3>
<hr>
<h4 id="Fast_forward_merge">Fast forward merge</h4>
<p>直接上图例，不多解释  </p>
<pre><code>            <span class="comment">master</span>
               <span class="comment">↓</span>
<span class="comment">A</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">B</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">C</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">D</span>        <span class="comment">issue03</span>
                <span class="comment">\</span>          <span class="comment">↓</span>
                 <span class="comment">E</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">F</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">G</span>

                            <span class="comment">master</span>
                              <span class="comment">↓</span>
<span class="comment">A</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">B</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">C</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">D</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">E</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">F</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">G</span>
                              <span class="comment">↑</span>
                            <span class="comment">issue03</span>
</code></pre><p>以上就是一个fast forward merge，那什么不是fast forward merge呢？请看下图  </p>
<pre><code>            <span class="comment">master</span>
               <span class="comment">↓</span>
<span class="comment">A</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">B</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">C</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">D</span>        <span class="comment">issue03</span>
           <span class="comment">\</span>               <span class="comment">↓</span>
            <span class="comment">E</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">F</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">G</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">H</span>

                              <span class="comment">master</span>
                              <span class="comment">↓</span>
<span class="comment">A</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">B</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">C</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">D</span> <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span> <span class="comment">I</span>
           <span class="comment">\</span>                <span class="comment">/</span> <span class="comment">↑</span>
            <span class="comment">E</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">F</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">G</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">H</span>  <span class="comment">issue03</span>
</code></pre><h4 id="Three-way_merge">Three-way merge</h4>
<p>two-way merge只用两个档案进行合并(svn默认是 two-way merge)<br>three-way merge 处理要合并的两个档案，还会奖赏两个档案的共同祖先。如此可大大减少人为处理conflict的情况。<br>为什么能减少人为处理conflict的情况呢？一图胜千言。<br><img src="/resources/three-way-merge.png" alt="Three-way merge">  </p>
<h4 id="实用alias">实用alias</h4>
<pre><code>// 每个commit显示一行，显示图形化的commit history，显示简短的SHA1
alias <span class="keyword">log</span>=<span class="string">"git log --oneline --graph --decorate --color=always"</span>
// 显示所有branch的commit history
alias logg=<span class="string">"git log --graph --all --format=format:'<span class="variable">%C</span>(bold blue)<span class="variable">%h</span><span class="variable">%C</span>(reset) - <span class="variable">%C</span>(bold green)(<span class="variable">%ar</span>)<span class="variable">%C</span>(reset) <span class="variable">%C</span>(white)<span class="variable">%s</span><span class="variable">%C</span>(reset) <span class="variable">%C</span>(bold white)—     <span class="variable">%an</span><span class="variable">%C</span>(reset)<span class="variable">%C</span>(bold yellow)<span class="variable">%d</span><span class="variable">%C</span>(reset)' --abbrev-commit --date=relative"</span>
</code></pre><h4 id="坚持新开branch进行开发需要遵循的原则">坚持新开branch进行开发需要遵循的原则</h4>
<pre><code>1. 不要直接在任何已经与远端建立track关系的branch中进行修改  
    目的：便于维护整洁的<span class="operator"><span class="keyword">commit</span> history

<span class="number">2.</span> feature branch的周期越短越好，不要同时开太多feature branch

<span class="number">3.</span> 在push之前先将本地分支与远端分支同步，推荐使用rebase的方式<span class="keyword">merge</span>

<span class="number">4.</span> 只有在需要push时（如，完成一个功能开发），才将开发分支与主干分支进行合并  
    目的：便于识别<span class="keyword">commit</span>是否push到远端，便于维护整洁的主干<span class="keyword">commit</span> history

<span class="number">5.</span> 分支命名规则
    与远端同步的分支，名字与远端分支一样。如dev -&gt; origin/dev
    进行开发的分支命名不严格限制，但不得与上一类分支重名。
        通过git <span class="keyword">log</span> <span class="comment">--graph即可看出开发分支与主干分支的关系</span></span>
</code></pre><hr>
<h3 id="FAQ">FAQ</h3>
<hr>
<h4 id="如何在git中添加空文件夹">如何在git中添加空文件夹</h4>
<p>git木人的情况下空目录是不会commit出去的，这在某些情况下会遇到问题（比如Rails如果少了log或tmp目录会不能启动）。<br>解决办法就是在空目录下面touch一个空的档案，一般是.gitkeep。  </p>
<h4 id="为什么说懂图论对理解git很有帮助">为什么说懂图论对理解git很有帮助</h4>
<p>理解Git最好的办法，就是用图论中的节点和指针来思考，所有的git的指令操作，<br>都是操作这些节点，新增、修改、删除、变更。<br>首先Git对于所有的内容管理可以理解为一张有向无环图，<a href="https://codewords.recurse.com/issues/two/git-from-the-inside-out" target="_blank" rel="external">这是一篇很好解释文章</a>。<br>同时就自身体会而言，rebase中的base可以理解为两个branch的最小公共祖先。<br>而Fast forward merge可以理解为两个branch合并时，有一个branch是指向这个<br>base节点的。  </p>
<h4 id="如何撤销merge操作">如何撤销merge操作</h4>
<p>如果是刚刚merge完，则可以直接<code>git reset --hard HEAD~</code><br>如果已经添加了很多commit后，才想起来撤销merge，那就该好好反省了。  </p>
<h4 id="如何合理的操作处理分支">如何合理的操作处理分支</h4>
<pre><code><span class="comment">// push 操作</span>
<span class="array"># git push origin b</span>1:rb1    <span class="comment">// 将本地的b1分支推送到远端分支rb1，当前分支不需要一定是b1</span>
<span class="array"># git push origin b</span>1        <span class="comment">// 将本地的b1分支推送到远端分支b1，如果远端不存在b1则新建一个</span>
<span class="array"># git push </span>-u origin b1     <span class="comment">// 第一次push时指定好track，之后就可以直接git push了</span>
<span class="array"># git push                  </span><span class="comment">// 如果是在一个已经建立了track关系的local branch，则可直接push</span>
<span class="array"># git push origin </span>:rb1      <span class="comment">// 删除远端分支rb1</span>

<span class="comment">// fetch 操作</span>
<span class="array"># git fetch </span>-a                  <span class="comment">// 获取远端所有分支</span>
<span class="array"># git fetch origin b</span>2           <span class="comment">// 获取远端分支b2</span>
<span class="array"># git branch b</span>2 origin/b2       <span class="comment">// 随后创建一个本地的b2分支与远端分支建立联系，最好名字一样，否则push时要手动指定</span>
<span class="array"># git checkout </span>--track -b b2 origin/b2  <span class="comment">// 或者直接checkout到一个新建的b2分支   </span>

<span class="comment">// merge 操作</span>
<span class="array"># git cherry</span>-pick <span class="number">332</span>sd3f3      <span class="comment">// 仅将选定的commit apply/patch进入当前分支，相当于首先将332sd3fs打包成一个git格式的patch，然后apply进来。很干净的一种用法</span>
<span class="array"># git merge b</span>1                  <span class="comment">// 将b1分支与current分支合并</span>

<span class="comment">// pull 操作 = fetch + merge</span>
<span class="array"># git pull origin b</span>10   <span class="comment">// 将远端的b10分支与当前分支进行合并，等价于下面两句</span>
    <span class="array"># git fetch origin b</span>10
    <span class="array"># git merge origin</span>/b10
<span class="array"># git pull </span>--rebase origin b10  <span class="comment">// 推荐使用rebase方式合并：本地分支及它track的远端分支</span>

<span class="comment">// remote 操作</span>
<span class="array"># git remote prune origin   </span><span class="comment">// 删除不存在远端仓库的分支</span>
</code></pre><h4 id="如何为一个新建的git添加remote">如何为一个新建的git添加remote</h4>
<pre><code><span class="comment">// 添加remote的仓库地址，origin是名字</span>
<span class="array"># git remote add origin git</span>:<span class="comment">//example.com/a.git    </span>
</code></pre><h4 id="如何恢复某个被修改过的文件">如何恢复某个被修改过的文件</h4>
<pre><code><span class="preprocessor"># git checkout file-name    </span>
</code></pre><h4 id="如何整理git_working_area文件">如何整理git working area文件</h4>
<pre><code><span class="array"># git clean </span>-f          <span class="comment">// 删除未被git管理的文件</span>
<span class="array"># git clean </span>-f -d       <span class="comment">// 同时将未被git管理的目录也删除</span>
<span class="array"># git clean </span>-f -X       <span class="comment">// 仅删除被.gitignore忽略的文件</span>
<span class="array"># git clean </span>-f -x       <span class="comment">// 同时删除被.gitignore忽略的文件和未被管理的文件</span>
<span class="array"># git clean </span>-f -x -d    <span class="comment">// 删除所有未被git管理的文件和目录</span>
</code></pre><h4 id="如何创建一个独立的分支？">如何创建一个独立的分支？</h4>
<pre><code><span class="array"># git checkout </span>--orphan newbranch  <span class="comment">// git v1.7.2</span>
</code></pre><h4 id="有哪些经典的git_workflow可以参考学习？">有哪些经典的git workflow可以参考学习？</h4>
<p><a href="https://guides.github.com/introduction/flow/index.html" target="_blank" rel="external">1. Github Flow</a><br><a href="http://nvie.com/posts/a-successful-git-branching-model/" target="_blank" rel="external">2. GitFlow</a>  </p>
<hr>
<h3 id="参考资料">参考资料</h3>
<p><a href="http://liujin.me/blog/2015/05/25/Git-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" target="_blank" rel="external">Git 常用命令</a><br><a href="http://www.slideshare.net/epatey/perforce-convergence-vs-divergence/10" target="_blank" rel="external">The essence of a three-way merge</a><br><a href="https://ihower.tw/blog/archives/2620" target="_blank" rel="external">開branch 分支和操作遠端repo</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>git作为一个强大的工具，也就意味着它也同样的复杂。<br>长期使用下来难免会遇到很多奇奇怪怪的问题和一些小的知识点，<br>这个帖子就用来记录一下那些年某人踩过的的坑T_T  </p>
<p>这篇会慢慢更新，当某个点内容较多后，会独立出去成为一篇独立的wiki<br>]]>
    
    </summary>
    
      <category term="git" scheme="http://perthcharles.github.com/tags/git/"/>
    
      <category term="wiki-GIT" scheme="http://perthcharles.github.com/categories/wiki-GIT/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[GIT系列四：在push之前对本地commit进行整理]]></title>
    <link href="http://perthcharles.github.com/2015/08/25/clean-commit-log-before-push/"/>
    <id>http://perthcharles.github.com/2015/08/25/clean-commit-log-before-push/</id>
    <published>2015-08-25T03:58:42.000Z</published>
    <updated>2015-08-25T08:12:34.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>在系列三中描述了commit消息的规范，但在实际操作中很难时刻做到那么严格的<br>控制，尤其是在本地做一些实验性的工作的时候。<br>但是如果需要push到远端去，则就必须保证commit消息的规范和commit的独立性。<br>因此就有了这样一个需求：在执行git push之前对本地的commit日志进行整理。<br><a id="more"></a>  </p>
<hr>
<h3 id="一个好习惯">一个好习惯</h3>
<p>本文讨论的一个重要前提是在执行git push之前，对于在本地还未提交commit进行整理！！！<br>本文讨论的一个重要前提是在执行git push之前，对于在本地还未提交commit进行整理！！！<br>本文讨论的一个重要前提是在执行git push之前，对于在本地还未提交commit进行整理！！！<br>重要的事情说三遍。<br>那为什么在git push之后不宜使用这些命令呢？<br>主要是因为本文设计到的命令都会重新提交commit，尽管有commit msg有时候不会变，但commit对应的SHA1哈希值会被改变。如果是已经push了的commit被改变了SHA1，则会造成比较严重的混乱。    </p>
<p>所以这里推荐一个好习惯  </p>
<pre><code>保持重要分支(如master)与远端的同步，开发一定要新开分支。  
</code></pre><p>这样一来就能够快速的识别那些属于还未push的本地commit。<br>接下来就详细介绍整理本地commit的几个重要命令：amemd, reset和rebase  </p>
<hr>
<h3 id="amend">amend</h3>
<p>amend会使用一个新的commit去替换最近的一次commit。<br>amend适用于：<br>a. 在提交commit后，才发现漏掉了某些修改，文件的情况<br>b. 修正一些typo  </p>
<pre><code><span class="comment">// 先进行一些修改，然后使用--amend选项重新提交一次commit</span>
<span class="array"># git commit </span>-a --amend             <span class="comment">// 弹出编辑窗口，重新提交新commit</span>
<span class="array"># git commit </span>-a --amend -C HEAD     <span class="comment">// 直接上一个commit消息</span>
</code></pre><hr>
<h3 id="reset">reset</h3>
<p>amend仅能替换最近一次commit，功能不够强大。比如想要快速的将working tree的修改和最近的两次commit合并得到一个新的commit则需要用到reset啦。<br>reset适用于：<br>a. 需要修改多个commit的情况，但也受限于修改从HEAD~开始连续的多个commit<br>b. 完全的删除前几个commit  </p>
<pre><code><span class="array"># git reset </span>--soft HEAD~<span class="number">2</span>       <span class="comment">// 删掉前两个commit，并保留文件更改</span>
<span class="array"># git reset </span>--hard HEAD~<span class="number">2</span>       <span class="comment">// 删掉前两个commit，并删除文件更改</span>
</code></pre><p>另外，万一如果需要修改的commit已经push出去了（是否应该避免？），又最好不要reset，那么该怎么做呢？<br>那就需要使用revert命令，revert命令会接着重新提交一个新的commit，用以回滚上一个commit的修改。有点负负得正的感觉。  </p>
<hr>
<h3 id="rebase">rebase</h3>
<p>reset受限于只能将从HEAD~开始的连续多个commit删除或(人工)合并。也还是不够强大。比如想要合并HEAD~2到HEAD~3的commit，删除HEAD~4的commit，则需要使用到rebase命令。<br>那到底什么是rebase呢？  </p>
<pre><code>rebase的核心含义就是重新设定基准！  
</code></pre><p>什么意思呢？<br>git对于commit的管理可以理解为一个有向无环图，你的某个branch一定是从另一个分支的某个节点开始分离出来的。比如下面情况下的dev分支的base就可以理解是B节点。<br>更专业的说法应该是：B是E(dev)和C(master)的最小公共祖先。    </p>
<pre><code><span class="comment">A</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">B</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">C</span>   &lt;<span class="comment">=</span> <span class="comment">master</span>
      <span class="comment">\</span>
       <span class="comment">D</span> <span class="literal">-</span><span class="literal">-</span> <span class="comment">E</span> &lt;<span class="comment">=</span> <span class="comment">dev</span>
</code></pre><p>rebase可以用于干什么？<br>a. 仅修改某些commit的msg<br>b. 变更commit顺序<br>c. 删掉某一个commit<br>d. 修改某一个commit对应的内容</p>
<p>rebase的基本命令就是<code>git rebase -i HEAD~n</code>啦，具体的操作流程在执行的时候都有详细的引导，这里就不再重复。想了解细节的推荐看<a href="https://help.github.com/articles/using-git-rebase/" target="_blank" rel="external">这篇tutorial</a> — 其实更推荐找个git仓库实践一把。</p>
<p>下面来介绍一下怎样处理常见的rebas冲突，至于rebase进阶用法，将在后续的wiki上介绍。  </p>
<h4 id="解决rebase冲突">解决rebase冲突</h4>
<p>当发生rebase无法顺利进行的时候，有以下几种选择：  </p>
<pre><code><span class="comment">// a. 放弃rebase  </span>
<span class="preprocessor"># git rebase --abort</span>
<span class="comment">// b. 忽视冲突  -- 一般很少用</span>
<span class="preprocessor"># git rebase --skip</span>

<span class="comment">// c. 解决冲突</span>
<span class="preprocessor"># git status                // 查看冲突类型，常见的是编辑冲突</span>
<span class="preprocessor"># vim conflict-file.md      // 编辑冲突文件</span>
<span class="preprocessor"># git add conflict-file.md  // 重新添加冲突文件</span>
<span class="preprocessor"># git rebase --continue     // 继续rebase</span>
</code></pre><hr>
<h3 id="参考资料">参考资料</h3>
<p><a href="http://gitready.com/intermediate/2009/03/16/rolling-back-changes-with-revert.html" target="_blank" rel="external">rolling back changes with revert</a><br><a href="https://ihower.tw/blog/archives/2622" target="_blank" rel="external">Git 版本控制系統3 - 還沒 push 前可以做的事</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>在系列三中描述了commit消息的规范，但在实际操作中很难时刻做到那么严格的<br>控制，尤其是在本地做一些实验性的工作的时候。<br>但是如果需要push到远端去，则就必须保证commit消息的规范和commit的独立性。<br>因此就有了这样一个需求：在执行git push之前对本地的commit日志进行整理。<br>]]>
    
    </summary>
    
      <category term="git" scheme="http://perthcharles.github.com/tags/git/"/>
    
      <category term="wiki-GIT" scheme="http://perthcharles.github.com/categories/wiki-GIT/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[GIT系列三：commit消息规范]]></title>
    <link href="http://perthcharles.github.com/2015/08/25/git-commit-log-format/"/>
    <id>http://perthcharles.github.com/2015/08/25/git-commit-log-format/</id>
    <published>2015-08-25T03:24:27.000Z</published>
    <updated>2015-08-25T03:52:57.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>维护一个良好的commit消息格式和规范，是一个优秀项目的重要前提。<br>本文就先来谈谈commit消息到底该怎么提交。<br><a id="more"></a>  </p>
<hr>
<h3 id="提交commit的基本原则">提交commit的基本原则</h3>
<pre><code><span class="bullet">1. </span>以一个小功能、小改进或一个bug fixed为单位
<span class="bullet">2. </span>对应的unit test 程序放在同一个commit中
<span class="bullet">3. </span>不相关的代码修改不要放在同一个commit
<span class="bullet">4. </span>语法错误的半成品程序不能commit
</code></pre><hr>
<h3 id="commit消息格式">commit消息格式</h3>
<p>这部分内容已经在具体的例子：<a href="http://perthcharles.github.io/2015/08/14/manage-project-code-like-linux-kernel/" target="_blank" rel="external">像linux kernel一样管理你的项目</a>描述过。<br>这里算是正式的整理进入wiki页面了。<br>至于如何保证做到这么干净利落的commit消息日志，则请移步后续对于rebase等命令的分析。commit的消息格式如下  </p>
<pre><code>第一行用一句简短的话总结这个<span class="operator"><span class="keyword">commit</span>  

第一行最好用一个描述性的前缀开始，比如  
  <span class="string">"net:"</span>表示针对net子系统的修改  
  <span class="string">"fix:"</span>表示这是一个bug fix  

第二行为空行

最后可以增加一些详细的描述，用以解释<span class="keyword">commit</span>具体干了什么，为什么这么干  </span>
</code></pre><p>commit message格式的一个模板如下，为保持原文含义，直接贴上英文版。  </p>
<pre><code>Short (<span class="number">50</span> <span class="keyword">chars</span> <span class="operator">or</span> less) summary <span class="operator">of</span> changes

More <span class="keyword">detailed</span> explanatory <span class="keyword">text</span>, <span class="keyword">if</span> necessary.  Wrap <span class="keyword">it</span> <span class="built_in">to</span>
about <span class="number">72</span> <span class="keyword">characters</span> <span class="operator">or</span> so.  In some contexts, <span class="operator">the</span> <span class="keyword">first</span>
<span class="built_in">line</span> is treated <span class="keyword">as</span> <span class="operator">the</span> subject <span class="operator">of</span> <span class="operator">an</span> email <span class="operator">and</span> <span class="operator">the</span> rest <span class="operator">of</span>
<span class="operator">the</span> <span class="keyword">text</span> <span class="keyword">as</span> <span class="operator">the</span> body.  The blank <span class="built_in">line</span> separating <span class="operator">the</span>
summary <span class="built_in">from</span> <span class="operator">the</span> body is critical (unless you omit <span class="operator">the</span> body
entirely); tools like rebase can <span class="built_in">get</span> confused <span class="keyword">if</span> you run
<span class="operator">the</span> <span class="constant">two</span> together.

Further paragraphs come <span class="keyword">after</span> blank <span class="keyword">lines</span>.

  - Bullet points are okay, too

  - Typically <span class="operator">a</span> hyphen <span class="operator">or</span> asterisk is used <span class="keyword">for</span> <span class="operator">the</span> bullet,
    preceded <span class="keyword">by</span> <span class="operator">a</span> single <span class="constant">space</span>, <span class="operator">with</span> blank <span class="keyword">lines</span> <span class="operator">in</span>
    between, but conventions vary here
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>维护一个良好的commit消息格式和规范，是一个优秀项目的重要前提。<br>本文就先来谈谈commit消息到底该怎么提交。<br>]]>
    
    </summary>
    
      <category term="git" scheme="http://perthcharles.github.com/tags/git/"/>
    
      <category term="wiki-GIT" scheme="http://perthcharles.github.com/categories/wiki-GIT/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[GIT系列二：手动提交一个commit]]></title>
    <link href="http://perthcharles.github.com/2015/08/24/commit-a-simple-manually/"/>
    <id>http://perthcharles.github.com/2015/08/24/commit-a-simple-manually/</id>
    <published>2015-08-24T13:04:02.000Z</published>
    <updated>2015-08-25T03:01:40.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>想要深入的了解一个工具，就必须完一些比较hack的用法。<br>为了更好的了解git内部的工作机制，本文就试图通过手动的编辑.git目录下的<br>文件，来完成一次commit的提交。  </p>
<a id="more"></a>  

<hr>
<h3 id="-git目录下面的文件">.git目录下面的文件</h3>
<pre><code><span class="comment"># git --version  // 当前git版本</span>
    git version 2.3.2 (Apple Git-55)
<span class="comment"># ls -1 .git</span>
<span class="constant">objects</span>     &lt;= 
branches    description info    refs

<span class="constant">HEAD</span>            &lt;= 存放当前branch的HEAD指针
<span class="constant">branches</span>        &lt;= 新版git没有使用该目录
<span class="constant">config</span>          &lt;= 本地git仓库的配置文件
<span class="constant">description</span>     &lt;= 仅用于gitweb程序
<span class="constant">hooks</span>           &lt;= 一定在特定时间发生后被调用的脚本，可理解为钩子函数
<span class="constant">index</span>           &lt;= 文件暂存区信息
info/exclude    &lt;= 功能类似.gitignore的全局性排除文件
<span class="constant">objects</span>         &lt;= 存放真实的数据文件的地方，文件名是SHA1哈希值
refs/heads      &lt;= 存放各个分支的HEAD指针
refs/tags       &lt;= 存放各个tag的commit指针
refs/remotes    &lt;= 存放remote分支的HEAD指针
</code></pre><p>通过分析可以看到，对于一个普通的commit而言，比较相关的应该是objects和HEAD指针  </p>
<hr>
<h3 id="正常的commit过程">正常的commit过程</h3>
<pre><code><span class="preprocessor"># echo "hello world" &gt; hello</span>
<span class="preprocessor"># git add hello</span>
<span class="preprocessor"># git commit -am "add file"</span>
</code></pre><p>在接下来的内容中，将介绍如何在直接编辑.git目录文件的情况下达到与上面命令一样的效果。  </p>
<hr>
<h3 id="手动提交一个commit的步骤">手动提交一个commit的步骤</h3>
<p>git存储内容时，会有一个头部信息一并被保存。<br>比如如果是要存储”hello world\n”字符串，可以通过以下ruby脚本得到  </p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/ruby</span></div><div class="line"></div><div class="line"><span class="built_in">require</span> <span class="string">'digest/sha1'</span></div><div class="line"><span class="built_in">require</span> <span class="string">'zlib'</span></div><div class="line"><span class="built_in">require</span> <span class="string">'fileutils'</span></div><div class="line"></div><div class="line">content = <span class="string">"hello world\n"</span></div><div class="line">header = <span class="string">"blob #{content.length}\0"</span></div><div class="line">store = header + content</div><div class="line"></div><div class="line">sha1 = Digest::SHA1.hexdigest(store)</div><div class="line">puts <span class="string">"sha1:"</span> + sha1</div><div class="line"></div><div class="line">zlib_content = Zlib::Deflate.deflate(store)</div><div class="line">puts <span class="string">"zlib_contet:"</span> + zlib_content</div><div class="line"></div><div class="line">path = <span class="string">'.git/objects/'</span> + sha1[<span class="number">0</span>,<span class="number">2</span>] + <span class="string">'/'</span> + sha1[<span class="number">2</span>,<span class="number">38</span>]</div><div class="line">FileUtils.mkdir_p(File.dirname(path))</div><div class="line">File.<span class="built_in">open</span>(path, <span class="string">'w'</span>) { |f| f.<span class="built_in">write</span> zlib_content}</div></pre></td></tr></table></figure>



<p>由于hello文件的内容是”hello world\n”，因此可以通过以上脚本首先生成<br>hello文件内容对应的object文件，文件类型是blob。可以通过一下命令判断生成的文件内容是否正确  </p>
<pre><code># git <span class="keyword">cat</span>-<span class="keyword">file</span> -<span class="keyword">p</span> <span class="number">3</span>b18e512dba79e4c8300dd08aeb37f8e728b8dad  
# git <span class="keyword">cat</span>-<span class="keyword">file</span> -<span class="keyword">t</span> <span class="number">3</span>b18e512dba79e4c8300dd08aeb37f8e728b8dad
</code></pre><p>以上的object也可以通过一下一条命令得到  </p>
<pre><code># echo <span class="string">"hello world"</span> | git hash-<span class="class"><span class="keyword">object</span> -<span class="title">w</span> --<span class="title">stdin</span></span>
</code></pre><p>随后更新生成.git/index文件  </p>
<pre><code># git <span class="keyword">update</span>-<span class="built_in">index</span> --<span class="built_in">add</span> --cacheinfo <span class="number">100644</span> <span class="number">3</span>b18e512dba79e4c8300dd08aeb37f8e728b8dad hello
</code></pre><p>以上步骤仅是生成了”hello world” 对应的blob文件，但并没有制定这个内容对应的<br>文件名叫什么，也就是少了tree类型的object。接着执行一下命令  </p>
<pre><code><span class="preprocessor"># git write-tree        // 生成指向3b18e5的tree文件，可以用下面两条命令验证</span>
<span class="preprocessor"># git cat-file -p 7604755fe13e27f5327d6d13dc6663d44847562d</span>
<span class="preprocessor"># git cat-file -t 7604755fe13e27f5327d6d13dc6663d44847562d</span>
</code></pre><p>一个真正的commit还需要创建一个commit类型的object指向一个特定的tree节点  </p>
<pre><code><span class="preprocessor"># git commit-tree 7604755fe -m "add file"</span>
<span class="preprocessor"># git cat-file -p df36f6b4884ecf2ec519ddec85f959a83b4adec8</span>
<span class="preprocessor"># git cat-file -t df36f6b4884ecf2ec519ddec85f959a83b4adec8</span>
</code></pre><p>接着更新master的HEAD指针  </p>
<pre><code># git <span class="operator"><span class="keyword">update</span>-ref refs/heads/<span class="keyword">master</span> df36f6b4884ecf2ec519ddec85f959a83b4adec8
# git <span class="keyword">log</span>  &lt;= 至此就能看到一个完整的<span class="keyword">commit</span> <span class="keyword">log</span>
# git checkout hello  &lt;= 将hello文件从.git库checkout出来，就算彻底的完成了一个<span class="keyword">commit</span>了</span>
</code></pre><hr>
<h3 id="总的来说">总的来说</h3>
<pre><code><span class="comment">// 第一部分是完成git add的操作  </span>
<span class="preprocessor"># echo "hello world" | git hash-object -w --stdin</span>
    <span class="number">3</span>b18e512dba79e4c8300dd08aeb37f8e728b8dad    <span class="comment">// 生成blob文件</span>
<span class="preprocessor"># git update-index --add --cacheinfo 100644 3b18e512dba79e4c8300dd08aeb37f8e728b8dad hello</span>

<span class="comment">// 第二部分是完成git  commit的操作</span>
<span class="preprocessor"># git write-tree</span>
    <span class="number">7604755</span>fe13e27f5327d6d13dc6663d44847562d    <span class="comment">// 生成tree文件</span>
<span class="preprocessor"># git commit-tree 7604755fe -m "add file"</span>
    df36f6b4884ecf2ec519ddec85f959a83b4adec8    <span class="comment">// 生成commit</span>
</code></pre><p>可以看出一个commit对应会有三种object文件生成，每种object文件的命名都是以sha1哈希值为依据的。<br>除了commit文件由于带有日期信息所以hash值会变化之外，其他两个文件的hash值都是固定不变的。  </p>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://ihower.tw/git/files/ihower-git-internal.pdf" target="_blank" rel="external">Git internal</a><br><a href="http://git-scm.com/book/zh/v2/Git-%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86-Git-%E5%AF%B9%E8%B1%A1" target="_blank" rel="external">Git 内部原理 - Git 对象</a><br><a href="https://gist.github.com/ihower/6132576" target="_blank" rel="external">Git commit without commit</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>想要深入的了解一个工具，就必须完一些比较hack的用法。<br>为了更好的了解git内部的工作机制，本文就试图通过手动的编辑.git目录下的<br>文件，来完成一次commit的提交。  </p>
]]>
    
    </summary>
    
      <category term="git" scheme="http://perthcharles.github.com/tags/git/"/>
    
      <category term="wiki-GIT" scheme="http://perthcharles.github.com/categories/wiki-GIT/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[GIT系列一：使用gitolite搭建git仓库管理服务]]></title>
    <link href="http://perthcharles.github.com/2015/08/24/setup-gitolite-service-git-1/"/>
    <id>http://perthcharles.github.com/2015/08/24/setup-gitolite-service-git-1/</id>
    <published>2015-08-24T01:40:40.000Z</published>
    <updated>2015-08-25T03:55:11.000Z</updated>
    <content type="html"><![CDATA[<hr>
<p>当在工程实践中需要频繁使用git后发现，要达到真正的熟练掌握git并不是学会几个简单的git commit, git push 就能搞得定的。<br>因此开了这样一个系列，来集中梳理各种正确运用git及相关服务的要点。<br>不过既然是梳理，像那种直接man就能查到的简单用法就不会再赘述。重点在于梳理那些在使用git时会遇到的坑。<br>作为git工程实践系列的开篇，则是介绍如何使用gitolite在自己的机器上搭建git仓库管理服务。<br>只有在搭建好了一个良好的后台管理服务，才能为后续的git使用保驾护航。  </p>
<pre><code>如果是想了解git基本操作，这是一个不错的开始：[<span class="link_label">Try git</span>](<span class="link_url">https://www.codeschool.com/courses/try-git</span>)  
</code></pre><a id="more"></a>  

<hr>
<h3 id="安装gitolite">安装gitolite</h3>
<pre><code><span class="comment">// 创建专用账号</span>
@<span class="keyword">server</span> <span class="preprocessor"># adduser -m git -s /bin/bash</span>

<span class="comment">// 将客户端公钥上传服务器</span>
@admin-<span class="keyword">client</span> <span class="preprocessor"># scp ~/.ssh/id_ras.pub git@gitolite-server-ip:/home/git/admin.pub</span>

<span class="comment">// 切换到专用账号git，然后安装gitolite</span>
<span class="preprocessor"># sudo su git</span>
$ mkdir -p ~/bin
$ cd /home/git
$ git clone git:<span class="comment">//github.com/sitaramc/gitolite    // 获取gitolite</span>
$ git checkout -b newest-release v3<span class="number">.6</span><span class="number">.3</span>           <span class="comment">// 换到最新的一次release</span>
$ gitolite/install -ln ~/bin             <span class="comment">// 安装gitolite到指定目录</span>

<span class="comment">// 配置管理员公钥</span>
$ bin/gitolite setup -pk admin.pub
</code></pre><hr>
<h3 id="克隆gitolite">克隆gitolite</h3>
<p>至此可在admin-client克隆gitolite管理仓库</p>
<pre><code>@admin-<span class="keyword">client</span> <span class="preprocessor"># git clone git@gitolite-server-ip:gitolite-admin</span>

    <span class="comment">// MAC电脑下如果是新生成的id_ras.pub，则需要添加管理</span>
    @admin-<span class="keyword">client</span> <span class="preprocessor"># ssh-add -K ~/.ssh/id_ras.pub</span>

<span class="preprocessor"># cd gitolite-admin</span>
<span class="preprocessor"># ls</span>
conf    keydir        <span class="comment">// conf用于配置git项目权限，keydir用于存放git用户公钥</span>
</code></pre><hr>
<h3 id="新建GIT项目">新建GIT项目</h3>
<pre><code><span class="comment">// 回到客户端，在gitolite的配置中，增加project项目，并设置admin访问权限</span>
<span class="preprocessor"># cat conf/gitolite.conf</span>
repo gitolite-admin
    RW+     =   admin

repo testing
    RW+     =   @all

repo git-learning
    RW+     =   admin

<span class="preprocessor"># 提交对gitolite配置文件的修改</span>
<span class="preprocessor"># git commit -am 'add git project'</span>
<span class="preprocessor"># git push origin master    // 至此，管理员可在客户端克隆git@gitolite-server-ip:project</span>

<span class="comment">// 新的project.git会在执行git push自动创建，默认的目录是：/home/git/repositories</span>
</code></pre><hr>
<h3 id="新增GIT用户">新增GIT用户</h3>
<pre><code>// 将要添加的用户的公钥上传到gitolite-admin/kerdir目录下
$ <span class="keyword">ls</span> kerdir/
admin.pub <span class="keyword">new</span>.pub

// 配置用户<span class="keyword">new</span>的权限
$ <span class="keyword">cat</span> <span class="keyword">conf</span>/gitolite.<span class="keyword">conf</span>
repo gitolite-admin
    RW+     =   admin

repo testing
    RW+     =   @all

repo git-learning
    RW+     =   admin
    RW        =    <span class="keyword">new</span>

// 然后提交
$ git <span class="built_in">add</span> kerdir/<span class="keyword">new</span>.pub
$ git commit -<span class="keyword">am</span> <span class="string">'add user new for project'</span>
$ git push origin master
</code></pre><hr>
<h3 id="权限控制管理">权限控制管理</h3>
<pre><code><span class="comment">/* 实例1 */</span>  
repo project
    RW+        =    admin    <span class="comment">// admin 有读，写，强制写的权限</span>
    R        =    <span class="keyword">new</span>        <span class="comment">// new 仅有读权限，如果尝试提交会报错</span>

<span class="comment">/* 实例2 */</span> 
repo project
    RW+            =    admin    <span class="comment">// admin 有读，写，强制写的权限</span>
    <span class="comment">// new 对所有以dev开始的分支都有读写权限。即可以新建dev3，修改dev2分支 </span>
    RW    dev        =    <span class="keyword">new</span>        

<span class="comment">/* 实例3 */</span>
repo project
    RW+            =    admin
    <span class="comment">// new 仅对dev分支有写权限，$表示精确匹配</span>
    RW    dev$    =    <span class="keyword">new</span>

<span class="comment">/* 实例4 */</span>
repo project
    ...
    -    refs/tags/v[<span class="number">0</span>-<span class="number">9</span>]    = <span class="keyword">new</span>    <span class="comment">// new用户仅能创建除了以v加上数字开头之外的其他tag</span>

<span class="comment">/* 实例5 */</span>
repo project
    ...
    <span class="comment">// 除了根目录的Makefile文件外，new对其他文件都具有写权限</span>
    -    NAME/Makefile    = <span class="keyword">new</span>
    RW    Name/            = <span class="keyword">new</span>

<span class="comment">/* 推荐用法 */</span>
repo project
    <span class="comment">// 有效防止误操作：</span>
    <span class="comment">//     指定admin对branch的读写权限，防止误操作将本地的临时性branch推送到服务器端</span>
    <span class="comment">//     如果确定需要新增一个branch，则在下面新增一行，例如新增dev分支</span>
    RW+ master$     =   admin   <span class="comment">// admin 有读，写，强制写master分支的权限</span>
    RW+ dev$        =   admin   <span class="comment">// admin 有读，写，强制写dev分支的权限</span>

    RW  dev$             =  dev1 dev2     <span class="comment">// 普通developer仅能读写dev分支，且不能强制写</span>
    -   refs/tags/v[<span class="number">0</span>-<span class="number">9</span>] =  dev2 dev2     <span class="comment">// 限制普通用户不能创建以v加上数字开头的release tag</span>
    <span class="comment">// 如果不同的用户(组)分别负责完全独立的两个子系统，则可通过类似以下这种方式排除互相干扰</span>
    -   NAME/net/        =  dev1    <span class="comment">// dev1 不能修改net子系统下的文件</span>
    -   NAME/arch/       =  dev2    <span class="comment">// dev2 不能修改arch子系统下的文件</span>
</code></pre><hr>
<h3 id="配置gitweb">配置gitweb</h3>
<p>本节主要参考<a href="http://zodiacg.net/2014/05/gitolite_gitweb_nginx/" target="_blank" rel="external">配置Gitolite+Gitweb+Nginx</a>  </p>
<pre><code><span class="comment">// 安装gitweb 和用于代码高亮的highlight</span>
$ sudo apt-get install -y gitweb highlight

<span class="comment">// 修改文件权限，用于gitweb读取</span>
$ chmod <span class="number">0027</span> /home/git.gitolite.rc
$ sudo usermod -a -G git www-data   <span class="comment">// www-data 是运行nginx服务的用户</span>
$ sudo chmod g+r    /home/git/projects.<span class="keyword">list</span>
$ sudo chmod -R g+rx /home/git/repositories

<span class="comment">// 将要显示的repo写入projects.list文件</span>
$ cat projects.<span class="keyword">list</span>
    testing.git

<span class="comment">// 修改/etc/gitweb.conf，修改以下几个关键值</span>
$ cat /etc/gitweb.conf
    <span class="comment"># path to git projects (&lt;project&gt;.git)</span>
    <span class="variable">$projectroot</span> = <span class="string">"/home/git/repositories/"</span>;

    <span class="comment"># directory to use for temp files</span>
    <span class="variable">$git_temp</span> = <span class="string">"/tmp"</span>;

    <span class="comment"># target of the home link on top of all pages</span>
    <span class="comment">#$home_link = $my_uri || "/";</span>

    <span class="comment"># html text to include at home page</span>
    <span class="comment">#$home_text = "indextext.html";</span>

    <span class="comment"># file with project list; by default, simply scan the projectroot dir.</span>
    <span class="variable">$projects_list</span> = <span class="string">"/home/git/projects.list"</span>;
    <span class="variable">$strict_export</span> = <span class="number">1</span>;

    <span class="comment"># stylesheet to use</span>
    <span class="comment">#@stylesheets = ("static/gitweb.css");</span>

    <span class="comment"># javascript code for gitweb</span>
    <span class="variable">$javascript</span> = <span class="string">"static/gitweb.js"</span>;

    <span class="comment"># logo to use</span>
    <span class="variable">$logo</span> = <span class="string">"static/git-logo.png"</span>;

    <span class="comment"># the 'favicon'</span>
    <span class="comment">#$favicon = "static/git-favicon.png";</span>

    <span class="comment"># git-diff-tree(1) options to use for generated patches</span>
    <span class="comment">#@diff_opts = ("-M");</span>
    @diff_opts = ();

    <span class="variable">$feature</span> {<span class="string">'blame'</span>}{<span class="string">'default'</span>} = [<span class="number">1</span>];
    <span class="variable">$feature</span> {<span class="string">'blame'</span>}{<span class="string">'override'</span>} = <span class="number">1</span>;

    <span class="variable">$feature</span> {<span class="string">'snapshot'</span>}{<span class="string">'default'</span>} = [<span class="string">'zip'</span>, <span class="string">'tgz'</span>];
    <span class="variable">$feature</span> {<span class="string">'snapshot'</span>}{<span class="string">'override'</span>} = <span class="number">1</span>;

    <span class="variable">$feature</span>{<span class="string">'highlight'</span>}{<span class="string">'default'</span>} = [<span class="number">1</span>];

<span class="comment">// 配置nginx</span>
$ sudo apt-get install spawn-fcgi fcgiwrap
<span class="comment">// 修改/etc/init/d/fcgi.fcgiwrap,将FCGI_USER FCGI_GROUP FCGI_SOCKET_OWNER FCGI_SOCKET_GROUP 都修改为运行web服务的用户</span>
<span class="comment">// 在nginx的配置文件中添加一个新的server段</span>
    server {
        listen <span class="number">80</span>;
        server_name gitweb.example.com;
        access_log  /home/wwwlogs/access.log  main;

        location / {
            root /usr/share/gitweb;
            index index.cgi;
            <span class="keyword">include</span> fastcgi_params;
            gzip off;
            fastcgi_param GITWEB_CONFIG /etc/gitweb.conf;

            <span class="keyword">if</span> (<span class="variable">$uri</span> ~ <span class="string">"/index.cgi"</span>) {
                fastcgi_pass unix:/<span class="keyword">var</span>/run/fcgiwrap.socket;
            }
        }
    }

<span class="comment">// 重启fcgiwrap和nginx</span>
$ sudo service fcgiwrap restart
$ sudo nginx -s reload
</code></pre><hr>
<h3 id="参考资料">参考资料</h3>
<p><a href="http://www.ossxp.com/doc/git/gitolite.html" target="_blank" rel="external">Gitolite 构建 Git 服务器</a><br><a href="http://zodiacg.net/2014/05/gitolite_gitweb_nginx/" target="_blank" rel="external">配置Gitolite+Gitweb+Nginx</a><br><a href="http://gitolite.com/gitolite/gitolite.html" target="_blank" rel="external">gitolite all-in-one page</a>  </p>
]]></content>
    <summary type="html">
    <![CDATA[<hr>
<p>当在工程实践中需要频繁使用git后发现，要达到真正的熟练掌握git并不是学会几个简单的git commit, git push 就能搞得定的。<br>因此开了这样一个系列，来集中梳理各种正确运用git及相关服务的要点。<br>不过既然是梳理，像那种直接man就能查到的简单用法就不会再赘述。重点在于梳理那些在使用git时会遇到的坑。<br>作为git工程实践系列的开篇，则是介绍如何使用gitolite在自己的机器上搭建git仓库管理服务。<br>只有在搭建好了一个良好的后台管理服务，才能为后续的git使用保驾护航。  </p>
<pre><code>如果是想了解git基本操作，这是一个不错的开始：[<span class="link_label">Try git</span>](<span class="link_url">https://www.codeschool.com/courses/try-git</span>)  
</code></pre>]]>
    
    </summary>
    
      <category term="git" scheme="http://perthcharles.github.com/tags/git/"/>
    
      <category term="wiki-GIT" scheme="http://perthcharles.github.com/categories/wiki-GIT/"/>
    
  </entry>
  
</feed>
